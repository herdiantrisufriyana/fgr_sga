---
title: 'Widely-accessible prognostication using medical history for fetal 
        growth restriction and small for gestational age in nationwide insured 
        women'
author:
  - name: Herdiantri Sufriyana
    affiliation:
    - &gibi Graduate Institute of Biomedical Informatics, College of Medical
      Science and Technology, Taipei Medical University, Taipei, Taiwan
    - Department of Medical Physiology, Faculty of Medicine, Universitas 
      Nahdlatul Ulama Surabaya, Surabaya, Indonesia
    email: herdiantrisufriyana@unusa.ac.id
  - name: Fariska Zata Amani
    affiliation:
    - Department of Obstetric and Gynecology, Faculty of Medicine, Universitas 
      Nahdlatul Ulama Surabaya, Surabaya, Indonesia
  - name: Aufar Zimamuzzaman Al Hajiri
    affiliation:
    - Faculty of Medicine, Universitas Nahdlatul Ulama Surabaya, Surabaya, 
      Indonesia
  - name: Yu-Wei Wu
    affiliation:
    - *gibi
    - &tmuh Clinical Big Data Research Center, Taipei Medical University
      Hospital, Taipei, Taiwan
  - name: Emily Chia-Yu Su
    affiliation:
    - *gibi
    - *tmuh
    - Research Center for Artificial Intelligence in Medicine, Taipei Medical
      University, Taipei, Taiwan
output: 
  html_document
  # pdf_document
  # word_document:
  #   reference_docx: styles_fgr_sga.docx
always_allow_html: yes
---

\tableofcontents
\newpage
\listoffigures
\listoftables

Please kindly see Supplemental Spreadsheet. Most are complex tables. There are 
20 tables in different tabs.

\newpage

In this Supplementary Information, we describe details on this study following 
chronological order of our analysis pipeline on causal inference or predictive 
modeling for fetal growth restriction and small for gestational age (FGR-SGA). 
There three sections corresponding to the same sections in the main text but 
different order, which are respectively Methods, Results, and Discussion. Along 
with this PDF document, we also provide R Markdown (.Rmd) containing the same 
texts with this document but including the programming codes for the data 
analysis in-between of these texts. The codes for core steps in the analysis 
pipeline are also provided exclusively in an R Script (.R). The codes beyond 
the core steps were used for analytic decision or creating tables or figures. 
These are shown to provide details on how data are processed to construct all 
tables and figures in both the main text and this Supplementary Information, 
including those in Source Data Spreadsheets (.xlsx) for all figures in the main 
text and those in a single Supplemental Spreadsheet (.xlsx) with multiple tabs 
for all tables in this Supplementary Information. The complex tables were 
produced separately as comma-separated value (.csv) files then compiled into 
the single Supplemental Spreadsheet. We also provided a 5-minute Supplemental 
Video to briefly explain technical details on deep-insight visible neural 
network (DI-VNN) pipeline.The R Markdown and Script are available in 
https://github.com/herdiantrisufriyana/fgr_sga.The R Markdown, R Script, and 
processed data are available in https://github.com/herdiantrisufriyana/fgr_sga. 
To get raw data, one need to request an access from the BPJS Kesehatan for 
their sample dataset published in August 2019. Up to this date, there are three 
sample datasets they published in February 2019, August 2019, and December 
2020. For the first and second versions, a request is applied via 
https://e-ppid.bpjs-kesehatan.go.id/, while the third is applied via 
https://data.bpjs-kesehatan.go.id. To preprocess the raw data into the input 
dataset of this study, follow the codes of the R Markdown in 
https://github.com/herdiantrisufriyana/medhist/tree/main/preprocessing.

# Methods

## Research Guidelines

We followed three research guidelines. The checklists for all the guidelines 
are shown (Table 1 to 3 in Supplemental Spreadsheet). To find comparable models 
to evaluate success criteria, we also followed other guidelines. The checklist 
and the comparable models are also described (Table 4 and 5 in Supplemental 
Spreadsheet).

## Programming environment

We set up a programming environment for this study. Bioconductor was utilized 
as described in the main text. There were ... R packages which are ... base 
packages, ... other packages, and ... dependencies (Table 6 in Supplemental 
Spreadsheet). We also used renv package to set up reproducible environment 
across R and Python.

```{r Set up reproducible environment, include=FALSE}
if(!require(renv)) install.packages('renv')
if(!file.exists('renv')) renv::init(restart=F)
```

```{r Set sample kind, include=FALSE}
# sample.kind=NULL # if using R 3.5 or earlier
sample.kind='Rounding' # if using R 3.6 or later
```

```{r Set to run or not run very heavy computations, include=FALSE}
# Many computations were very heavy;
# thus, we provided the RDS files as substitutes and load only ones
# that can be ran in most computers.
# Set to TRUE if you want to run the very heavy computations.
run_heavy_computation=F
```

```{r Recommended memory limit, include=FALSE}
# Minimum 1 GB free memory should be allocated
memory.limit(size=1000000)
```

```{r Install and set specific version of Bioconductor, include=FALSE}
source('R/check_install_load-function.R')

# Install devtools to install specific version of BiocManager.
check_install_load('devtools',version='2.4.1',repo='cran',load=F)

# Install specific version of BiocManager and Bioconductor.
check_install_load('BiocManager',version='1.30.10',repo='cran',load=F)
install_steps=T
if(BiocManager::version()!='3.11'){
  BiocManager::install(version='3.11',update=TRUE,ask=FALSE)
  install_steps=c(F,T)
}
```

```{r Install and load packages with specific version, include=FALSE}
for(i in install_steps){
  if(i) renv::restore()
  
  check_install_load('tidyverse','1.3.0',repo='bioc',load=i)
  check_install_load('dslabs','0.7.3',repo='bioc',load=i)
  check_install_load('kableExtra','1.3.4',repo='bioc',load=i)
  check_install_load('parallel','4.0.2',repo='bioc',load=i)
  check_install_load('doParallel','1.0.16',repo='bioc',load=i)
  check_install_load('pbapply','1.4.3',repo='bioc',load=i)
  check_install_load('lubridate','1.7.10',repo='bioc',load=i)
  check_install_load('broom','0.7.8',repo='bioc',load=i)
  check_install_load('caret','6.0.86',repo='bioc',load=i)
  check_install_load('gmethods','0.1.0',repo='herdiantrisufriyana',load=i)
  check_install_load('igraph','1.2.6',repo='bioc',load=i)
  check_install_load('glmnet','4.1',repo='bioc',load=i)
  check_install_load('Rborist','0.2.3',repo='bioc',load=i)
  check_install_load('gbm','2.1.8',repo='bioc',load=i)
  check_install_load('gam','1.20',repo='bioc',load=i)
  check_install_load('preprocessCore','1.50.0',repo='bioc',load=i)
  check_install_load('limma','3.44.3',repo='bioc',load=i)
  check_install_load('AnnotationDbi','1.50.3',repo='bioc',load=i)
  check_install_load('Rcpp','1.0.7',repo='bioc',load=i)
  check_install_load('GO.db','3.11.4',repo='bioc',load=i)
  check_install_load('WGCNA','1.70.3',repo='bioc',load=i)
  check_install_load('matrixStats','0.59.0',repo='bioc',load=i)
  check_install_load('Rtsne','0.15',repo='bioc',load=i)
  check_install_load('reticulate','1.16',repo='bioc',load=i)
  check_install_load('Biobase','2.48.0',repo='bioc',load=i)
  check_install_load('medhist','0.1.0',repo='herdiantrisufriyana',load=i)
  check_install_load('survival','3.1.12',repo='bioc',load=i)
  check_install_load('imputeTS','3.2',repo='bioc',load=i)
  check_install_load('geepack','1.3.2',repo='bioc',load=i)
  check_install_load('rsdr','0.1.0',repo='herdiantrisufriyana',load=i)
  check_install_load('zeallot','0.1.0',repo='bioc',load=i)
  check_install_load('divnn','0.1.3',repo='herdiantrisufriyana',load=i)
  check_install_load('clixo','0.1.1',repo='herdiantrisufriyana',load=i)
  check_install_load('MLeval','0.3',repo='bioc',load=i)
  check_install_load('ggnetwork','0.5.10',repo='bioc',load=i)
  check_install_load('visNetwork','2.0.9',repo='bioc',load=i)
  check_install_load('parallelDist','0.2.4',repo='bioc',load=i)
  check_install_load('ggpubr','0.4.0',repo='bioc',load=i)
  check_install_load('extrafont','0.17',repo='bioc',load=i)
  check_install_load('ggsci','2.9',repo='bioc',load=i)
  check_install_load('readxl','1.3.1',repo='bioc',load=i)
  check_install_load('tensorflow','2.0.0',repo='devtools',load=F)
  check_install_load('keras','2.3.0.0',repo='devtools',load=F)
  
  if(i){
    options(dplyr.summarise.inform=F)
    dslabs::ds_theme_set()
    select=dplyr::select
    rename=dplyr::rename
    slice=dplyr::slice
    use_condaenv('./renv/python/condaenvs/renv-python',required=T)
    renv::use_python(name='./renv/python/condaenvs/renv-python')
  }else{
    extrafont::font_import()
    reticulate::conda_create(
      envname='./renv/python/condaenvs/renv-python'
      ,packages='python=3.6.3'
    )
    reticulate::use_condaenv('./renv/python/condaenvs/renv-python',required=T)
    renv::use_python(name='./renv/python/condaenvs/renv-python')
    keras::install_keras(
      method='conda',
      version='2.3.0',
      tensorflow='2.0.0-gpu',
      envname='./renv/python/condaenvs/renv-python',
      conda_python_version='3.6.3',
      extra_packages=
        c('numpy','pandas','matplotlib==3.1.0','scikit-learn','h5py==2.10.0'),
      restart_session=F
    )
    # Please use console for this python installation.
    reticulate::py_install(
      envname='./renv/python/condaenvs/renv-python'
      ,packages='h5py==2.10.0'
      ,python_version='3.6.3'
      ,pip=T
      ,pip_options='--force-reinstall'
      ,pip_ignore_installed=T
    )
    renv::snapshot()
  }
}

rm(i)
```

```{r Load log for the expensive computation, include=FALSE}
# This is needed to print messages at the time we run the expensive computation.
source('data/log.R')
```

```{r table-C1, eval=FALSE, include=FALSE}
# Save package tables and the versions
rbind(
  
    # The base packages
    sessionInfo()$basePkgs %>%
      data.frame(
        package=.
        ,version=
          paste0(
            sessionInfo()$R.version$major
            ,'.'
            ,sessionInfo()$R.version$minor
          )
        ,base='Yes'
        ,loaded='Yes'
        ,attached='Yes'
      )
    
    # Additional packages specific to this study
    ,sessionInfo()$otherPkgs %>%
      lapply(function(x)data.frame(version=x$Version)) %>%
      do.call(rbind,.) %>%
      rownames_to_column(var='package') %>%
      mutate(base='No',loaded='Yes',attached='Yes')
    
    # The explicit dependencies
    ,sessionInfo()$loadedOnly %>%
      lapply(function(x)data.frame(version=x$Version)) %>%
      do.call(rbind,.) %>%
      rownames_to_column(var='package') %>%
      mutate(base='No',loaded='Yes',attached='No')
    
  ) %>%
  setNames(str_to_sentence(colnames(.))) %>%
  
  # Save for Table C1.
  write_csv('data/table_C1.csv')
```

## Sampling procedures of the data source

The data source was a sample dataset of the whole health insurance database 
during 2015 and 2016 by cross-sectional design. Stratified random sampling was 
applied. The strata variable was constructed from 66,072 combinations of all 
the healthcare facilities (*n*=22,024) and category of family, which were: (1) 
a family of which members never visit the healthcare facilities; (2) a family 
of which members have visited only primary care; and (3) a family of which 
members have visited all levels of care. For each stratum, one to ten families 
were randomly included. This means only 10 families were randomly included if 
more than that number, resulting 586,969 families with 1,697,452 subjects.

## The sampling procedures of the dataset in this study

We conducted non-essential data cleaning, e.g. revising the inconsistent name 
of states, estimating the healthcare identifiers, *et cetera*. These procedures 
were parts of our R package of ... (DBPR). No sampling was conducted.

```{r Read public data II tables from an R file, eval=FALSE, include=FALSE}
# This is the output of the raw data after being preprocessed by data.Rmd in:
# https://github.com/herdiantrisufriyana/medhist/tree/main/preprocessing
public=readRDS('data/public2.rds')
```

```{r Combine tables, eval=FALSE, include=FALSE}
public$visits=
  
  # Access a list of visit datasets based on capitation, fee for service (FFS), 
  # and diagnosis-related group (DRG).
  public[c('visit_cap','visit_ffs','visit_drg')] %>%
  
  # For each element of the list, select 4 columns and bind the elements by row.
  lapply(select,visit_id,subject_id,healthcare_id,admission_date) %>%
  do.call(rbind,.) %>%
  
  # Join with diagnosis dataset by visit_id, follow the dataframe above.
  left_join(public$diagnosis,by='visit_id') %>%
  
  # Exclude diagnoses at admission since it's unlikely definitive.
  filter(!code_type%in%c('Admission diagnosis')) %>%
  select(-code_type) %>%
  
  # Find the earliest visit per subject and filter only the unique visits.
  group_by(subject_id) %>%
  mutate(db_start_date=min(admission_date)) %>%
  ungroup() %>%
  filter(!duplicated(.))
```

After the non-essential data cleaning, we applied retrospective cohort design, 
as described in the main text. For pregnant women, we use several codes for 
determining delivery or immediately after delivery care. The 220 codes are 
described (Table 7 in Supplemental Spreadsheet).

```{r Determine target population, eval=FALSE, include=FALSE}
public$target_population=
  
  ##### The health insurance holders of
  public$subject %>%
  lapply(X=1,Y=.,function(X,Y){
    # Record this step to the table of subject selection
    data.frame(
        step='total'
        ,exc_visit=0
        ,inc_visit=sum(public$visits$subject_id %in% Y$subject_id)
        ,exc_subject=0
        ,inc_subject=nrow(Y)
      ) %>%
      saveRDS('data/selection.rds')
    Y
  }) %>%
  .[[1]]


public$target_population=
  
  public$target_population %>%

  ##### 12-to-55-years-old (at visit between 2015 and 2016)
  filter(
    between(as.duration(as_date('2015-01-01')-birth_date)/dyears(1),12,55) |
    between(as.duration(as_date('2016-12-31')-birth_date)/dyears(1),12,55)
  ) %>%
  lapply(X=1,Y=.,function(X,Y){
    # Record this step to the table of subject selection.
    readRDS('data/selection.rds') %>%
      rbind(
        data.frame(
          step='age selection by 12 to 55 years old'
          ,exc_visit=
            .$inc_visit[nrow(.)]
            -sum(public$visits$subject_id %in% Y$subject_id)
          ,inc_visit=sum(public$visits$subject_id %in% Y$subject_id)
          ,exc_subject=.$inc_subject[nrow(.)]-nrow(Y)
          ,inc_subject=nrow(Y)
        )
      ) %>%
      saveRDS('data/selection.rds')
    Y
  }) %>%
  .[[1]]

public$target_population=
  
  public$target_population %>%

  ##### females
  filter(sex=='female') %>%
  lapply(X=1,Y=.,function(X,Y){
    # Record this step to the table of subject selection.
    readRDS('data/selection.rds') %>%
      rbind(
        data.frame(
          step='sex selection by female'
          ,exc_visit=
            .$inc_visit[nrow(.)]
            -sum(public$visits$subject_id %in% Y$subject_id)
          ,inc_visit=sum(public$visits$subject_id %in% Y$subject_id)
          ,exc_subject=.$inc_subject[nrow(.)]-nrow(Y)
          ,inc_subject=nrow(Y)
        )
      ) %>%
      saveRDS('data/selection.rds')
    Y
  }) %>%
  .[[1]]


public$target_population=
  
  public$target_population %>%

  ##### who visit healthcare providers
  filter(subject_id%in%public$visits$subject_id) %>%
  lapply(X=1,Y=.,function(X,Y){
    # Record this step to the table of subject selection.
    readRDS('data/selection.rds') %>%
      rbind(
        data.frame(
          step='visit healthcare providers'
          ,exc_visit=
            .$inc_visit[nrow(.)]
            -sum(public$visits$subject_id %in% Y$subject_id)
          ,inc_visit=sum(public$visits$subject_id %in% Y$subject_id)
          ,exc_subject=.$inc_subject[nrow(.)]-nrow(Y)
          ,inc_subject=nrow(Y)
        )
      ) %>%
      saveRDS('data/selection.rds')
    Y
  }) %>%
  .[[1]]
```

```{r Determine pregnant women of target population, eval=FALSE, include=FALSE}
public$pregnancy_status=
  
  # Get pregnancy status of the target population.
  public$target_population %>%
  lapply(X=1,Y=.,Z=public$visits,K=public$annotation,function(X,Y,Z,K){
    
    # Use these regular expression for the target population
    # to find codes related to pregnancy.
    L=Z %>%
      filter(subject_id%in%Y$subject_id) %>%
      left_join(K,by='code') %>%
      filter(
        str_detect(
          str_to_lower(paste(code,desc))
          ,paste0(c(
              'obstet'
              ,'pregnan'
              ,'labou?r\\s+'
              ,'deliver'
              ,'cesar'
              ,'natal'
              ,'z3[3467]'
              ,'o\\d+'
            ),collapse='|')
        )
      )
    
    # From the pregnancy-related visits, find the earliest and the latest.
    M=L %>%
      group_by(subject_id) %>%
      summarize(
        preg_e=min(admission_date)
        ,preg_l=max(admission_date)
        ,.groups='drop'
      ) %>%
      ungroup()
    
    # Find the related codes for the end of pregnancy.
    N=L %>%
      
      # This may include the false-positive codes
      filter(
        str_detect(
          str_to_lower(paste(code,desc))
          ,paste0(c(
            'abort'
            ,'deliver'
            ,'cesar'
            ,'labou?r\\s+'
            ,'natal'
            ,'postpartum'
            ,'terminat'
            ,'o0[0123]'
            ,'o152'
            ,'o364'
            ,'o63'
            ,'o7[02]'
            ,'o8[579]'
            ,'o90'
            ,'z3[79]'
          ),collapse='|')
        )
      ) %>%
      
      # By manual inspection, exclude the false-positive codes.
      filter(!(
        str_detect(
          str_to_lower(paste(code,desc))
          ,paste0(c(
            'aborter'
            ,'ante'
            ,'peri'
            ,'delayed'
            ,'false'
            ,'failed'
            ,'prenatal'
            ,'threatened'
            ,'o311'
            ,'z351'
            ,'o600'
            ,'o96'
          ),collapse='|')
        ) &
        !str_detect(
          str_to_lower(code)
          ,paste0(c(
            'o0[34568]'
            ,'o15[12]'
            ,'o7[02]'
            ,'o8[79]'
          ),collapse='|')
        )
      )) %>%
      
      # Record the codes for the end of pregnancy. 
      lapply(X=1,Y=.,function(X,Y){
        saveRDS(Y,'data/termination_codes.rds')
        Y
      }) %>%
      .[[1]] %>%
      
      # Find the earliest and latest dates of 
      # the related codes for  the end of pregnancy.
      group_by(subject_id) %>%
      summarize(
        termin_e=min(admission_date)
        ,termin_l=max(admission_date)
        ,.groups='drop'
      ) %>%
      ungroup()
    
    # Get visits after the end of the first pregnancy in the dataset period.
    O=L %>%
      left_join(N,by='subject_id') %>%
      filter(admission_date>termin_l)
    
    # Get the earliest date of the second-pregnancy visits.
    P=O %>%
      group_by(subject_id) %>%
      summarize(
        preg_e2=min(admission_date)
        ,.groups='drop'
      ) %>%
      ungroup()
    
    # Find the related codes for the end of the second pregnancy.
    Q=O %>%
      
      # This may include the false-positive codes
      filter(
        str_detect(
          str_to_lower(paste(code,desc))
          ,paste0(c(
            'abort'
            ,'deliver'
            ,'cesar'
            ,'labou?r\\s+'
            ,'natal'
            ,'postpartum'
            ,'terminat'
            ,'o0[0123]'
            ,'o152'
            ,'o364'
            ,'o63'
            ,'o7[02]'
            ,'o8[579]'
            ,'o90'
            ,'z3[79]'
          ),collapse='|')
        )
      ) %>%
      
      # By manual inspection, exclude the false-positive codes.
      filter(!(
        str_detect(
          str_to_lower(paste(code,desc))
          ,paste0(c(
            'aborter'
            ,'ante'
            ,'peri'
            ,'delayed'
            ,'false'
            ,'failed'
            ,'prenatal'
            ,'threatened'
            ,'o311'
            ,'z351'
            ,'o600'
            ,'o96'
          ),collapse='|')
        ) &
        !str_detect(
          str_to_lower(code)
          ,paste0(c(
            'o0[34568]'
            ,'o15[12]'
            ,'o7[02]'
            ,'o868'
            ,'o8[79]'
          ),collapse='|')
        )
      )) %>%
      
      # Find the earliest and latest dates of 
      # the related codes for  the end of the second pregnancy.
      group_by(subject_id) %>%
      summarize(
        termin_e2=suppressWarnings(min(admission_date))
        ,termin_l2=suppressWarnings(max(admission_date))
        ,.groups='drop'
      ) %>%
      ungroup()
    
    # Join offset dates to find the pregnancy periods.
    R=M %>%
      left_join(N,by='subject_id') %>%
      left_join(P,by='subject_id') %>%
      left_join(Q,by='subject_id') %>%
      select(
        subject_id
        ,preg_e
        ,termin_e
        ,termin_l
        ,preg_e2
        ,termin_e2
        ,termin_l2
        ,preg_l
        ,everything()
      )
    
    # Join the offset dates to the target population data
    # and compute the number of either gestation and termination.
    S=Y %>%
      left_join(R,by='subject_id') %>%
      mutate(
        gestation=
          as.integer(!is.na(preg_e))
          + as.integer(!is.na(preg_e2))
        ,termination=
          as.integer(!is.na(termin_l))
          + as.integer(!is.na(termin_l2))
      )
    
    # Filtered by gestation, select different offsets depending on
    # the pregnancy period, and combine the filtering results. 
    # This separates 2 pregnancy periods of a subject into 2 instances.
    rbind(
        filter(S,gestation==0) %>%
          select(
            subject_id,preg_e,termin_e,termin_l,preg_l,gestation,termination
          ) %>%
          mutate(gestation_n=0)
        ,filter(S,gestation==1) %>%
          select(
            subject_id,preg_e,termin_e,termin_l,preg_l,gestation,termination
          ) %>%
          mutate(gestation_n=1)
        ,filter(S,gestation==2) %>%
          select(
            subject_id,preg_e,termin_e,termin_l,preg_l,gestation,termination
          ) %>%
          mutate(gestation_n=1)
        ,filter(S,gestation==2) %>%
          select(
            subject_id,preg_e2,termin_e2,termin_l2,preg_l,gestation,termination
          ) %>%
          rename(preg_e=preg_e2,termin_e=termin_e2,termin_l=termin_l2) %>%
          mutate(gestation_n=2)
      ) %>%
      
      # If no termination for a pregnancy period of a subject,
      # then label the period as having censored outcome.
      mutate(censoring=is.na(termin_l)) %>%
      
      # Join to the target population data and arranged by subject_id
      left_join(
        S %>%
          select(
            -preg_e
            ,-termin_e
            ,-termin_l
            ,-preg_e2
            ,-termin_e2
            ,-termin_l2
            ,-preg_l
            ,-gestation
            ,-termination
          )
        ,by='subject_id'
      ) %>%
      arrange(
        factor(subject_id,S$subject_id %>% .[!duplicated(.)])
      )
    
  }) %>%
  .[[1]]
```

```{r table-C2, eval=FALSE, include=FALSE}
# Save termination codes as CSV
readRDS('data/termination_codes.rds') %>%
  
  # By manual inspection, check the termination codes.
  select(code,desc) %>%
  filter(!duplicated(.)) %>%
  arrange(code) %>%
  
  # Save for Table C2.
  rename(description=desc) %>%
  setNames(str_to_title(colnames(.))) %>%
  write_csv('data/table_C2.csv')
```

```{r Outcome before correcting the code assignment, eval=FALSE, include=FALSE}
public$outcome0=
  
  # Filter visits from the target population only.
  public$visits %>%
  # filter(subject_id %in% public$target_population$subject_id) %>%
  
  # Extract outcome, which is P05
  extract_outcome(
    icd10_event='O365|P05'#|P07[0-1]|Z364'
    ,latest_event=min
    ,day_to_event=0
    ,icd10_nonevent=''
    ,latest_nonevent=max
    ,day_to_nonevent=0
    ,verbose=1
  ) %>%
  
  # Join the pregnancy status data to the outcome data.
  left_join(public$pregnancy_status,by='subject_id') %>%
  
  # If non-event, the latest date should be 
  # the earliest date of the end of pregnancy.
  lapply(X=1,Y=.,function(X,Y){
    Z=Y %>%
      filter(!censoring & outcome=='nonevent') %>%
      mutate(latest_date=termin_e)
    K=Y %>%
      filter(!(!censoring & outcome=='nonevent'))
    rbind(Z,K) %>%
      arrange(factor(subject_id,unique(Y$subject_id)))
  }) %>%
  .[[1]] %>%
  
  # Get only column to filter visits before the outcome 
  # for each pregnancy episode.
  select(subject_id,latest_date,outcome,censoring,gestation_n)
```

The outcome, which are any codes prefixed by P05, are ideally assigned to the 
children. However, in our dataset, these codes may be mistakenly assigned to 
the mothers. To solve this problem, first, we split subjects with these codes 
into those aged 2 years or less and those aged 12 to 55 years. For the children 
group, we identified the family identifiers and filter the 12-to-55 female(s) 
in each of the families. All of the families only consisted of 1-2 adult 
females, while those with 2 females were not possible to determine which one 
was the mother. Another female may be the older female sibling, the 
grandmother, and another relative. We exclude any female in this kind of 
family. Therefore, we only selected two groups of event subjects: 1) mothers 
assigned with any P05-prefixed codes had these should be assigned to her child; 
and 2) mothers of the children assigned with the codes from families in which 
the mother in each family is the only 12-to-55-year-old female. The nonevent 
subjects are the remaining within the target population.

```{r Identify outcome code assigned to children, eval=FALSE, include=FALSE}
public$child=
  public$subject %>%
  filter(subject_id%in%filter(public$outcome0,outcome=='event')$subject_id) %>%
  mutate(age=as.duration(as.Date('2016-12-31')-birth_date)/dyears()) %>%
  filter(age<=2)
```

```{r Show age distribution of the children, eval=FALSE, include=FALSE}
public$child %>%
  pull(age) %>%
  ecdf() %>%
  plot()
```

```{r Identify outcome code assigned to mothers, eval=FALSE, include=FALSE}
public$mother=
  public$subject %>%
  filter(subject_id%in%filter(public$outcome0,outcome=='event')$subject_id) %>%
  mutate(age=as.duration(as.Date('2016-12-31')-birth_date)/dyears()) %>%
  filter(age>12 & age<=55)
```

```{r Show age distribution of the mothers, eval=FALSE, include=FALSE}
public$mother %>%
  pull(age) %>%
  ecdf() %>%
  plot()
```

```{r Mothers of the children coded by outcome, eval=FALSE, include=FALSE}
# All families, including only the adult females
public$family=
  public$subject %>%
  filter(
    householder_id%in%public$child$householder_id
    & sex=='female'
  ) %>%
  mutate(age=as.duration(as.Date('2016-12-31')-birth_date)/dyears()) %>%
  filter(age>12 & age<=55)

# All of the families where the females are the only ones
public$family1=
  public$family %>%
  group_by(householder_id) %>%
  summarize(n=n(),.groups='drop') %>%
  arrange(desc(n)) %>%
  filter(n==1)

# All of the families where the females are many
public$family2=
  public$family %>%
  group_by(householder_id) %>%
  summarize(n=n(),.groups='drop') %>%
  arrange(desc(n)) %>%
  filter(n>1)
```

```{r Identify the structure with many females, eval=FALSE, include=FALSE}
public$family %>%
  filter(householder_id%in%public$family2$householder_id) %>%
  select(subject_id,householder_id,birth_date,age,family_status,everything()) %>%
  arrange(householder_id) %>%
  kable() %>%
  kable_classic()
```

```{r Show age of the family with single female, eval=FALSE, include=FALSE}
public$family %>%
  filter(householder_id%in%public$family1$householder_id) %>%
  pull(age) %>%
  ecdf() %>%
  plot()
```

```{r Show age of the family with many females, eval=FALSE, include=FALSE}
public$family %>%
  filter(householder_id%in%public$family2$householder_id) %>%
  pull(age) %>%
  ecdf() %>%
  plot()
```

```{r Show status-wise age of many-female family, eval=FALSE, include=FALSE}
public$family %>%
  filter(householder_id%in%public$family2$householder_id) %>%
  lapply(X=unique(pull(.,family_status)),Y=.,function(X,Y){
    filter(Y,family_status==X) %>%
      pull(age) %>%
      ecdf() %>%
      plot(main=X)
  })
```

```{r Wife from many-female families, eval=FALSE, include=FALSE}
# All families, including only wife from many-female families
public$wife=
  public$subject %>%
  filter(
    householder_id%in%public$family2$householder_id
    & family_status=='wife'
  ) %>%
  mutate(age=as.duration(as.Date('2016-12-31')-birth_date)/dyears())

# All of the families where the wife is the only one
public$wife1=
  public$wife %>%
  group_by(householder_id) %>%
  summarize(n=n(),.groups='drop') %>%
  arrange(desc(n)) %>%
  filter(n==1)

# All of the families where the wife are many
public$wife2=
  public$wife %>%
  group_by(householder_id) %>%
  summarize(n=n(),.groups='drop') %>%
  arrange(desc(n)) %>%
  filter(n>1)
```

```{r Identify the structure with many wifes, eval=FALSE, include=FALSE}
public$wife %>%
  filter(householder_id%in%public$wife2$householder_id) %>%
  select(subject_id,householder_id,birth_date,age,family_status,everything()) %>%
  arrange(householder_id) %>%
  kable() %>%
  kable_classic()
```

```{r Outcome after correcting the code assignment, eval=FALSE, include=FALSE}
public$event_subject=
  rbind(
    public$mother
    ,public$family %>%
      filter(householder_id%in%public$family1$householder_id)
    ,public$wife %>%
      filter(householder_id%in%public$wife1$householder_id)
  )

public$outcome=
  public$outcome0 %>%
  filter(
    !(outcome=='event' & !subject_id%in%public$event_subject$subject_id)
  )
```

```{r Show event distribution target population, eval=FALSE, include=FALSE}
public$outcome0 %>%
  pull(outcome) %>%
  table(`all previous subjects`=.)

public$outcome %>%
  pull(outcome) %>%
  table(`after excluding ambigous subjects`=.)
```

```{r Determine target visits, eval=FALSE, include=FALSE}
public$target_visits=
  
  # Join the outcome data to the visit data.
  public$outcome %>%
  right_join(public$visits,by='subject_id') %>%
  select(visit_id, everything()) %>%
  
  # If the outcome is censored, take visits up to the outcome date.
  # Otherwise, take all visits.
  filter(!is.na(censoring)) %>%
  filter(censoring | (!censoring & admission_date<=latest_date)) %>%
  mutate(code=ifelse(is.na(code)|code=='','NA',code)) %>%
  
  # Take only codes that are available 
  # in all combinations of outcome and censoring status.
  lapply(X=1,Y=.,function(X,Y){
    Z=Y %>%
      select(outcome,censoring,code) %>%
      filter(!duplicated(.)) %>%
      mutate(count=1) %>%
      group_by(code) %>%
      summarize(count=sum(count)) %>%
      arrange(desc(count)) %>%
      filter(count==4) %>%
      pull(code)
    
    Y %>% filter(code%in%Z)
  }) %>%
  .[[1]] %>%
  
  # Take needed columns and make subject_id different 
  # between pregnancy episodes of the same subject.
  select(-censoring,-outcome,-latest_date) %>%
  unite(subject_id,subject_id,gestation_n,sep='.')
```

```{r Update related variables, eval=FALSE, include=FALSE}
# Take only subjects' outcome that are assigned to the target visits.
public$outcome2=
  public$outcome %>%
  unite(subject_id,subject_id,gestation_n,sep='.') %>%
  filter(subject_id%in%public$target_visits$subject_id)

# Take only subjects' pregnancy status that are assigned to the target visits.
public$pregnancy_status2=
  public$pregnancy_status %>%
  unite(subject_id,subject_id,gestation_n,sep='.') %>%
  filter(subject_id%in%public$target_visits$subject_id)

# Add more criterion to the target population.
public$target_population2=
  
  public$target_population %>%
  left_join(
    select(public$pregnancy_status,subject_id,gestation_n)
    ,by=c('subject_id')
  ) %>%
  unite(subject_id,subject_id,gestation_n,sep='.') %>%
  
  ##### before the latest date of event/non-event
  ##### and split if >1 pregnancies
  filter(subject_id%in%public$target_visits$subject_id) %>%
  lapply(X=1,Y=.,function(X,Y){
    # Record this step to the table of subject selection.
    step_desc='up to the latest date for uncensored and split if >1 pregnancies'
    readRDS('data/selection.rds') %>%
      filter(step!=step_desc) %>%
      rbind(
        data.frame(
          step=step_desc
          ,exc_visit=
            .$inc_visit[nrow(.)]
            -sum(public$target_visits$subject_id %in% Y$subject_id)
          ,inc_visit=sum(public$target_visits$subject_id %in% Y$subject_id)
          ,exc_subject=.$inc_subject[nrow(.)]-nrow(Y)
          ,inc_subject=nrow(Y)
        )
      ) %>%
      saveRDS('data/selection.rds')
    Y
  }) %>%
  .[[1]]
```

```{r Describe selection results for sanity check, eval=FALSE, include=FALSE}
readRDS('data/selection.rds') %>%
  kable() %>%
  kable_classic()
```

```{r Describe pregnancy status, eval=FALSE, include=FALSE}
public$pregnancy_status %>%
  
  # Summarize the number and proportion of subjects with 0 to 2 gestation.
  select(subject_id,gestation) %>%
  filter(!duplicated(.)) %>%
  group_by(gestation) %>%
  summarize(n=n(),.groups='drop') %>%
  mutate(p=n/sum(n)) %>%
  
  # Join to compare with the subjects' pregnancy status 
  # that are assigned to the target visits.
  left_join(
    public$pregnancy_status2 %>%
      separate(subject_id,c('subject_id','gestation_n'),sep='\\.') %>%
      select(subject_id,gestation) %>%
      filter(!duplicated(.)) %>%
      group_by(gestation) %>%
      summarize(n2=n(),.groups='drop') %>%
      mutate(p2=n2/sum(n2))
    ,by='gestation'
  ) %>%
  kable() %>%
  kable_classic()
```

```{r Describe outcome per pregnancy status, eval=FALSE, include=FALSE}
public$pregnancy_status %>%
  
  # Join the ourcome data to the pregnancy status data.
  left_join(public$outcome0,by=c('subject_id','gestation_n','censoring')) %>%
  
  # Summarize the number and proportion of subjects 
  # by combination of censoring status, outcome, and number of gestation.
  group_by(gestation_n,outcome,censoring) %>%
  summarize(n=n(),.groups='drop') %>%
  mutate(p=n/sum(n)) %>%
  
  # Join to compare with the subjects' pregnancy status 
  # that are assigned to the target visits.
  left_join(
    public$pregnancy_status2 %>%
      separate(subject_id,c('subject_id','gestation_n'),sep='\\.') %>%
      left_join(
        public$outcome2 %>%
          separate(subject_id,c('subject_id','gestation_n'),sep='\\.')
        ,by=c('subject_id','gestation_n','censoring')
      ) %>%
      mutate(gestation_n=as.numeric(gestation_n)) %>%
      group_by(gestation_n,outcome,censoring) %>%
      summarize(n2=n(),.groups='drop') %>%
      mutate(p2=n2/sum(n2))
    ,by=c('gestation_n','outcome','censoring')
  ) %>%
  kable() %>%
  kable_classic()
```

```{r Save selection results to RDS file, eval=FALSE, include=FALSE}
saveRDS(public$target_population2,'data/target_population.rds')
saveRDS(public$pregnancy_status2,'data/pregnancy_status.rds')
saveRDS(public$outcome2,'data/outcome.rds')
saveRDS(public$target_visits,'data/target_visits.rds')
saveRDS(public$annotation,'data/annotation.rds')
```

```{r Remove public data II after selection, eval=FALSE, include=FALSE}
rm(public)
```

## Data preprocessing

We conducted data preprocessing after defining the target population and 
sampling it retrospectively. Demographics were included as categorical 
variables for causal inference. Then, we applied systematic human learning, as 
described in the main text, to determine what were causal factors that can be 
inferred from our dataset. We also computed a number of days for a code in the 
latest encounter before the time of prediction, including those by codes as a 
causal factor.

```{r Load an outcome table, include=FALSE}
outcome=
  readRDS('data/outcome.rds') %>%
  left_join(
    readRDS('data/pregnancy_status.rds')
    ,by=c('subject_id','censoring')
  ) %>%
  rename(reghc_id=healthcare_id)
```

```{r Visits with categorical identity as additional variables, include=FALSE}
visit_cip=
  
  # Transform age into a categorical variable based on domain knowledge.
  outcome %>%
  mutate(
    age=case_when(
      ((latest_date-birth_date)/dyears(1))<20~'Too Young'
      ,(((latest_date-birth_date)/dyears(1))>=20 &
        ((latest_date-birth_date)/dyears(1))<=35)
       ~'Low Risk'
      ,((latest_date-birth_date)/dyears(1))>35~'Too Old'
      ,TRUE~'NA'
    )
  ) %>%
  
  # Select subject_id and all categorical variables (not medical history).
  select(subject_id,age,marital_status,insurance_class,occupation_segment) %>%
  gather(variable,value,-subject_id) %>%
  unite(desc,variable,value,sep='_') %>%
  mutate(desc=str_replace_all(desc,'_|-|\\s',' ')) %>%
  separate(desc,c('first_word','desc'),sep=' ',extra='merge') %>%
  mutate_at('first_word',str_to_sentence) %>%
  unite(desc,first_word,desc,sep=' ') %>%
  
  # Create a code for each category.
  lapply(X=1,Y=.,function(X,Y){
    select(.,desc) %>%
      filter(!duplicated(.)) %>%
      
      # Create a code for each categorical variable.
      mutate(code=sapply(desc,function(x){
        str_split(x,'\\s')[[1]] %>%
          substr(1,1) %>%
          paste(collapse='') %>%
          str_to_upper()
      })) %>%
      
      # For each code, assign number to non-single code.
      group_by(code) %>%
      mutate(code_seq=seq(n()),max_code_seq=n()) %>%
      ungroup() %>%
      unite(code2,code,code_seq,sep='',remove=F) %>%
      mutate(code=ifelse(max_code_seq==1,code,code2)) %>%
      
      # Save all categorical variables and the codes.
      select(code,desc) %>%
      saveRDS('data/cat_identity.rds')
    Y
  }) %>%
  .[[1]] %>%
  
  # Join the codes of the categorical variables.
  left_join(readRDS('data/cat_identity.rds'),by='desc') %>%
  
  # Join the target visits.
  left_join(
    readRDS('data/target_visits.rds') %>%
      select(-code) %>%
      mutate(seq=seq(nrow(.))) %>%
      select(seq,everything())
    ,by='subject_id'
  ) %>%
  
  # Select columns according to the standard for medhist.
  select(
    seq
    ,visit_id
    ,subject_id
    ,healthcare_id
    ,admission_date
    ,code
    ,db_start_date
  ) %>%
  
  # Add the categorical variables as if these are diagnosis/procedure codes 
  # of which dates are the dates of any codes in a visit of a subject.
  rbind(
    readRDS('data/target_visits.rds') %>%
      mutate(seq=seq(nrow(.))) %>%
      select(seq,everything())
  )
```

```{r Convenient sampling from an authoritative, include=FALSE}
# ACOG Practice Bulletin 227 https://pubmed.ncbi.nlm.nih.gov/33481528/
convenient_sampling=
  matrix(
    c('variable'
      ,'FGR-SGA' # Fetal Growth restriction and small for gestational age
      ,'PIH' # Pregnancy-induced hypertension
      ,'APS' # Anti-phospholipid syndrome
      ,'Cigarette smoking'
      ,'Illicit drug use'
      ,'Multiple pregnancy'
      ,'Cyclophosphamide'
      ,'Valproic acid'
      ,'Warfarin'
      ,'IAI'
      ,'Malaria'
      ,'Cytomegalovirus'
      ,'Rubella'
      ,'Toxoplasmosis'
      ,'Varicella'
      ,'Syphilis'
      ,'Trisomy 13'
      ,'Trisomy 18'
      ,'Placental mosaicism'
      ,'Congenital heart disease'
      ,'Single umbilical artery'
      ,'Gastroschisis'
      ,'Placental abruption'
      ,'Placental infarction'
      ,'Circumvallate placenta'
      ,'Chorioangioma'
      ,'Velamentous cord insertion'
      ,'Marginal cord insertion'
    )
    ,ncol=1,byrow=T
  ) %>%
  `colnames<-`(.[1,]) %>%
  .[-1,,drop=F] %>%
  as.data.frame()
```

```{r Snowball sampling results, include=FALSE}
dag=list()

# Take notes while applying systematic human learning 
# by snowball sampling based on the convenient sampling.
# Start: 2021/07/10
# End: 2021/07/21
dag$factor=
  matrix(
    c('dependent_factor','independent_factor','citation'
      
      ############### d0 ACOG Practice Bulletin 227
      ,'FGR-SGA','PIH','ACOG (2021)'
      ,'FGR-SGA','APS','ACOG (2021)'
      ,'FGR-SGA','Cigarette smoking','ACOG (2021)'
      # Drug and alcohol
      ,'FGR-SGA','Illicit drug use','ACOG (2021)'
      ,'FGR-SGA','Multiple pregnancy','ACOG (2021)'
      ,'FGR-SGA','Cyclophosphamide','ACOG (2021)'
      ,'FGR-SGA','Valproic acid','ACOG (2021)'
      ,'FGR-SGA','Warfarin','ACOG (2021)'
      ,'FGR-SGA','IAI','ACOG (2021)'
      ,'FGR-SGA','Malaria','ACOG (2021)'
      ,'FGR-SGA','Cytomegalovirus','ACOG (2021)'
      ,'FGR-SGA','Rubella','ACOG (2021)'
      ,'FGR-SGA','Toxoplasmosis','ACOG (2021)'
      ,'FGR-SGA','Varicella','ACOG (2021)'
      ,'FGR-SGA','Syphilis','ACOG (2021)'
      ,'FGR-SGA','Trisomy 13','ACOG (2021)'
      ,'FGR-SGA','Trisomy 18','ACOG (2021)'
      ,'FGR-SGA','Placental mosaicism','ACOG (2021)'
      ,'FGR-SGA','Congenital heart disease','ACOG (2021)'
      ,'FGR-SGA','Single umbilical artery'
           ,'ACOG (2021); Murphy-Kaulbeck L, et al (2010)'
      ,'FGR-SGA','Gastroschisis','ACOG (2021)'
      ,'FGR-SGA','Placental abruption','ACOG (2021)'
      ,'FGR-SGA','Placental infarction','ACOG (2021)'
      ,'FGR-SGA','Circumvallate placenta','ACOG (2021)'
      ,'FGR-SGA','Chorioangioma','ACOG (2021)'
      ,'FGR-SGA','Velamentous cord insertion','ACOG (2021)'
      ,'FGR-SGA','Marginal cord insertion','ACOG (2021)'
      
      ############## A firstly from a1 PIH
      ,'FGR-SGA','Maternal age','Lean S, et al (2017)'
      ,'FGR-SGA','Obesity','Tanner LD, et al (2020)'
      ,'FGR-SGA','Cardiovascular disease','Manh TN, et al (2019)'
      ,'FGR-SGA','CKD','Wiles KS, et al (2018)'
      ,'FGR-SGA','SLE','Petri M (2020)'
      ,'FGR-SGA','Parity','Ciobanu A, et al (2019)'
      ,'FGR-SGA','High altitude','Grant I, et al (2021)'
      ,'FGR-SGA','Kidney transplantation','Cyganek A, et al (2014)'
      ,'FGR-SGA','Aspirin','Roberge S, et al (2017)'
      
      ############## A firstly from a3 Cigarette smoking
      ,'FGR-SGA','Low SES','Gaudineau A (2013)'
      ,'FGR-SGA','Race','Nasiri K, et al (2017)'
      ,'FGR-SGA','Low education','Black RE, et al (2018)'
      
      ############## A firstly from a4 Illicit drug use
      ,'FGR-SGA','Stress','Valsamakis G, et al (2019)'
      
      ############## A firstly from a5 Cyclophosphamide
      ,'FGR-SGA','Cancer metastasis','Hartnett KP, et al (2017)'
      
      ############## A firstly from a6 Valproic acid
      ,'FGR-SGA','Epilepsy','Viale L, et al (2015)'
      
      ############## A firstly from a8 IAI
      ,'FGR-SGA','UTI','Mazor-Dray E, et al (2009)'
      ,'FGR-SGA','GTI','Ashorn P, et al (2015); Vedmedovska N, et al (2010)'
      ,'FGR-SGA','Periodontal disease','Komine-Aizawa S, et al (2019)'
      # Up to December 31, 2019 to fit the context of our dataset 
      # and avoid confusion with pneumonia due to CoViD-19
      ,'FGR-SGA','Pneumonia','Romanyuk V, et al (2011)'
      
      ############## A firstly from a9 Malaria
      ,'FGR-SGA','Chloroquine prophylaxis','Leroux M, et al (2015)'
      
      ############## A firstly from a11 Rubella
      ,'FGR-SGA','Immunodeficiency','Cailhol J, et al (2009)'
      
      ############## A firstly from a21 Placental abruption
      ,'FGR-SGA','Anemia','Rahman MM, et al (2016)'
      ,'FGR-SGA','Marital status','Vedmedovska N, et al (2010)'
      ,'FGR-SGA','Miscarriage'
          ,'Vedmedovska N, et al (2010); Gunnarsdottir J, et al (2014)'
      ,'FGR-SGA','Placenta previa','Balayla J, et al (2019)'
      ,'FGR-SGA','Hyperhomocysteinemia'
          ,'Gaiday AN, et al (2018); Steegers-Theunissen RP, et al (2004)'
      ,'FGR-SGA','Thrombophilia','Simcox LE, et al (2015)'
      ,'FGR-SGA','Hypothyroidism','Tong Z, et al (2016)'
      ,'FGR-SGA','Uterine anomaly','Akhtar MA, et al (2020)'
      ,'FGR-SGA','Stillbirth','Malacova E, et al (2018)'
      ,'FGR-SGA','Fetal sex','Beaumann M, et al (2020)'
      
      ############## A firstly from a22 Placental infarction
      ,'FGR-SGA','Placental calcification','Mirza FG, et al (2018)'
      ,'FGR-SGA','Chronic villitis','Kim CJ, et al (2015)'
      
      ############## A firstly from a25 Velamentous cord insertion
      ,'FGR-SGA','Asthma','Ebbing C, et al (2013)'
      
      ############## A firstly from a29 Cardiovascular disease
      ,'FGR-SGA','Low HDL','Kallol S, et al (2020)'
      
      ############## A firstly from a31 SLE
      ,'FGR-SGA','Endometriosis','Bruun MR, et al (2018)'
      ,'FGR-SGA','Air pollution','Nobles CJ, et al (2019)'
      ,'FGR-SGA','Epstein-Barr virus infection','Tomai XH (2011)'
      ,'FGR-SGA','Pesticides','Snijder CA, et al (2012)'
      
      ############## A firstly from a43 GTI
      ,'FGR-SGA','Tuberculosis','Orazulike N, et al (2021)'
      
      ############## A firstly from a44 Periodontal disease
      ,'FGR-SGA','Anorexia nervosa','Micali N, et al (2016)'
      
      ############## A firstly from a46 Chloroquine prophylaxis
      ,'FGR-SGA','Travelling','Wang Y, et al (2019)'
      
      ############## A firstly from a47 Immunodeficiency
      ,'FGR-SGA','HIV','Dos Reis HL, et al (2015)'
      ,'FGR-SGA','Malnutrition','Black RE, et al (2018)'
      
      ############## A firstly from a48 Anemia
      ,'FGR-SGA','Schistosomiasis','Kurtis JD, et al (2011)'
      ,'FGR-SGA','Microangiopathy','Azzoug S, et al (2016)'
      ,'FGR-SGA','Sickle cell disease','Christensen T, et al (2020)'
      ,'FGR-SGA','Thalassemia','Sorrentino F, et al (2020)'
      ,'FGR-SGA','Iron deficiency','Georgieff MK (2020)'
      ,'FGR-SGA','Vitamin A deficiency','Chaparro CM, et al (2019)'
      ,'FGR-SGA','Chemotherapy','Abdalla N, et al (2017)'
      ,'FGR-SGA','Folate deficiency','Hovdenak N, et al (2012)'
      ,'FGR-SGA','Vitamin B12 deficiency','Hovdenak N, et al (2012)'
      
      ############## A firstly from a50 Miscarriage
      ,'FGR-SGA','Coeliac disease','Martinelli D, et al (2010)'
      ,'FGR-SGA','Androgens','Huang G, et al (2021)'
      ,'FGR-SGA','Short interpregnancy interval','van Eijsden M, et al (2002)'
      ,'FGR-SGA','Parvovirus B19','Waldorf KMA, et al (2013)'
      ,'FGR-SGA','Water pollution','Forand SP, et al (2012)'
      
      ############## A firstly from a59 Chronic villitis
      ,'FGR-SGA','Season','Fulford AJ, et al (2006)'
      
      ############## A firstly from a62 Endometriosis
      ,'FGR-SGA','Menarche age','Kaplanoglu M, et al (2015)'
      ,'FGR-SGA','Physical abuse','Janssen PA, et al (2003)'
      
      ############# A firstly from a64 Epstein-Barr virus infection
      ,'FGR-SGA','Low BMI','Sawant LD, et al (2013)'
      
      ############## A firstly from a75 Iron deficiency
      ,'FGR-SGA','Bariatric surgery','Chevrot A, et al (2016)'
      ,'FGR-SGA','Helicobacter pylori infection','Zhan Y, et al (2019)'
      
      ############## A firstly from a80 Coeliac disease
      ,'FGR-SGA','Sjögren syndrome','Elliott B, et al (2019)'
      ,'FGR-SGA','Turner syndrome','Church E, et al (2014)'
      ,'FGR-SGA','Williams syndrome','van der Tuuk K, et al (2007)'
      
      ############## A firstly from a83 Parvovirus B19
      ,'FGR-SGA','Daycare workers','Radauceanu A, et al (2020)'
      ,'FGR-SGA','Hemophilia','Togioka BM, et al (2021)'
      
      ############## A firstly from a88 Low BMI
      ,'FGR-SGA','Diet restriction','Masoumy EP, et al (2018)'
      
      ############## A firstly from a89 Bariatric surgery
      ,'FGR-SGA','Dyslipidemia','Paules C, et al (2020)'
      
      ############## A firstly from a91 Sjögren syndrome
      ,'FGR-SGA','Estrogen deficiency','Zou Z, et al (2021)'
      ,'FGR-SGA','Vitamin D deficiency','Yoon HK (2017)'
      
      ############## A firstly from a97 Dyslipidemia
      ################### START HERE
      ,'FGR-SGA','Antiretroviral therapy','Mohammadi H, et al (2018)'
      
      ############## A firstly from a99 Vitamin D deficiency
      ,'FGR-SGA','Low calcium intake','Hovdenak N, et al (2012)'
      ,'FGR-SGA','Low zinc intake','Terrin G, et al (2015)'
      
      ############## a1 PIH
      ############## A
      # Chronic hypertension, preeclampsia, and gestational hypertension
      ,'PIH','Obesity','Shah S, et al (2019); Tanner LD, et al (2020)'
      ,'PIH','Single umbilical artery','Murphy-Kaulbeck L, et al (2010)'
      ,'PIH','Placental abruption','Tikkanen M (2011)'
      
      # Chronic hypertension and preeclampsia
      ,'PIH','Maternal age','Shah S, et al (2019); Lean S, et al (2017)'
      ,'PIH','Velamentous cord insertion','Ebbing C, et al (2013)'
      ,'PIH','Marginal cord insertion','Ebbing C, et al (2013)'
      
      # Preeclampsia
      ,'PIH','CKD' # Chronic kidney disease
          ,'Shah S, et al (2019); Wiles KS, et al (2018)'
      ,'PIH','SLE' # Systemic lupus erythematous
          ,'Shah S, et al (2019); Petri M (2020)'
      ,'PIH','APS','Shah S, et al (2019)'
      ,'PIH','Parity','Shah S, et al (2019); Ciobanu A, et al (2019)'
      ,'PIH','High altitude','Shah S, et al (2019); Grant I, et al (2021)'
      ,'PIH','Kidney transplantation'
          ,'Shah S, et al (2019); Cyganek A, et al (2014)'
      ,'PIH','Aspirin','Shah S, et al (2019); Roberge S, et al (2017)'
      ,'PIH','Hyperhomocysteinemia'
          ,'Gaiday AN, et al (2018); Steegers-Theunissen RP, et al (2004)'
      ,'PIH','Thrombophilia','Simcox LE, et al (2015)'
      ,'PIH','Uterine anomaly','Akhtar MA, et al (2020)'
      ,'PIH','Chronic villitis','Kim CJ, et al (2015)'
      ,'PIH','Miscarriage','Gunnarsdottir J, et al (2014)'
      ,'PIH','Microangiopathy','Azzoug S, et al (2016)'
      ,'PIH','Helicobacter pylori infection','Zhan Y, et al (2019)'
      ,'PIH','Sjögren syndrome','Elliott B, et al (2019)'
      ,'PIH','Low calcium intake','Hovdenak N, et al (2012)'
      
      # Preeclampsia and gestational hypertension
      ,'PIH','Multiple pregnancy','Shah S, et al (2019)'
      
      ############### L
      # Preeclampsia
      ,'PIH','Pregestational DM','Shah S, et al (2019)' # Diabetes mellitus
      ,'PIH','Family history of preeclampsia'
          ,'Shah S, et al (2019); Serrano NC, et al (2020)'
      ,'PIH','Cardiovascular disease'
          ,'Shah S, et al (2019); Serrano NC, et al (2020)'
      ,'PIH','Nephrolithiasis','Shah S, et al (2019)'
      ,'PIH','History of kidney donation','Shah S, et al (2019)'
      
      # Preeclampsia and gestational hypertension
      ,'PIH','Prior history of preeclampsia','Shah S, et al (2019)'
      
      ############### a2 APS
      
      ############### a3 Cigarette smoking (from PROM study)
      ############### A
      ,'Cigarette smoking','Maternal age','De Genna NM, et al (2017)'
      ,'Cigarette smoking','Low SES','Najman JM, et al (1998)'
      ,'Cigarette smoking','Race','De Genna NM, et al (2017)'
      
      ############### L
      ,'Cigarette smoking','Pregnancy','Najman JM, et al (1998)'
      
      ############### a4 Illicit drug use (from PROM study)
      ############### A
      ,'Illicit drug use','Maternal age','Homsup P, et al (2018)'
      ,'Illicit drug use','Low SES','Marzban M, et al (2019)'
      ,'Illicit drug use','Cigarette smoking'
          ,'Oga EA, et al (2018); De Genna NM, et al (2017)'
      ,'Illicit drug use','Race','Homsup P, et al (2018)'
      ,'Illicit drug use','Low education','Homsup P, et al (2018)'
      ,'Illicit drug use','Stress','Rocha PC, et al (2016)'
      
      ############### a4 Multiple pregnancy (from PROM study
      ############### A
      ,'Multiple pregnancy','Maternal age'
          ,paste(
            'Thilaganathan B, and Khalil A (2014);'
            ,'Martin JA, and Osterman MJK (2019)'
          )
      ,'Multiple pregnancy','Race','Martin JA, and Osterman MJK (2019)'
      
      ############### L
      ,'Multiple pregnancy','Assisted reproduction'
          ,'Thilaganathan B, and Khalil A (2014)'
      
      ############### a5 Cyclophosphamide
      ############### A
      # Breast cancer brain metastasis & extranodal non-Hodgkin lymphoma
      ,'Cyclophosphamide','Cancer metastasis'
          ,'Fenner MH, et al (2002); Mertsoylu H, et al (2014)'
      
      ############### a6 Valproic acid
      ############### A
      ,'Valproic acid','Epilepsy','Tomson T, et al (2016)'
      
      ############### a7 Warfarin
      ############### A
      # Atrial fibrillation and valvular heart disease
      ,'Warfarin','Cardiovascular disease','Harter K, et al (2015)'
      
      ############### a8 IAI (from PROM study
      ############### A
      ,'IAI','Multiple pregnancy','Lee SM, et al (2020)'
      ,'IAI','Race','Menon R, et al (2011)'
      ,'IAI','Parity','Park KH, et al (2012)'
      ,'IAI','UTI','Tantengco OAG, et al (2019); Mazor-Dray E, et al (2009)'
      ,'IAI','GTI','Romero R, et al (2019); Tantengco OAG, et al (2019)'
      ,'IAI','Periodontal disease','Stinson LF, et al (2019)'
      ,'IAI','Pneumonia','Stinson LF, et al (2019)'
      
      ############### L
      ,'IAI','Cervical shortening','Kiefer DG, et al (2009)'
      
      ############### a9 Malaria
      ############### A
      ,'Malaria','Low SES','Essendi WM, et al (2019)'
      ,'Malaria','Low education','Essendi WM, et al (2019)'
      ,'Malaria','Chloroquine prophylaxis','Fried M, et al (2017)'
      
      ############### a10 Cytomegalovirus
      ############### A
      ,'Cytomegalovirus','Low SES','Naing ZW, et al (2016)'
      
      ############### a11 Rubella
      ############### A
      ,'Rubella','Immunodeficiency','Leung AKC, et al (2019)'
      
      ############### a12 Toxoplasmosis
      ############### A
      ,'Toxoplasmosis','Immunodeficiency','Borges M, et al (2019)'
      ,'Toxoplasmosis','Maternal age','Carellos EV, et al (2014)'
      ,'Toxoplasmosis','Low SES','Carellos EV, et al (2014)'
      ,'Toxoplasmosis','Low education','Carellos EV, et al (2014)'
      
      ############### a13 Varicella
      ############### A
      ,'Varicella','SLE','Gergianaki I, et al (2018)'
      
      ############### a14 Syphilis
      ############### A
      # Drug
      ,'Syphilis','Illicit drug use','Kwak J, et al (2015)'
      ,'Syphilis','Low SES','Kwak J, et al (2015)'
      
      ############### a15 Trisomy 13
      ############### A
      ,'Trisomy 13','Maternal age','De Souza E, et al (2009)'
      
      ############### a16 Trisomy 18
      ############### A
      ,'Trisomy 18','Maternal age','De Souza E, et al (2009)'
      
      ############### a17 Placental mosaicism
      ############### A
      ,'Placental mosaicism','Trisomy 13','Brison N, et al (2018)'
      ,'Placental mosaicism','Trisomy 18','Brison N, et al (2018)'
      
      ############### L
      ,'Placental mosaicism','Assisted reproduction','Margot H, et al (2018)'
      
      ############### a18 Congenital heart disease
      ############### A
      # Alcohol
      ,'Congenital heart disease','Illicit drug use','Sun R, et al (2015)'
      ,'Congenital heart disease','Rubella','Sun R, et al (2015)'
      
      ############### a19 Single umbilical artery
      ############### A
      ,'Single umbilical artery','Cigarette smoking'
          ,'Murphy-Kaulbeck L, et al (2010)'
      ,'Single umbilical artery','Multiple pregnancy'
          ,'Murphy-Kaulbeck L, et al (2010)'
      
      ############### L
      ,'Single umbilical artery','Prior history of FGR-SGA'
          ,'Murphy-Kaulbeck L, et al (2010)'
      ,'Single umbilical artery','Neurologic disease'
          ,'Murphy-Kaulbeck L, et al (2010)'
      
      ############### a20 Gastroschisis
      ############### A
      ,'Gastroschisis','Cigarette smoking','Frolov P, et al (2010)'
      # Drug and alcohol
      ,'Gastroschisis','Illicit drug use','Frolov P, et al (2010)'
      ,'Gastroschisis','Multiple pregnancy','Frolov P, et al (2010)'
      ,'Gastroschisis','Trisomy 13','Frolov P, et al (2010)'
      ,'Gastroschisis','Trisomy 18','Frolov P, et al (2010)'
      ,'Gastroschisis','Congenital heart disease','Frolov P, et al (2010)'
      ,'Gastroschisis','Obesity','Frolov P, et al (2010)'
      ,'Gastroschisis','Parity','Frolov P, et al (2010)'
      ,'Gastroschisis','Maternal age','Frolov P, et al (2010)'
      ,'Gastroschisis','Low SES','Frolov P, et al (2010)'
      ,'Gastroschisis','Race','Frolov P, et al (2010)'
      ,'Gastroschisis','GTI','Frolov P, et al (2010)'
      
      ############### L
      ,'Gastroschisis','Familial history of gastroschisis'
          ,'Frolov P, et al (2010)'
      
      ############### a21 Placental abruption
      ############### A
      ,'Placental abruption','Cigarette smoking'
          ,'Eubanks AA, et al (2021); Tikkanen M (2011)'
      # Drug and alcohol
      ,'Placental abruption','Illicit drug use','Tikkanen M (2011)'
      ,'Placental abruption','Multiple pregnancy','Tikkanen M (2011)'
      ,'Placental abruption','Single umbilical artery'
          ,'Murphy-Kaulbeck L, et al (2010)'
      ,'Placental abruption','Maternal age'
          ,paste0(
            'Lean S, et al (2017); '
            ,'Eubanks AA, et al (2021); '
            ,'Guo GL, et al (2018)'
            ,'Tikkanen M (2011)'
          )
      ,'Placental abruption','Race'
          ,'Eubanks AA, et al (2021); Tikkanen M (2011)'
      ,'Placental abruption','Parity','Tikkanen M (2011)'
      ,'Placental abruption','Velamentous cord insertion'
          ,'Tikkanen M (2011); Ebbing C, et al (2013)'
      ,'Placental abruption','Anemia','Guo GL, et al (2018); Tikkanen M (2011)'
      ,'Placental abruption','Marital status'
          ,'Anderson E, et al (2020); Tikkanen M (2011)'
      ,'Placental abruption','Miscarriage','Tikkanen M (2011)'
      ,'Placental abruption','Placenta previa','Anderson E, et al (2020)'
      ,'Placental abruption','Hyperhomocysteinemia'
          ,'Tikkanen M (2011); Steegers-Theunissen RP, et al (2004)'
      ,'Placental abruption','Thrombophilia'
          ,'Tikkanen M (2011); Simcox LE, et al (2015)'
      ,'Placental abruption','Hypothyroidism','Tikkanen M (2011)'
      ,'Placental abruption','Uterine anomaly','Tikkanen M (2011)'
      ,'Placental abruption','Stillbirth','Tikkanen M (2011)'
      ,'Placental abruption','Fetal sex','Tikkanen M (2011)'
      ,'Placental abruption','Circumvallate placenta','Suzuki S (2008)'
      ,'Placental abruption','Marginal cord insertion','Ebbing C, et al (2013)'
      
      # Chronic hypertension and preeclampsia
      ,'Placental abruption','PIH'
          ,'Guo GL, et al (2018); Anderson E, et al (2020); Tikkanen M (2011)'
      
      ############### L
      ,'Placental abruption','Assisted reproduction','Tikkanen M (2011)'
      ,'Placental abruption','Pregestational DM','Tikkanen M (2011)'
      ,'Placental abruption','Prior history of preeclampsia','Tikkanen M (2011)'
      ,'Placental abruption','APH','Anderson E, et al (2020)'
      ,'Placental abruption','Prior history of placental abruption'
          ,'Tikkanen M (2011)'
      ,'Placental abruption','Prior history of cesarean section'
          ,'Tikkanen M (2011)'
      
      ############### a22 Placental infarction
      ############### A
      ,'Placental infarction','Placental calcification'
          ,'Colley SM, et al (2013)'
      ,'Placental infarction','Chronic villitis','Colley SM, et al (2013)'
      
      ############### a23 Circumvallate placenta
      ############### A
      ,'Circumvallate placenta','Single umbilical artery'
          ,'Murphy-Kaulbeck L, et al (2010)'
      
      ############### L
      ,'Circumvallate placenta','Assisted reproduction'
          ,'Jauniaux E, et al (2020)'
      ,'Circumvallate placenta','Prior history of cesarean section'
          ,'Jauniaux E, et al (2020)'
      
      ############### a24 Chorioangioma
      
      ############### a25 Velamentous cord insertion
      ############### A
      ,'Velamentous cord insertion','Cigarette smoking','Ebbing C, et al (2013)'
      ,'Velamentous cord insertion','Maternal age','Ebbing C, et al (2013)'
      ,'Velamentous cord insertion','Parity','Ebbing C, et al (2013)'
      ,'Velamentous cord insertion','Single umbilical artery'
          ,'Murphy-Kaulbeck L, et al (2010)'
      ,'Velamentous cord insertion','Fetal sex','Ebbing C, et al (2013)'
      ,'Velamentous cord insertion','Asthma','Ebbing C, et al (2013)'
      
      ############### L
      ,'Velamentous cord insertion','Assisted reproduction'
          ,'Jauniaux E, et al (2020); Ebbing C, et al (2013)'
      ,'Velamentous cord insertion','Prior history of cesarean section'
          ,'Jauniaux E, et al (2020); Ebbing C, et al (2013)'
      ,'Velamentous cord insertion','APH','Ebbing C, et al (2013)'
      ,'Velamentous cord insertion','GDM','Ebbing C, et al (2013)'
      
      ############### a26 Marginal cord insertion
      ############### A
      ,'Marginal cord insertion','Maternal age','Ebbing C, et al (2013)'
      ,'Marginal cord insertion','Parity','Ebbing C, et al (2013)'
      ,'Marginal cord insertion','Single umbilical artery'
          ,'Murphy-Kaulbeck L, et al (2010)'
      ,'Marginal cord insertion','Fetal sex','Ebbing C, et al (2013)'
      ,'Marginal cord insertion','Asthma','Ebbing C, et al (2013)'
      
      ############### L
      ,'Marginal cord insertion','Assisted reproduction'
          ,'Ebbing C, et al (2013)'
      ,'Marginal cord insertion','Prior history of cesarean section'
          ,'Ebbing C, et al (2013)'
      ,'Marginal cord insertion','APH','Ebbing C, et al (2013)'
      ,'Marginal cord insertion','Pregestational DM','Ebbing C, et al (2013)'
      ,'Marginal cord insertion','GDM','Ebbing C, et al (2013)'
      ,'Marginal cord insertion','Multivitamin','Ebbing C, et al (2013)'
      
      ############### a27 Maternal age
      ############### A
      ,'Maternal age','Low education','Sauer MV, et al (2015)'
      
      ############### a28 Obesity
      ############### A
      ,'Obesity','Parity','Gaillard R, et al (2013)'
      ,'Obesity','Low SES','Gaillard R, et al (2013)'
      ,'Obesity','Low education','Gaillard R, et al (2013)'
      
      ############### a29 Cardiovascular disease
      ############### A
      ,'Cardiovascular disease','Cigarette smoking','Gill KS (2015)'
      ,'Cardiovascular disease','Obesity','Gill KS (2015)'
      ,'Cardiovascular disease','CKD','Webster AC, et al (2017)'
      ,'Cardiovascular disease','SLE','Gergianaki I, et al (2018)'
      ,'Cardiovascular disease','Maternal age','Gill KS (2015)'
      ,'Cardiovascular disease','Race','Gill KS (2015)'
      ,'Cardiovascular disease','Low HDL','Gill KS (2015)'
      
      ############### L
      ,'Cardiovascular disease','Pregestational DM','Gill KS (2015)'
      
      ############### a30 CKD
      ############### A
      ,'CKD','Low SES','Webster AC, et al (2017)'
      ,'CKD','Race','Webster AC, et al (2017)'
      
      # Chronic hypertension
      ,'CKD','PIH','Webster AC, et al (2017)'
      
      ############### L
      ,'CKD','Pregestational DM','Webster AC, et al (2017)'
      
      ############### a31 SLE
      ############### A
      ,'SLE','Cigarette smoking','Gergianaki I, et al (2018)'
      # Alcohol
      ,'SLE','Illicit drug use','Gergianaki I, et al (2018)'
      ,'SLE','Obesity','Gergianaki I, et al (2018)'
      ,'SLE','Maternal age','Gergianaki I, et al (2018)'
      ,'SLE','Low SES','Gergianaki I, et al (2018)'
      ,'SLE','Race','Gergianaki I, et al (2018)'
      ,'SLE','Endometriosis','Gergianaki I, et al (2018)'
      ,'SLE','Air pollution','Gergianaki I, et al (2018)'
      ,'SLE','Epstein-Barr virus infection','Gergianaki I, et al (2018)'
      ,'SLE','Pesticides','Gergianaki I, et al (2018)'
      
      ############### L
      ,'SLE','Prior history of FGR-SGA','Gergianaki I, et al (2018)'
      ,'SLE','Family history of SLE','Gergianaki I, et al (2018)'
      ,'SLE','Prior history of premature birth','Gergianaki I, et al (2018)'
      ,'SLE','Hormonal contraception','Guettrot-Imbert G, et al (2016)'
      
      ############### a32 Parity
      ############### A
      
      ############### L
      ,'Parity','Hormonal contraception','Cleland J, et al (2012)'
      
      ############### a33 High altitude
      ############### A
      ,'High altitude','Race','Azad P, et al (2017)'
      
      ############### a34 Kidney transplantation
      ############### A
      ,'Kidney transplantation','CKD','Huang Y, et al (2012)'
      
      ############### a35 Aspirin
      ############### A
      ,'Aspirin','Cardiovascular disease','Belhomme N, et al (2017)'
      ,'Aspirin','Miscarriage','Belhomme N, et al (2017)'
      
      ############### L
      ,'Aspirin','Prior history of FGR-SGA','Belhomme N, et al (2017)'
      ,'Aspirin','Prior history of preeclampsia','Belhomme N, et al (2017)'
      
      ############### a36 Low SES
      
      ############### a37 Race
      
      ############### a38 Low education
      
      ############### a39 Stress
      ############### A
      ,'Stress','Low SES','Schetter CD, et al (2012)'
      ,'Stress','Marital status','Schetter CD, et al (2012)'
      
      ############### a40 Cancer metastasis
      ############### A
      ,'Cancer metastasis','Obesity','Xu W, et al (2020)'
      ,'Cancer metastasis','Maternal age'
          ,'Jiang X, et al (2020); Shen L, et al (2020)'
      ,'Cancer metastasis','Cigarette smoking','Shen L, et al (2020)'
      ,'Cancer metastasis','CKD','Webster AC, et al (2017)'
      ,'Cancer metastasis','SLE','Gergianaki I, et al (2018)'
      
      ############### a41 Epilepsy
      ############### A
      ,'Epilepsy','Low SES','Thijs R, et al (2019)'
      ,'Epilepsy','Malaria','Thijs R, et al (2019)'
      
      ############### L
      ,'Epilepsy','Brain trauma','Thijs R, et al (2019)'
      ,'Epilepsy','Brain infection','Thijs R, et al (2019)'
      ,'Epilepsy','Brain tumor','Thijs R, et al (2019)'
      ,'Epilepsy','Neurocysticercosis','Thijs R, et al (2019)'
      ,'Epilepsy','Onchocerciasis','Thijs R, et al (2019)'
      
      ############### a42 UTI
      ############### A
      ,'UTI','SLE','Gergianaki I, et al (2018)'
      ,'UTI','Maternal age','Foxman B (2014)'
      ,'UTI','GTI','Foxman B (2014)'
      
      ############### L
      ,'UTI','Urinary catheterization','Foxman B (2014)'
      
      ############### a43 GTI (from PROM study
      ############### A
      ,'GTI','Tuberculosis','Sharma JB, et al (2018)'
      
      ############### L
      ,'GTI','Pregestational DM','Nichols GA, et al (2017)'
      
      ############### a44 Periodontal disease (from PROM study
      ############### A
      ,'Periodontal disease','Anemia','Genco RJ, and Borgnakke WS (2013)'
      ,'Periodontal disease','Low education','Genco RJ, and Borgnakke WS (2013)'
      ,'Periodontal disease','Maternal age','Genco RJ, and Borgnakke WS (2013)'
      ,'Periodontal disease','Cigarette smoking'
          ,'Genco RJ, and Borgnakke WS (2013)'
      ,'Periodontal disease','Stress','Genco RJ, and Borgnakke WS (2013)'
      ,'Periodontal disease','Asthma','Moraschini V, et al (2018)'
      ,'Periodontal disease','Anorexia nervosa','Chiba FY, et al (2019)'
      
      ############### L
      ,'Periodontal disease','Pregestational DM'
          ,'Genco RJ, and Borgnakke WS (2013)'
      ,'Periodontal disease','Allergy','Genco RJ, and Borgnakke WS (2013)'
      
      ############### a45 Pneumonia (from PROM study
      ############### A
      ,'Pneumonia','Asthma','Goodnight WH, and Soper DE (2005)'
      ,'Pneumonia','Anemia','Goodnight WH, and Soper DE (2005)'
      ,'Pneumonia','Varicella','Goodnight WH, and Soper DE (2005)'
      # From previous steps
      ,'Pneumonia','SLE','Gergianaki I, et al (2018)'
      
      ############### L
      # Up to December 31, 2019 to fit the context of our dataset 
      # and avoid confusion with pneumonia due to CoViD-19,
      # including when we search literatures about 
      # the effects of these factors on FGR-SGA
      ,'Pneumonia','Influenza','Goodnight WH, and Soper DE (2005)'
      ,'Pneumonia','Acute respiratory syndrome'
          ,'Goodnight WH, and Soper DE (2005)'
      
      ############### a46 Chloroquine prophylaxis
      ############### A
      ,'Chloroquine prophylaxis','Travelling','Steffen R, et al (1992)'
      
      ############### a47 Immunodeficiency
      ############### A
      ,'Immunodeficiency','HIV','Chinen J, et al (2010)'
      ,'Immunodeficiency','Malnutrition','Chinen J, et al (2010)'
      
      ############### L
      ,'Immunodeficiency','Glucocorticoid drugs','Chinen J, et al (2010)'
      
      ############### a48 Anemia
      ############### A
      ,'Anemia','CKD','Webster AC, et al (2017); Chaparro CM, et al (2019)'
      ,'Anemia','Malaria','Chaparro CM, et al (2019)'
      ,'Anemia','Malnutrition','Chaparro CM, et al (2019)'
      ,'Anemia','Schistosomiasis','Chaparro CM, et al (2019)'
      ,'Anemia','Microangiopathy','Chaparro CM, et al (2019)'
      ,'Anemia','Sickle cell disease','Chaparro CM, et al (2019)'
      ,'Anemia','Thalassemia','Chaparro CM, et al (2019)'
      ,'Anemia','Iron deficiency','Chaparro CM, et al (2019)'
      ,'Anemia','Vitamin A deficiency','Chaparro CM, et al (2019)'
      ,'Anemia','Chemotherapy','Chaparro CM, et al (2019)'
      ,'Anemia','Folate deficiency','Chaparro CM, et al (2019)'
      ,'Anemia','Vitamin B12 deficiency','Chaparro CM, et al (2019)'
      
      ############### L
      ,'Anemia','Prior history of postpartum hemorrhage'
          ,'Chaparro CM, et al (2019)'
      ,'Anemia','Menorrhagia','Chaparro CM, et al (2019)'
      ,'Anemia','Gastric ulcers','Chaparro CM, et al (2019)'
      ,'Anemia','Ancylostomiasis','Chaparro CM, et al (2019)'
      ,'Anemia','Hypersplenism','Chaparro CM, et al (2019)'
      ,'Anemia','G6PD deficiency','Chaparro CM, et al (2019)'
      
      ############### a49 Marital status
      ############### A
      ,'Marital status','Physical abuse','Berenson AB, et al (1991)'
      
      ############### a50 Miscarriage
      ############### A
      ,'Miscarriage','APS','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Cigarette smoking','García-Enguídanos A, et al (2002)'
      # Drug and alcohol
      ,'Miscarriage','Illicit drug use','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Maternal age','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Malaria','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Syphilis','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','HIV','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Air pollution','Simcox LE, et al (2015)'
      ,'Miscarriage','Hyperhomocysteinemia','Simcox LE, et al (2015)'
      ,'Miscarriage','Thrombophilia','Simcox LE, et al (2015)'
      ,'Miscarriage','Uterine anomaly'
          ,'Akhtar MA, et al (2020); García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Prior history of miscarriage'
          ,'García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Coeliac disease','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Androgens','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Short interpregnancy interval'
          ,'García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Parvovirus B19','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Water pollution'
          ,'Simcox LE, et al (2015); García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Endometriosis','Dai Y, et al (2018)'
      ,'Miscarriage','Helicobacter pylori infection','Zhan Y, et al (2019)'
      ,'Miscarriage','Turner syndrome','Mardy AH, et al (2020)'
      
      ############### L
      ,'Miscarriage','Pregestational DM','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Caffeine','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Prior history of delivery'
          ,'García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Chromosomal aberrations'
          ,'García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Oligomenorrhea','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','PCOS','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Sexual activity','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Maternal injury','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Lysteriosis','García-Enguídanos A, et al (2002)'
      ,'Miscarriage','Anesthetic gases'
          ,'Simcox LE, et al (2015); García-Enguídanos A, et al (2002)'
      
      ############### a51 Placenta previa
      ############### A
      ,'Placenta previa','Cigarette smoking','Shobeiri F, et al (2017)'
      # Drug
      ,'Placenta previa','Illicit drug use','Faiz AS, et al (2003)'
      ,'Placenta previa','Maternal age','Faiz AS, et al (2003)'
      ,'Placenta previa','Parity','Faiz AS, et al (2003)'
      ,'Placenta previa','Miscarriage','Faiz AS, et al (2003)'
      ,'Placenta previa','Fetal sex','Faiz AS, et al (2003)'
      ,'Placenta previa','Velamentous cord insertion','Ebbing C, et al (2013)'
      ,'Placenta previa','Marginal cord insertion','Ebbing C, et al (2013)'
      ,'Placenta previa','Endometriosis','Dai Y, et al (2018)'
      
      ############### L
      ,'Placenta previa','Prior history of delivery','Faiz AS, et al (2003)'
      ,'Placenta previa','Prior history of cesarean section'
          ,'Jauniaux E, et al (2020); Li X, et al (2019)'
      ,'Placenta previa','Assisted reproduction','Jauniaux E, et al (2020)'
      ,'Placenta previa','Anterior placenta','Li X, et al (2019)'
      
      ############### a52 Hyperhomocysteinemia
      ############### A
      ,'Hyperhomocysteinemia','CKD','Kim J, et al (2018)'
      ,'Hyperhomocysteinemia','Hypothyroidism','Kim J, et al (2018)'
      ,'Hyperhomocysteinemia','Anemia','Kim J, et al (2018)'
      ,'Hyperhomocysteinemia','Chemotherapy','Kim J, et al (2018)'
      
      ############### L
      ,'Hyperhomocysteinemia','Hormonal contraception','Kim J, et al (2018)'
      ,'Hyperhomocysteinemia','Malignant tumors','Kim J, et al (2018)'
      ,'Hyperhomocysteinemia','Cholestyramine','Kim J, et al (2018)'
      ,'Hyperhomocysteinemia','Metformin','Kim J, et al (2018)'
      ,'Hyperhomocysteinemia','Nicotinic acid','Kim J, et al (2018)'
      ,'Hyperhomocysteinemia','Fibric acid derivatives','Kim J, et al (2018)'
      
      ############### a53 Thrombophilia
      
      ############### a54 Hypothyroidism
      ############### A
      ,'Hypothyroidism','Obesity'
          ,'Jiang L, et al (2020); Tonstad S, et al (2013)'
      ,'Hypothyroidism','Maternal age','Jiang L, et al (2020)'
      # Chronic hypertension
      ,'Hypothyroidism','PIH','Jiang L, et al (2020)'
      ,'Hypothyroidism','Race','Tonstad S, et al (2013)'
      ,'Hypothyroidism','Low education','Tonstad S, et al (2013)'
      
      ############### L
      ,'Hypothyroidism','Lacto-ovo vegetarian','Tonstad S, et al (2013)'
      ,'Hypothyroidism','Hemithyroidectomy','Chotigavanich C, et al (2016)'
      
      ############### a55 Uterine anomaly
      ############### A
      ,'Uterine anomaly','Miscarriage'
          ,'Chan YY, et al (2011); Hooker AB, et al (2014)'
      
      ############### a56 Stillbirth
      ############### A
      # Chronic hypertension
      ,'Stillbirth','PIH','Reddy UM, et al (2010)'
      ,'Stillbirth','Cigarette smoking','Reddy UM, et al (2010)'
      # Alcohol
      ,'Stillbirth','Illicit drug use','Reddy UM, et al (2010)'
      ,'Stillbirth','Maternal age','Reddy UM, et al (2010)'
      ,'Stillbirth','Race','Reddy UM, et al (2010)'
      ,'Stillbirth','Parity','Reddy UM, et al (2010)'
      ,'Stillbirth','Obesity','Reddy UM, et al (2010)'
      ,'Stillbirth','Miscarriage','Gunnarsdottir J, et al (2014)'
      ,'Stillbirth','Prior history of cesarean section','Reddy UM, et al (2010)'
      
      ############### L
      ,'Stillbirth','Pregestational DM','Reddy UM, et al (2010)'
      
      ############### a57 Fetal sex
      
      ############### a58 Placental calcification
      ############### A
      ,'Placental calcification','Cigarette smoking','Brown HL, et al (1988)'
      
      ############### a59 Chronic villitis
      ############### A
      ,'Chronic villitis','Obesity','Boog B (2008)'
      ,'Chronic villitis','Parity','Boog B (2008)'
      ,'Chronic villitis','Race','Boog B (2008)'
      ,'Chronic villitis','Season','Freedman AA, et al (2020)'
      
      ############### a60 Asthma (from PROM study
      ############### A
      ,'Asthma','Varicella','Murphy VE, et al (2017)'
      
      ############### L
      ,'Asthma','Influenza','Murphy VE, et al (2017)'
      
      ############### a61 Low HDL
      
      ############### a62 Endometriosis
      ############### A
      ,'Endometriosis','Cigarette smoking','Dai Y, et al (2018)'
      ,'Endometriosis','Obesity'
          ,'Shafrir AL, et al (2018); Khan Z, et al (2017)'
      ,'Endometriosis','Race','Dai Y, et al (2018)'
      ,'Endometriosis','Parity','Khan Z, et al (2017)'
      ,'Endometriosis','GTI','Dai Y, et al (2018)'
      ,'Endometriosis','Water pollution','Dai Y, et al (2018)'
      ,'Endometriosis','Menarche age','Shafrir AL, et al (2018)'
      ,'Endometriosis','Physical abuse','Harris HR, et al (2018)'
      
      ############### L
      ,'Endometriosis','Vegetarian','Jurkiewicz-Przondziono J, et al (2017)'
      ,'Endometriosis','Short menstrual cycle','Shafrir AL, et al (2018)'
      
      ############### a63 Air pollution
      
      ############### a64 Epstein-Barr virus infection
      ############### A
      ,'Epstein-Barr virus infection','Cigarette smoking','Kuri A, et al (2020)'
      ,'Epstein-Barr virus infection','Race','Kuri A, et al (2020)'
      ,'Epstein-Barr virus infection'
          ,'Maternal age','Rostgaard K, et al (2019); Kuri A, et al (2020)'
      ,'Epstein-Barr virus infection','Low BMI','Kuri A, et al (2020)'
      
      ############### a65 Pesticides
      
      ############### a66 Tuberculosis (from PROM study
      ############### A
      ,'Tuberculosis','Race','Malhamé I, et al (2016)'
      ,'Tuberculosis','Low SES','Malhamé I, et al (2016)'
      ,'Tuberculosis','Asthma','Yii AC, et al (2019)'
      
      ############### L
      ,'Tuberculosis','Influenza','de Paus RA, et al (2013)'
      
      ############### a67 Anorexia nervosa (from PROM study
      
      ############### a68 Travelling
      
      ############### a69 HIV
      ############### A
      # Alcohol
      ,'HIV','Illicit drug use','Courtney LP, et al (2017)'
      ,'HIV','Maternal age','Serwadda D, et al (1992)'
      ,'HIV','Low education','Courtney LP, et al (2017)'
      ,'HIV','Parity','Humphrey JH, et al (2007)'
      ,'HIV','Marital status','Humphrey JH, et al (2007)'
      ,'HIV','Low SES','Humphrey JH, et al (2007)'
      
      ############### L
      ,'HIV','Multiple sexual partners','Courtney LP, et al (2017)'
      ,'HIV','Religion','Humphrey JH, et al (2007)'
      
      ############### a70 Malnutrition
      ############### A
      ,'Malnutrition','Maternal age','Regassa N, et al (2012)'
      ,'Malnutrition','Low SES'
          ,'Maehara M, et al (2019); Regassa N, et al (2012)'
      ,'Malnutrition','Low education'
          ,'Maehara M, et al (2019); Regassa N, et al (2012)'
      ,'Malnutrition','Marital status','Regassa N, et al (2012)'
      
      ############### a71 Schistosomiasis
      ############### A
      ,'Schistosomiasis','Maternal age','Murenjekwa W, et al (2021)'
      ,'Schistosomiasis','Low education','Murenjekwa W, et al (2021)'
      ,'Schistosomiasis','Parity','Mombo-Ngoma G, et al (2017)'
      ,'Schistosomiasis','Marital status','Murenjekwa W, et al (2021)'
      ,'Schistosomiasis','Season','Murenjekwa W, et al (2021)'
      
      ############### L
      ,'Schistosomiasis','Religion','Murenjekwa W, et al (2021)'
      
      ############### a72 Microangiopathy
      ############### A
      
      ############### L
      ,'Microangiopathy','Pregestational DM','Azzoug S, et al (2016)'
      
      ############### a73 Sickle cell disease
      
      ############### a74 Thalassemia
      
      ############### a75 Iron deficiency
      ############### A
      ,'Iron deficiency','Low SES','Cappellini MD, et al (2020)'
      ,'Iron deficiency','Coeliac disease','Cappellini MD, et al (2020)'
      ,'Iron deficiency','Bariatric surgery','Cappellini MD, et al (2020)'
      ,'Iron deficiency','Helicobacter pylori infection'
          ,'Cappellini MD, et al (2020)'
      
      ############### L
      ,'Iron deficiency','Vegetarian','Cappellini MD, et al (2020)'
      ,'Iron deficiency','Cereal diet','Cappellini MD, et al (2020)'
      ,'Iron deficiency','Atrophic gastritis','Cappellini MD, et al (2020)'
      ,'Iron deficiency','IBD','Cappellini MD, et al (2020)'
      ,'Iron deficiency','PPI','Cappellini MD, et al (2020)'
      
      ############### a76 Vitamin A deficiency
      ############### A
      ,'Vitamin A deficiency','Maternal age','Baytekus A, et al (2019)'
      ,'Vitamin A deficiency','Low SES','Baytekus A, et al (2019)'
      ,'Vitamin A deficiency','Low education','Baytekus A, et al (2019)'
      ,'Vitamin A deficiency','Malnutrition','Baytekus A, et al (2019)'
      
      ############### L
      ,'Vitamin A deficiency','NAFLD'
          ,'Godala M, et al (2017); Saeed A, et al (2017)'
      
      ############### a77 Chemotherapy
      ############### A
      ,'Chemotherapy','Cancer metastasis','Jacob SA, et al (2015)'
      
      ############### a78 Folate deficiency
      ############### A
      ,'Folate deficiency','Low SES','Bi Y, et al (2016)'
      ,'Folate deficiency','Race','Bi Y, et al (2016)'
      
      ############### L
      ,'Folate deficiency','Cereal diet','Bi Y, et al (2016)'
      
      ############### a79 Vitamin B12 deficiency
      ############### A
      ,'Vitamin B12 deficiency','Bariatric surgery','Langan RC, et al (2017)'
      
      ############### L
      ,'Vitamin B12 deficiency','Vegetarian'
          ,'Green R, et al (2017); Langan C, et al (2017)'
      ,'Vitamin B12 deficiency','IBD','Langan C, et al (2017)'
      ,'Vitamin B12 deficiency','PPI','Langan C, et al (2017)'
      ,'Vitamin B12 deficiency','Metformin','Langan C, et al (2017)'
      ,'Vitamin B12 deficiency','H2 blockers','Langan C, et al (2017)'
      
      ############### a80 Coeliac disease
      ############### A
      ,'Coeliac disease','Maternal age','Lindfors K, et al (2019)'
      ,'Coeliac disease','Low SES','Lindfors K, et al (2019)'
      ,'Coeliac disease','Hypothyroidism','Lindfors K, et al (2019)'
      ,'Coeliac disease','Sjögren syndrome'
          ,'Lindfors K, et al (2019); Elliot B, et al (2019)'
      ,'Coeliac disease','Turner syndrome','Lindfors K, et al (2019)'
      ,'Coeliac disease','Williams syndrome','Lindfors K, et al (2019)'
      
      ############### L
      ,'Coeliac disease','Pregestational DM','Lindfors K, et al (2019)'
      ,'Coeliac disease','Cereal diet','Lindfors K, et al (2019)'
      ,'Coeliac disease','Family history of coeliac disease'
          ,'Lindfors K, et al (2019)'
      ,'Coeliac disease','Selective IgA deficiency','Lindfors K, et al (2019)'
      ,'Coeliac disease','Down syndrome','Lindfors K, et al (2019)'
      ,'Coeliac disease','Addison disease','Lindfors K, et al (2019)'
      
      ############### a81 Androgens
      
      ############### a82 Short interpregnancy interval
      ############### A
      # Alcohol
      ,'Short interpregnancy interval','Illicit drug use'
          ,'Huber LRB, et al (2018)'
      ,'Short interpregnancy interval','Maternal age','Dedecker F, et al (2006)'
      ,'Short interpregnancy interval','Race','Huber LRB, et al (2018)'
      ,'Short interpregnancy interval','Low SES','Vandenbroucke L, et al (2013)'
      ,'Short interpregnancy interval','Parity'
          ,'Harney C, et al (2017); Dedecker F, et al (2006)'
      
      ############### L
      ,'Short interpregnancy interval','Hormonal contraception'
          ,'Vandenbroucke L, et al (2013)'
      ,'Short interpregnancy interval','Prior history of prenatal depression'
          ,'Backley S, et al (2020)'
      
      ############### a83 Parvovirus B19
      ############### A
      ,'Parvovirus B19','Maternal age','Reinheimer C, et al (2010)'
      ,'Parvovirus B19','Parity','Valeur-Jensen AK, et al (1999)'
      ,'Parvovirus B19','Immunodeficiency','Reinheimer C, et al (2010)'
      ,'Parvovirus B19','Daycare workers','Starke KR, et al (2019)'
      ,'Parvovirus B19','Hemophilia','Reinheimer C, et al (2010)'
      
      ############### L
      ,'Parvovirus B19','Malignant tumors','Reinheimer C, et al (2010)'
      
      ############### a84 Air pollution
      
      ############### a85 Season
      
      ############### a86 Menarche age
      ############### A
      ,'Menarche age','Obesity','Yermachenko A, et al (2017)'
      ,'Menarche age','Malnutrition','Yermachenko A, et al (2017)'
      
      ############### a87 Physical abuse
      ############### A
      ,'Physical abuse','Maternal age','Saminathan TA, et al (2019)'
      ,'Physical abuse','Cigarette smoking','Berenson AB, et al (1991)'
      # Drug and alcohol [Berenson AB, et al (1991)]
      ,'Physical abuse','Illicit drug use'
          ,'Saminathan TA, et al (2019); Berenson AB, et al (1991)'
      ,'Physical abuse','Low SES','Jonas KAWM, et al (2020)'
      ,'Physical abuse','Low education','Jonas KAWM, et al (2020)'
      ,'Physical abuse','Race'
          ,'Saminathan TA, et al (2019); Berenson AB, et al (1991)'
      
      ############### L
      ,'Physical abuse','Female nurses','Ceballos JB, et al (2020)'
      ,'Physical abuse','Female doctors','Kumari A, et al (2020)'
      ,'Physical abuse','Female caregivers','Karlsson ND, et al (2019)'
      
      ############### a88 Low BMI (from PROM study
      ############### A
      ,'Low BMI','Anorexia nervosa','Bjørnholt SM, et al (2019)'
      ,'Low BMI','Stress','Han YS, et al (2011)'
      
      ############### L
      ,'Low BMI','Diet restriction','Bjørnholt SM, et al (2019)'
      
      ############### a89 Bariatric surgery
      ############### A
      ,'Bariatric surgery','Obesity','Neff KJ, et al (2014)'
      # Chronic hypertension
      ,'Bariatric surgery','PIH','Neff KJ, et al (2014)'
      ,'Bariatric surgery','Dyslipidemia','Neff KJ, et al (2014)'
      
      ############### L
      ,'Bariatric surgery','Pregestational DM','Neff KJ, et al (2014)'
      
      ############### a90 Helicobacter pylori infection
      ############### A
      ,'Helicobacter pylori infection','Cigarette smoking'
          ,'Kotilea K, et al (2019)'
      ,'Helicobacter pylori infection','Low SES','Kotilea K, et al (2019)'
      
      ############### L
      ,'Helicobacter pylori infection','Vegetarian','Kotilea K, et al (2019)'
      
      ############### a91 Sjögren syndrome
      ############### A
      ,'Sjögren syndrome','Cigarette smoking','Björk A, et al (2020)'
      ,'Sjögren syndrome','Stress','Björk A, et al (2020)'
      ,'Sjögren syndrome','Pneumonia','Mofors J, et al (2019)'
      ,'Sjögren syndrome','UTI','Mofors J, et al (2019)'
      ,'Sjögren syndrome','GTI','Mofors J, et al (2019)'
      ,'Sjögren syndrome','Helicobacter pylori infection'
          ,'Björk A, et al (2020)'
      ,'Sjögren syndrome','Estrogen deficiency','Björk A, et al (2020)'
      ,'Sjögren syndrome','Vitamin D deficiency','Björk A, et al (2020)'
      
      ############### L
      ,'Sjögren syndrome','Influenza','Mofors J, et al (2019)'
      ,'Sjögren syndrome','Nontuberculous mycobacterial infection'
          ,'Björk A, et al (2020)'
      ,'Sjögren syndrome','Silicone breast implant','Björk A, et al (2020)'
      
      ############### a92 Turner syndrome
      
      ############### a93 Williams syndrome
      
      ############### a94 Daycare workers
      
      ############### a95 Hemophilia
      
      ############### a96 Diet restriction
      
      ############### a97 Dyslipidemia
      ############### A
      ,'Dyslipidemia','Cigarette smoking','Yang ZZ, et al (2018)'
      # Alcohol
      ,'Dyslipidemia','Illicit drug use','Yang ZZ, et al (2018)'
      ,'Dyslipidemia','Maternal age','Sun LQ, et al (2020)'
      # Chronic hypertension
      ,'Dyslipidemia','PIH','Yang ZZ, et al (2018)'
      ,'Dyslipidemia','Antiretroviral therapy','Sun LQ, et al (2020)'
      
      ############### L
      ,'Dyslipidemia','HBsAg positive','He H, et al (2019)'
      
      ############### a98 Estrogen deficiency
      ############### A
      
      ############### L
      ,'Estrogen deficiency','Functional hypothalamic amenorrhea'
          ,'Shufelt CL, et al (2017)'
      
      ############### a99 Vitamin D deficiency
      ############### A
      ,'Vitamin D deficiency','Maternal age','Nakhaee S, et al (2019)'
      ,'Vitamin D deficiency','Low calcium intake','Nakhaee S, et al (2019)'
      ,'Vitamin D deficiency','Low zinc intake','Gonoodi K, et al (2019)'
      
      ############### L
      ,'Vitamin D deficiency','Vegetarian','Craig WJ (2010)'
      
      ############### a100 Antiretroviral therapy
      ############### A
      ,'Antiretroviral therapy','HIV','Hoffman RM, et al (2019)'
      
      ############### a101 Low calcium intake
      ############### A
      
      ############### L
      ,'Low calcium intake','Vegetarian','Craig WJ (2010)'
      
      ############### a102 Low zinc intake
      ############### A
      
      ############### L
      ,'Low zinc intake','Vegetarian','Craig WJ (2010)'
      
      )
    ,ncol=3,byrow=T
  ) %>%
  `colnames<-`(.[1,]) %>%
  .[-1,] %>%
  as.data.frame()

# Make a common-cause table.
dag$common_cause$df=
  dag$factor %>%
  lapply(X=seq(sum(!duplicated(.$dependent_factor))-1)
         ,Y=pull(.,dependent_factor) %>% .[!duplicated(.)]
         ,Z=.,function(X,Y,Z){
    
    data.frame(V1=Y[X],V2=Y[(X+1):length(Y)]) %>%
      mutate(
        
        # Common causes
        V1_V2=sapply(X=seq(nrow(.)),Y=V1,Z=V2,K=Z,function(X,Y,Z,K){
          intersect(
              filter(K,dependent_factor==Y[X])$independent_factor
              ,filter(K,dependent_factor==Z[X])$independent_factor
            ) %>%
            paste(collapse=',')
        })
        
        # Causes of the first variable only
        ,V1_only=sapply(X=seq(nrow(.)),Y=V1,Z=V2,K=Z,function(X,Y,Z,K){
          setdiff(
              filter(K,dependent_factor==Y[X])$independent_factor
              ,filter(K,dependent_factor==Z[X])$independent_factor
            ) %>%
            paste(collapse=',')
        })
        
        # Causes of the second variable only
        ,V2_only=sapply(X=seq(nrow(.)),Y=V1,Z=V2,K=Z,function(X,Y,Z,K){
          setdiff(
              filter(K,dependent_factor==Z[X])$independent_factor
              ,filter(K,dependent_factor==Y[X])$independent_factor
            ) %>%
            paste(collapse=',')
        })
      )
  }) %>%
  do.call(rbind,.)

# Identify the unique common causes.
dag$common_cause$vec=
  unlist(lapply(dag$common_cause$df$V1_V2,str_split,pattern=',')) %>%
  .[.!='' & !duplicated(.)]

# Bind tables for the edges.
dag$baseline_edges=
  rbind(
    filter(dag$factor,dependent_factor=='FGR-SGA')
    ,filter(dag$factor,!dependent_factor%in%c('FGR-SGA')) %>%
      filter(independent_factor %in% dag$common_cause$vec)
  )

# Construct the nodes only.
dag$baseline_nodes=
  
  # Use either independent or dependent factor.
  c(dag$baseline_edges$dependent_factor
    ,dag$baseline_edges$independent_factor) %>%
  .[!duplicated(.)] %>%
  data.frame(name=.) %>%
  
  # Assign a code for each causal factor.
  `rownames<-`(str_pad(seq(nrow(.)),str_count(max(nrow(.))),'left','0')) %>%
  rownames_to_column(var='label') %>%
  
  # Apply different prefixes for outcome (Y), 
  # and the first (A) and second-level factors (L)
  mutate(
    label=
      paste0(
        case_when(
          name=='FGR-SGA'
          ~'Y'
          ,name %in%
           filter(dag$factor,dependent_factor=='FGR-SGA')$independent_factor
           ~'A'
          ,TRUE~'L'
        )
        ,label
      )
  ) %>%
  select(name,label)

# Construct the edges that connect the common causes to the effects.
dag$baseline_edges=
  dag$baseline_edges %>%
  left_join(
    setNames(dag$baseline_nodes,c('independent_factor','from'))
    ,by='independent_factor'
  ) %>%
  left_join(
    setNames(dag$baseline_nodes,c('dependent_factor','to'))
    ,by='dependent_factor'
  ) %>%
  select(from,to,citation)
```

```{r Show snowball sampling results, eval=FALSE, include=FALSE}
# Common cause table
dag$common_cause$df %>%
  kable() %>%
  kable_classic()

# Outcome with the first- and second-level factors
dag$baseline_nodes %>%
  kable() %>%
  kable_classic()

# All edges and the citations
dag$baseline_edges %>%
  left_join(
    dag$baseline_nodes %>%
      rename(from=label) %>%
      mutate(label=paste(from,name)) %>%
      select(from,label)
    ,by='from'
  ) %>%
  select(-from) %>%
  rename(from=label) %>%
  left_join(
    dag$baseline_nodes %>%
      rename(to=label) %>%
      mutate(label=paste(to,name)) %>%
      select(to,label)
    ,by='to'
  ) %>%
  select(-to) %>%
  rename(to=label) %>%
  select(from,to,everything()) %>%
  kable() %>%
  kable_classic()
```

```{r Determine measurement of causal factors, include=FALSE}
# Add measurement variables.
dag$measure_edges=
  dag$baseline_nodes %>%
  select(label) %>%
  rename(from=label) %>%
  mutate(to=paste0(from,'*'),citation=NA)

# Define components of each causal factor by ICD-10 coding.
dag$measure_nodes=
  dag$baseline_nodes %>%
  mutate(
    regex=case_when(
      name=='FGR-SGA'~'P05'
      ,name=='PIH'~'O1[013456]'
      ,name=='Valproic acid'~'T42[567]'
      ,name=='Warfarin'~'Z7901|T4551|D6832'
      ,name=='Malaria'~'B5[01234]'
      ,name=='Cytomegalovirus'~'B25'
      ,name=='Rubella'~'B06'
      ,name=='Toxoplasmosis'~'B58'
      ,name=='Syphilis'~'A5[0123]'
      ,name=='Trisomy 13'~'Q91[4567]'
      ,name=='Trisomy 18'~'Q91[0123]'
      ,name=='Placental mosaicism'~'O4389'
      ,name=='Congenital heart disease'~'Q2[01234]'
      ,name=='Single umbilical artery'~'Q270'
      ,name=='Gastroschisis'~'Q793'
      ,name=='Placental abruption'~'O45'
      ,name=='Placental infarction'~'O4381'
      ,name=='Circumvallate placenta'~'O4311'
      ,name=='Velamentous cord insertion'~'O4312'
      ,name=='Marginal cord insertion'~'O6989'
      ,name=='Obesity'~'E66'
      ,name=='Cardiovascular disease'
       ~'I1[01346]|I25|I3[4567]|I4[234589]|I50|I151[057]'
      ,name=='CKD'~'N18'
      ,name=='SLE'~'M32'
      ,name=='High altitude'~'T702|W940'
      ,name=='Kidney transplantation'~'Z940|Z482|T861'
      ,name=='Aspirin'~'Z7982|T3901'
      ,name=='Cancer metastasis'~'C7[789]'
      ,name=='Epilepsy'~'G40'
      ,name=='Immunodeficiency'~'D8[01234]'
      ,name=='Marital status'~'MSM'
      ,name=='Miscarriage'~'O03|N96'
      ,name=='Placenta previa'~'O44'
      ,name=='Hyperhomocysteinemia'~'E7211'
      ,name=='Hypothyroidism'~'E0[23]'
      ,name=='Stillbirth'~'P95|Z37[1347]'
      ,name=='Endometriosis'~'N80'
      ,name=='Epstein-Barr virus infection'~'B27'
      ,name=='HIV'~'B2[01234]|Z21'
      ,name=='Malnutrition'~'E4[0123456]'
      ,name=='Schistosomiasis'~'B65'
      ,name=='Microangiopathy'~'M311'
      ,name=='Iron deficiency'~'E611'
      ,name=='Vitamin A deficiency'~'E50'
      ,name=='Coeliac disease'~'K900'
      ,name=='Parvovirus B19'~'B343|B976|B083'
      ,name=='Menarche age'~'E30[01]'
      ,name=='Physical abuse'~'T7[46]|Z914'
      ,name=='Bariatric surgery'~'Z9884|Z980|K95'
      ,name=='Helicobacter pylori infection'~'B9681|K2970'
      ,name=='Sjögren syndrome'~'M350'
      ,name=='Dyslipidemia'~'E78[012345]'
      ,name=='Vitamin D deficiency'~'E55'
      ,name=='Low calcium intake'~'E58'
      ,name=='Low zinc intake'~'E60'
      ,name=='APS'~'D6861|D68312'
      ,name=='Chorioangioma'~'D267'
      ,name=='Thrombophilia'~'D68[56]'
      ,name=='Low HDL'~'E786'
      ,name=='Air pollution'~'Z77110|Z573'
      ,name=='Pesticides'~'T60'
      ,name=='Travelling'~'Z7184'
      ,name=='Sickle cell disease'~'D57'
      ,name=='Thalassemia'~'D56'
      ,name=='Water pollution'~'Z77111'
      ,name=='Turner syndrome'~'Q96'
      ,name=='Williams syndrome'~'Q9382'
      ,name=='Hemophilia'~'D6[67]|D68311'
      ,name=='Diet restriction'~'Z724|E639|F5082'
      
      ,name=='Chemotherapy'~'Z5111|Z9221|T451'
      
      #### From PROM study with modification
      # Drug and alcohol
      ,name=='Illicit drug use'~'F1[09]'
      ,name=='Anemia'~'D5[^467]|D6[0-4]'
      
      #### From PROM study without modification
      ,name=='Multiple pregnancy'~'O3[01]'
      ,name=='IAI'~'O41[89]'
      ,name=='GTI'~'914[139]|A6[03]|O23[59]|R87'
      ,name=='Periodontal disease'~'K05'
      ,name=='Pneumonia'~'J1[23458]'
      ,name=='Tuberculosis'~'A1[569]'
      ,name=='Asthma'~'J4[56]'
      ,name=='Low SES'~'THIRD|UNEMPLOYED'
      ,name=='Maternal age'~'TOO YOUNG|TOO OLD'
      ,name=='Uterine anomaly'~'Q51'
      ,name=='UTI'~'N390|O23[01249]'
      ,name=='Parity'~'Z641'
      ,name=='Anorexia nervosa'~'F500|R63[0346]'
      ,name=='Varicella'~'B01'
      
      
      # ################## L
      # #### From PROM study with modification\
      # # Pregestational DM
      # ,name=='Type-2 diabetes mellitus'~'E1[124]'
      # 
      # #### From PROM study without modification
      # ,name=='Assisted reproduction'~'Z31|N98'
      # ,name=='APH'~'O46'
      # ,name=='Influenza'~'J(00|09|10|11)'
      
      ,TRUE~''
    )
  ) %>%
  filter(regex!='') %>%
  lapply(X=seq(nrow(.)),Y=.,function(X,Y){
    data.frame(name=Y$regex[X],label=paste0(Y$label[X],'*'))
  }) %>%
  do.call(rbind,.)

# For each measurement variable, add unmeasured variable 
# as a factor that affects the measurement variable.
dag$measure_edges=
  dag$measure_edges %>%
  filter(to %in% dag$measure_nodes$label) %>%
  rbind(mutate(.,from=str_replace_all(from,'[:alpha:]','U')))

# Assign labels of measurement variables with the ICD-10 codes.
dag$measure_nodes %>%
  lapply(X=seq(nrow(.))
         ,Y=.
         ,Z=
           readRDS('data/cat_identity.rds') %>%
           rbind(readRDS('data/annotation.rds'))
         ,function(X,Y,Z){
    
    if(Y$label[X]%in%c('A19*','A20*')){
      K=Z %>%
        filter(!str_detect(str_to_upper(code),'[:digit:]')) %>%
        filter(str_detect(str_to_upper(desc),Y$name[X]))
    }else{
      K=Z %>% filter(str_detect(str_to_upper(code),Y$name[X]))
    }
    
    K %>%
      mutate(label=Y$label[X]) %>%
      select(label,code,desc)
    
  }) %>%
  do.call(rbind,.) %>%
  left_join(mutate(dag$baseline_nodes,label=paste0(label,'*')),by='label') %>%
  select(name,everything()) %>%
  kable() %>%
  kable_classic()
```

```{r Show all available data or measures, eval=FALSE, include=FALSE}
dag$measure_edges %>%
  kable() %>%
  kable_classic()
```

```{r Compute nationwide day interval of medical history, include=FALSE}
if(run_heavy_computation){
  mh_nationwide=
    readRDS('data/target_visits.rds') %>%
    mutate(healthcare_id='nationwide') %>%
    extract_medical_history(cl=detectCores()-1)
  saveRDS(mh_nationwide,'data/mh_nationwide.rds')
}else{
  cat(readRDS('data/log.rds')[['mh_nationwide']])
  mh_nationwide=readRDS('data/mh_nationwide.rds')
}

```

```{r Compute provider-wise day interval of medical history, include=FALSE}
if(run_heavy_computation){
  mh_provider=
    readRDS('data/target_visits.rds') %>%
    extract_medical_history(cl=detectCores()-1)
  saveRDS(mh_provider,'data/mh_provider.rds')
}else{
  cat(readRDS('data/log.rds')[['mh_provider']])
  mh_provider=readRDS('data/mh_provider.rds')
}
```

```{r Compute nationwide day interval of causal factor, include=FALSE}
if(run_heavy_computation){
  cf_nationwide=
    
    # Exclude outcome.
    dag$measure_nodes %>%
    filter(label!='Y001*') %>%
    
    # For each causal factor, filter rows with the codes related to the factor 
    # regardless the healthcare facilities.
    lapply(X=seq(nrow(.))
           ,Y=.
           ,Z=
             visit_cip %>%
             mutate(healthcare_id='nationwide') %>%
             left_join(
               readRDS('data/cat_identity.rds') %>%
                 rbind(annotation)
               ,by='code'
             )
           ,function(X,Y,Z){
      
      if(Y$label[X]%in%c('A027*','A046*','A084*')){
        K=Z %>%
          filter(!str_detect(str_to_upper(code),'[:digit:]')) %>%
          filter(str_detect(str_to_upper(desc),Y$name[X]))
      }else{
        K=Z %>% filter(str_detect(str_to_upper(code),Y$name[X]))
      }
      
      K %>%
        select(-desc) %>%
        mutate(
          code=
            Y$label[X] %>%
            str_remove_all('\\*')
        )
      
    }) %>%
    do.call(rbind,.) %>%
    filter(!duplicated(.)) %>%
    select(-seq) %>%
    
    # Extract the day intervals.
    extract_medical_history(cl=detectCores()-1) %>%
    filter(!duplicated(.)) %>%
    
    # Join to the target visits.
    right_join(
      readRDS('data/target_visits.rds') %>%
        select(-code) %>%
        mutate(healthcare_id='nationwide')
      ,by=c('visit_id'
            ,'subject_id'
            ,'healthcare_id'
            ,'admission_date'
            ,'db_start_date')
    ) %>%
    select(
      visit_id
      ,subject_id
      ,healthcare_id
      ,admission_date
      ,db_start_date
      ,everything()
    )
  
  saveRDS(cf_nationwide,'data/cf_nationwide.rds')
}else{
  cat(readRDS('data/log.rds')[['cf_nationwide']])
  cf_nationwide=readRDS('data/cf_nationwide.rds')
}
```

```{r Compute provider-wise day interval of causal factor, include=FALSE}
if(run_heavy_computation){
  cf_provider=
    
    # Exclude outcome.
    dag$measure_nodes %>%
    filter(label!='Y001*') %>%
    
    # For each causal factor, filter rows with the codes related to the factor 
    # in each of the healthcare facilities.
    lapply(X=seq(nrow(.))
           ,Y=.
           ,Z=
             visit_cip %>%
             left_join(
               readRDS('data/cat_identity.rds') %>%
                 rbind(annotation)
               ,by='code'
             )
           ,function(X,Y,Z){
      
      if(Y$label[X]%in%c('A027*','A046*','A084*')){
        K=Z %>%
          filter(!str_detect(str_to_upper(code),'[:digit:]')) %>%
          filter(str_detect(str_to_upper(desc),Y$name[X]))
      }else{
        K=Z %>% filter(str_detect(str_to_upper(code),Y$name[X]))
      }
      
      K %>%
        select(-desc) %>%
        mutate(
          code=
            Y$label[X] %>%
            str_remove_all('\\*')
        )
      
    }) %>%
    do.call(rbind,.) %>%
    filter(!duplicated(.)) %>%
    select(-seq) %>%
    
    # Extract the day intervals.
    extract_medical_history(cl=detectCores()-1) %>%
    filter(!duplicated(.)) %>%
    
    # Join to the target visits.
    right_join(
      readRDS('data/target_visits.rds') %>%
        select(-code)
      ,by=c('visit_id'
            ,'subject_id'
            ,'healthcare_id'
            ,'admission_date'
            ,'db_start_date')
    ) %>%
    select(
      visit_id
      ,subject_id
      ,healthcare_id
      ,admission_date
      ,db_start_date
      ,everything()
    )
  
  saveRDS(cf_provider,'data/cf_provider.rds')
}else{
  cat(readRDS('data/log.rds')[['cf_provider']])
  cf_provider=readRDS('data/cf_provider.rds')
}
```

```{r Sanity check for the number of visits and subjects, include=FALSE}
source('R/outcome_visit_subject-function.R')
```

```{r Show sanity check results, eval=FALSE, include=FALSE}
rbind(
    readRDS('data/target_visits.rds') %>%
      left_join(readRDS('data/outcome.rds'),by='subject_id') %>%
      outcome_visit_subject('original')
    
    ,mh_nationwide %>%
      left_join(readRDS('data/outcome.rds'),by='subject_id') %>%
      outcome_visit_subject('nationwide')
    
    ,mh_provider %>%
      left_join(readRDS('data/outcome.rds'),by='subject_id') %>%
      outcome_visit_subject('provider')
    
    ,cf_nationwide %>%
      left_join(readRDS('data/outcome.rds'),by='subject_id') %>%
      outcome_visit_subject('nationwide, causal')
    
    ,cf_provider %>%
      left_join(readRDS('data/outcome.rds'),by='subject_id') %>%
      outcome_visit_subject('provider, causal')
  ) %>%
  kable() %>%
  kable_classic()
```

```{r Build a function to personalize PROM tidy set, include=FALSE}
source('R/prom_tidyset_personalization-function.R')
```

## Data partition

To ensure all inference or derivation using training set only, we need to 
conduct data partition before continuing the downstream analysis. We described 
data partition for model validation in the main text (see Methods).

```{r Build a function to split for external validation, include=FALSE}
source('R/extv-function.R')
```

```{r Compile tidy sets followed by data partitioning, include=FALSE}
if(run_heavy_computation){
  
  # Nationwide data for inference by medical histories with splitting 
  # information for external validation
  inferdata=
    mh_nationwide %>%
    compile_mh_outcome(select(outcome,subject_id,latest_date,outcome)) %>%
    prom_tidyset_personalization(
      outcome=outcome
      ,experimenter=
        MIAME(
          name='Herdiantri Sufriyana'
          ,lab='Emily Chia-Yu Su Lab'
          ,contact='herdiantrisufriyana@unusa.ac.id'
          ,title='Medical history dataset for causal inference'
          ,abstract=
            str_replace_all(
              'This dataset is a medical-history table from the BPJS Kesehatan.
              The target population is health insurance holders of 
              12-to-55-years-old females who visit healthcare providers between 
              2015 and 2016. The outcome of interest is fetal growth 
              restriction and small for gestational age (FGR-SGA). The medical 
              history scenario is recorded across healthcare providers 
              nationwide.'
              ,'\n',' '
            ) %>%
            str_replace_all('\\s+',' ')
          ,url='https://github.com/herdiantrisufriyana/fgr_sga'
        )
      ,annotation=readRDS('data/annotation.rds')
    ) %>%
    extv(geo_p=0.2,tem_p=0.1,bgt_p=1,ran_p=0.2)
  saveRDS(inferdata,'data/inferdata.rds')
  
  # Provider-wise data for prediction by medical histories with splitting 
  # information for external validation
  predidata=
    mh_provider %>%
    compile_mh_outcome(select(outcome,subject_id,latest_date,outcome)) %>%
    prom_tidyset_personalization(
      outcome=outcome
      ,experimenter=
        MIAME(
          name='Herdiantri Sufriyana'
          ,lab='Emily Chia-Yu Su Lab'
          ,contact='herdiantrisufriyana@unusa.ac.id'
          ,title='Medical history dataset for prediction'
          ,abstract=
            str_replace_all(
              'This dataset is a medical-history table from the BPJS Kesehatan.
              The target population is health insurance holders of 
              12-to-55-years-old females who visit healthcare providers between 
              2015 and 2016. The outcome of interest is fetal growth 
              restriction and small for gestational age (FGR-SGA). The medical 
              history scenario is recorded individually within each healthcare 
              provider nationwide.'
              ,'\n',' '
            ) %>%
            str_replace_all('\\s+',' ')
          ,url='https://github.com/herdiantrisufriyana/fgr_sga'
        )
      ,annotation=readRDS('data/annotation.rds')
    ) %>%
    extv(geo_p=0.2,tem_p=0.1,bgt_p=1,ran_p=0.2)
  saveRDS(predidata,'data/predidata.rds')
  
  # Nationwide data for inference by causal factors with splitting information 
  # for external validation
  infercause=
    cf_nationwide %>%
    compile_mh_outcome(select(outcome,subject_id,latest_date,outcome)) %>%
    prom_tidyset_personalization(
      outcome=outcome
      ,experimenter=
        MIAME(
          name='Herdiantri Sufriyana'
          ,lab='Emily Chia-Yu Su Lab'
          ,contact='herdiantrisufriyana@unusa.ac.id'
          ,title='Medical history dataset for causal inference'
          ,abstract=
            str_replace_all(
              'This dataset is a medical-history table from the BPJS Kesehatan.
              The codes are re-assigned into causal factors (defined by regex).
              The target population is health insurance holders of 
              12-to-55-years-old females who visit healthcare providers between 
              2015 and 2016. The outcome of interest is fetal growth 
              restriction and small for gestational age (FGR-SGA). The medical 
              history scenario is recorded across healthcare providers 
              nationwide.'
              ,'\n',' '
            ) %>%
            str_replace_all('\\s+',' ')
          ,url='https://github.com/herdiantrisufriyana/fgr_sga'
        )
      ,annotation=
        dag$measure_nodes %>%
        mutate(label=str_remove_all(label,'\\*')) %>%
        rename(code=label,desc=name) %>%
        select(code,desc)
    ) %>%
    extv(geo_p=0.1,tem_p=0.1,bgt_p=1,ran_p=0.2)
  saveRDS(infercause,'data/infercause.rds')
  
  # Provider-wise data for prediction by causal factors with splitting 
  # information for external validation
  predicause=
    cf_provider %>%
    compile_mh_outcome(select(outcome,subject_id,latest_date,outcome)) %>%
    prom_tidyset_personalization(
      outcome=outcome
      ,experimenter=
        MIAME(
          name='Herdiantri Sufriyana'
          ,lab='Emily Chia-Yu Su Lab'
          ,contact='herdiantrisufriyana@unusa.ac.id'
          ,title='Medical history dataset for prediction'
          ,abstract=
            str_replace_all(
              'This dataset is a medical-history table from the BPJS Kesehatan.
              The codes are re-assigned into causal factors (defined by regex).
              The target population is health insurance holders of 
              12-to-55-years-old females who visit healthcare providers between 
              2015 and 2016. The outcome of interest is fetal growth 
              restriction and small for gestational age (FGR-SGA). The medical 
              history scenario is recorded individually within each healthcare 
              provider nationwide.'
              ,'\n',' '
            ) %>%
            str_replace_all('\\s+',' ')
          ,url='https://github.com/herdiantrisufriyana/fgr_sga'
        )
      ,annotation=
        dag$measure_nodes %>%
        mutate(label=str_remove_all(label,'\\*')) %>%
        rename(code=label,desc=name) %>%
        select(code,desc)
    ) %>%
    extv(geo_p=0.2,tem_p=0.1,bgt_p=1,ran_p=0.2)
  saveRDS(predicause,'data/predicause.rds')
  
}else{
  inferdata=readRDS('data/inferdata.rds')
  predidata=readRDS('data/predidata.rds')
  infercause=readRDS('data/infercause.rds')
  predicause=readRDS('data/predicause.rds')
}
```

```{r Show data partition, eval=FALSE, include=FALSE}
inferdata %>%
  lapply(X=1,Y=.,function(X,Y){
    
    # Use phenotype and protocol data.
    cbind(
        pData(phenoData(Y))
        ,pData(protocolData(Y))
      ) %>%
      separate(subject_id,c('subject_id','gestation_n'),sep='\\.') %>%
      select(gestation_n,outcome,censoring,geo,tem,bgt,ran,int) %>%
      gather(partition,value,-gestation_n,-outcome,-censoring) %>%
      filter(value) %>%
      
      # Summarize number of instances 
      # by outcome, censoring status, and partition.
      # mutate(
      #   outcome=as.character(outcome)
      #   ,outcome=ifelse(censoring,NA,outcome)
      # ) %>%
      group_by(
        gestation_n
        ,outcome
        ,censoring
      ,partition) %>%
      summarize(n=n(),.groups='drop') %>%
      
      # Compute the statistics.
      group_by(partition) %>%
      mutate(subtotal=sum(n)) %>%
      ungroup() %>%
      mutate(total=ncol(Y)) %>%
      mutate(p=subtotal/total) %>%
      
      # Wrap up.
      select(partition,subtotal,total,p) %>%
      filter(!duplicated(.)) %>%
      arrange(factor(partition,c('int','ran','geo','tem','bgt')))
  }) %>%
  .[[1]] %>%
  kable() %>%
  kable_classic()
```

## Causal inference

We conducted causal inference as described in the main text. This will help us 
to include only the confirmed causal factors as candidate predictors before 
conducting pre-selection of those candidates to fulfill quality control of 
predictors in the main text. We included causal factors of which the data were 
available in training set. Details on this information and ICD-10 codes or 
demographical variables for each candidate of causal factors are shown in the 
next section.

```{r Unified causal diagram (caugram) plot function, include=FALSE}
source('R/plot_dag-function.R')
```

```{r Show caugram, fig.height=42, fig.width=42, eval=FALSE, include=FALSE}
suppressWarnings(set.seed(33,sample.kind=sample.kind))
dag$baseline_edges[,-3] %>%
  plot_dag(0,mode='in',circular=T,plot.title='Causal diagram')
```

```{r Create interactive causal diagram, include=FALSE}
pre_causal_diagram=
  dag$baseline_edges[,-3] %>%
  
  # Join the node table as 'from'.
  left_join(
    dag$baseline_nodes %>%
      rename(from=label) %>%
      mutate(label=paste(from,name)) %>%
      select(from,label)
    ,by='from'
  ) %>%
  select(-from) %>%
  rename(from=label) %>%
  
  # Join the node table as 'to'.
  left_join(
    dag$baseline_nodes %>%
      rename(to=label) %>%
      mutate(label=paste(to,name)) %>%
      select(to,label)
    ,by='to'
  ) %>%
  select(-to) %>%
  rename(to=label)
```

```{r Show the interactive causal diagram, eval=FALSE, include=FALSE}
pre_causal_diagram %>%
  gather(key,id) %>%
  select(id) %>%
  filter(!duplicated(.)) %>%
  mutate(label=id) %>%
  arrange(id) %>%
  mutate(
    color=
      unlist(mapply(
        RColorBrewer::brewer.pal
        ,RColorBrewer::brewer.pal.info %>%
          .[.$category=='qual',] %>%
          .$maxcolors
        ,RColorBrewer::brewer.pal.info %>%
          .[.$category=='qual',] %>%
          rownames()
      ))[seq(nrow(.))]
  ) %>%
  visNetwork(
    pre_causal_diagram %>%
      mutate(arrows='to')
    ,width='100%'
    ,height=700
  ) %>%
  visIgraphLayout(
    layout='layout_as_tree'
    ,root='Y001 FGR-SGA'
    ,mode='in'
    ,circular=T
  )
```

```{r Construct binary data of training set for causal inference, include=FALSE}
if(run_heavy_computation){
  cf_nw_int_bin=
    infercause %>%
    .[,pData(protocolData(.))$int] %>%
    trans_binary(verbose=F)
  
  saveRDS(cf_nw_int_bin,'data/cf_nw_int_bin.rds')
}else{
  cf_nw_int_bin=readRDS('data/cf_nw_int_bin.rds')
}
```

```{r Prepare formula for causal inference, include=FALSE}
dag$formula$A002=
  outcome~
  A002+A005+A027
dag$backdoor$A002=c('A054','A082','A020','A022','A025','A026','A028','A029'
                    ,'A030','A031','A032','A033','A034','A035','A047','A049'
                    ,'A087','A051','A062','A075','A076','A080')

# dag$formula$A004=outcome~A004+A027+A084
# dag$backdoor$A004=c('A003','A085','A086','A036')

dag$formula$A005=outcome~A005+A027
dag$backdoor$A005=c('A085')

# dag$formula$A007=outcome~A007+A038
# dag$backdoor$A007=c()
# 
# dag$formula$A008=outcome~A008+A029
# dag$backdoor$A008=c()
# 
# dag$formula$A009=outcome~A009+A005+A032+A039+A040+A041+A042
# dag$backdoor$A009=c('A085')

dag$formula$A010=outcome~A010+A084
dag$backdoor$A010=c('A086','A043')

# dag$formula$A011=outcome~A011+A084
# dag$backdoor$A011=c()
# 
# dag$formula$A012=outcome~A012+A044
# dag$backdoor$A012=c()
# 
# dag$formula$A013=outcome~A013+A027+A084+A044
# dag$backdoor$A013=c('A086')

dag$formula$A014=outcome~A014
dag$backdoor$A014=c('A031')

# dag$formula$A015=outcome~A015+A004+A084
# dag$backdoor$A015=c()
# 
# dag$formula$A016=outcome~A016+A027
# dag$backdoor$A016=c()
# 
# dag$formula$A017=outcome~A017+A027
# dag$backdoor$A017=c()
# 
# dag$formula$A018=outcome~A018+A017+A016
# dag$backdoor$A018=c()
# 
# dag$formula$A019=outcome~A019+A012+A004
# dag$backdoor$A019=c()
# 
# dag$formula$A020=outcome~A020+A005
# dag$backdoor$A020=c('A003')
# 
# dag$formula$A021=outcome~A021+A019+A017+A016+A005+A004+A027+A028+A032+A084+A040
# dag$backdoor$A021=c('A003','A085')
# 
# dag$formula$A022=
#   outcome~
#   A022+A020+A005+A004+A002+A024+A025+A026+A027+A032+A045+A046+A047+A048+A049+
#   A087+A050+A051+A052
# dag$backdoor$A022=c('A003','A085','A088')
# 
# dag$formula$A023=outcome~A023
# dag$backdoor$A023=c('A053','A054')
# 
# dag$formula$A024=outcome~A024+A020
# dag$backdoor$A024=c()
# 
# dag$formula$A025=outcome~A025+A020+A027+A032+A055
# dag$backdoor$A025=c('A003','A088')
# 
# dag$formula$A026=outcome~A026+A020+A027+A032+A055
# dag$backdoor$A026=c('A003','A088')

dag$formula$A027=outcome~A027
dag$backdoor$A027=c('A086')

# dag$formula$A028=outcome~A028+A032+A084
# dag$backdoor$A028=c('A086')
# 
# dag$formula$A029=outcome~A029+A028+A027+A030+A031+A089
# dag$backdoor$A029=c('A003','A085')
# 
# dag$formula$A030=outcome~A030+A002+A084
# dag$backdoor$A030=c('A085')
# 
# dag$formula$A031=outcome~A031+A028+A027+A004+A084+A056+A090+A057+A091
# dag$backdoor$A031=c('A003','A085')
# 
# dag$formula$A032=outcome~A032
# dag$backdoor$A032=c()
# 
# dag$formula$A033=outcome~A033
# dag$backdoor$A033=c('A085')
# 
# dag$formula$A034=outcome~A034+A030
# dag$backdoor$A034=c()
# 
# dag$formula$A035=outcome~A035+A029+A047
# dag$backdoor$A035=c()
# 
# dag$formula$A035=outcome~A035+A029+A047
# dag$backdoor$A035=c()
# 
# dag$formula$A037=outcome~A037+A031+A030+A028+A027
# dag$backdoor$A037=c('A003')
# 
# dag$formula$A038=outcome~A038+A084+A010
# dag$backdoor$A038=c()

dag$formula$A039=outcome~A039+A027
dag$backdoor$A039=c('A031','A040')

# dag$formula$A040=outcome~A040+A058
# dag$backdoor$A040=c()
# 
# dag$formula$A041=outcome~A041+A027+A045+A055+A092
# dag$backdoor$A041=c('A036','A086','A003')
# 
# dag$formula$A042=outcome~A042+A031+A014+A045+A055
# dag$backdoor$A042=c()
# 
# dag$formula$A044=outcome~A044+A059+A060
# dag$backdoor$A044=c()
# 
# dag$formula$A045=outcome~A045+A030+A010+A060+A061+A062+A094+A095+A063+A064+A065
# dag$backdoor$A045=c('A066','A067')
# 
# dag$formula$A046=outcome~A046+A072
# dag$backdoor$A046=c()
# 
# dag$formula$A047=
#   outcome~
#   A047+A027+A015+A010+A004+A082+A049+A087+A051+A056+A090+A059+A068+A070+A097+
#   A075+A099
# dag$backdoor$A047=c('A003','A096','A069')

dag$formula$A048=outcome~A048+A027
dag$backdoor$A048=c('A003','A088','A047','A032','A026','A025','A004','A056')

# dag$formula$A049=outcome~A049+A045+A030+A050+A065
# dag$backdoor$A049=c()
# 
# dag$formula$A050=outcome~A050+A028+A027+A002
# dag$backdoor$A050=c('A086','A085')
# 
# dag$formula$A051=outcome~A051+A047
# dag$backdoor$A051=c()
# 
# dag$formula$A052=outcome~A052+A047+A032+A028+A027+A004+A002
# dag$backdoor$A052=c('A085','A003')
# 
# dag$formula$A055=outcome~A055+A014
# dag$backdoor$A055=c()
# 
# dag$formula$A056=outcome~A056+A040+A032+A028+A097+A071+A072
# dag$backdoor$A056=c('A085','A003')
# 
# dag$formula$A057=outcome~A057+A027
# dag$backdoor$A057=c('A085','A003','A073')
# 
# dag$formula$A058=outcome~A058+A055+A084
# dag$backdoor$A058=c('A085')
# 
# dag$formula$A059=outcome~A059+A046+A084+A032+A027+A004
# dag$backdoor$A059=c('A086')
# 
# dag$formula$A060=outcome~A060+A046+A084+A027
# dag$backdoor$A060=c('A086')
# 
# dag$formula$A061=outcome~A061+A046+A032+A027
# dag$backdoor$A061=c('A086','A098')
# 
# dag$formula$A062=outcome~A062
# dag$backdoor$A062=c()
# 
# dag$formula$A063=outcome~A063+A084+A068+A074+A075
# dag$backdoor$A063=c()
# 
# dag$formula$A064=outcome~A064+A060+A084+A027
# dag$backdoor$A064=c('A086')
# 
# dag$formula$A065=outcome~A065+A037
# dag$backdoor$A065=c()
# 
# dag$formula$A068=outcome~A068+A050+A084+A027+A076+A099+A100
# dag$backdoor$A068=c()
# 
# dag$formula$A070=outcome~A070+A044+A032+A027+A102
# dag$backdoor$A070=c('A101')
# 
# dag$formula$A071=outcome~A071+A060+A028
# dag$backdoor$A071=c()
# 
# dag$formula$A072=outcome~A072+A084+A027+A004
# dag$backdoor$A072=c('A086','A085','A003')
# 
# dag$formula$A074=outcome~A074+A028+A002+A077
# dag$backdoor$A074=c()
# 
# dag$formula$A075=outcome~A075+A084
# dag$backdoor$A075=c('A003')
# 
# dag$formula$A076=outcome~A076+A075+A042+A040+A039+A078
# dag$backdoor$A076=c('A036','A003','A104')
# 
# dag$formula$A077=outcome~A077+A027+A004+A002
# dag$backdoor$A077=c('A003','A079')
# 
# dag$formula$A078=outcome~A078+A027+A080+A081
# dag$backdoor$A078=c('A003')
# 
# dag$formula$A080=outcome~A080
# dag$backdoor$A080=c()
# 
# dag$formula$A081=outcome~A081
# dag$backdoor$A081=c()
# 
# dag$formula$A082=outcome~A082
# dag$backdoor$A082=c()
# 
# dag$formula$A083=outcome~A083
# dag$backdoor$A083=c()

dag$formula$A084=outcome~A084
dag$backdoor$A084=c()

# dag$formula$A087=outcome~A087
# dag$backdoor$A087=c()
# 
# dag$formula$A089=outcome~A089
# dag$backdoor$A089=c()
# 
# dag$formula$A090=outcome~A090
# dag$backdoor$A090=c()
# 
# dag$formula$A091=outcome~A091
# dag$backdoor$A091=c()
# 
# dag$formula$A092=outcome~A092
# dag$backdoor$A092=c()
# 
# dag$formula$A093=outcome~A093
# dag$backdoor$A093=c()
# 
# dag$formula$A094=outcome~A094
# dag$backdoor$A094=c()
# 
# dag$formula$A095=outcome~A095
# dag$backdoor$A095=c()
# 
# dag$formula$A097=outcome~A097
# dag$backdoor$A097=c()
# 
# dag$formula$A099=outcome~A099
# dag$backdoor$A099=c()
# 
# dag$formula$A100=outcome~A100
# dag$backdoor$A100=c()
# 
# dag$formula$A102=outcome~A102
# dag$backdoor$A102=c()
# 
# dag$formula$A103=outcome~A103
# dag$backdoor$A103=c()
```

```{r Prepare unadjusted formula, include=FALSE}
dag$formula2=
  dag$formula %>%
  lapply(function(x){
    x=as.character(x)
    x[3]=str_split(x[3],' \\+ ')[[1]][1]
    paste0(x[2],x[1],x[3]) %>%
      as.formula()
  })
```

```{r Show an example of causal diagram for inference of a cause, include=FALSE}
source('R/backdoor_path-function.R')
```

```{r Causal DAG function and the resulting images, include=FALSE}
source('R/causal_dag-function.R')
caudag_img=
  dag$baseline_nodes %>%
  
  # Use only the first-level factors.
  filter(str_sub(label,1,1)=='A') %>%
  pull(label) %>%
  
  # For each factor, use it to make a causal diagram plot.
  lapply(causal_dag)
```

```{r The DAG, fig.height=3.46457, fig.width=3.46457, eval=FALSE, include=FALSE}
caudag_img
```

```{r Conduct logistic regression for causal inference, include=FALSE}
# Fit the logistic regression.
dag$glm=
  dag$formula %>%
  lapply(
    FUN=glm
    ,family=binomial(link='logit')
    ,data=
      cf_nw_int_bin %>%
      pData() %>%
      mutate(outcome=ifelse(censoring,NA,as.integer(outcome=='event'))) %>%
      select(outcome) %>%
      cbind(
        cf_nw_int_bin %>%
          exprs() %>%
          t() %>%
          as.data.frame()
      )
  )

dag$glm2=
  dag$formula2 %>%
  lapply(
    FUN=glm
    ,family=binomial(link='logit')
    ,data=
      cf_nw_int_bin %>%
      pData() %>%
      mutate(outcome=ifelse(censoring,NA,as.integer(outcome=='event'))) %>%
      select(outcome) %>%
      cbind(
        cf_nw_int_bin %>%
          exprs() %>%
          t() %>%
          as.data.frame()
      )
  )

# Compute the OR and the 95% CI.
dag$coef=
  dag$glm %>%
  lapply(tidy) %>%
  lapply(
    mutate
    ,OR=exp(estimate)
    ,OR_lb=exp(estimate-qnorm(0.975)*std.error)
    ,OR_ub=exp(estimate+qnorm(0.975)*std.error)
    ,Pr=OR/(1+OR)
    ,Pr_lb=OR_lb/(1+OR_lb)
    ,Pr_ub=OR_ub/(1+OR_ub)
  )

dag$coef2=
  dag$glm2 %>%
  lapply(tidy) %>%
  lapply(
    mutate
    ,OR=exp(estimate)
    ,OR_lb=exp(estimate-qnorm(0.975)*std.error)
    ,OR_ub=exp(estimate+qnorm(0.975)*std.error)
    ,Pr=OR/(1+OR)
    ,Pr_lb=OR_lb/(1+OR_lb)
    ,Pr_ub=OR_ub/(1+OR_ub)
  )
```

```{r Conduct IPW for causal inference based on the causal diagram, include=FALSE}
if(run_heavy_computation){
  cat('Conduct IPW for causal inference based on the causal diagram\n')
  cat('Started:',as.character(now()),'\n')
  
    dag$ipw=
      
      # Fit the IPW.
      dag$formula %>%
      lapply(
        FUN=ipw
        ,data=
          cf_nw_int_bin %>%
          pData() %>%
          mutate(outcome=ifelse(censoring,NA,as.integer(outcome=='event'))) %>%
          select(outcome) %>%
          cbind(
            cf_nw_int_bin %>%
              exprs() %>%
              t() %>%
              as.data.frame()
          )
        ,bootstrap=30
        ,state=33
        ,verbose=T
      ) %>%
      
      # Reduce the size of IPW object.
      lapply(function(x){
        x$data=NULL
        x$index=NULL
        x
      })
  
  cat('End:',as.character(now()))
  saveRDS(dag$ipw,'data/ipw.rds')
}else{
  cat(readRDS('data/log.rds')[['ipw']])
  dag$ipw=readRDS('data/ipw.rds')
}
```

```{r Conduct IPW using unadjusted formula, include=FALSE}
if(run_heavy_computation){
  cat('Conduct IPW using unadjusted formula\n')
  cat('Started:',as.character(now()),'\n')
  
    dag$ipw2=
      
      # Fit the IPW.
      dag$formula2 %>%
      lapply(
        FUN=ipw
        ,data=
          cf_nw_int_bin %>%
          pData() %>%
          mutate(outcome=ifelse(censoring,NA,as.integer(outcome=='event'))) %>%
          select(outcome) %>%
          cbind(
            cf_nw_int_bin %>%
              exprs() %>%
              t() %>%
              as.data.frame()
          )
        ,bootstrap=30
        ,state=33
        ,verbose=T
      ) %>%
      
      # Reduce the size of IPW object.
      lapply(function(x){
        x$data=NULL
        x$index=NULL
        x
      })
  
  cat('End:',as.character(now()))
  saveRDS(dag$ipw2,'data/ipw2.rds')
}else{
  cat(readRDS('data/log.rds')[['ipw2']])
  dag$ipw2=readRDS('data/ipw2.rds')
}
```

```{r Save significant causal covariates, include=FALSE}
dag$sig=
  lapply(X=1:2,Y=dag$coef,Z=dag$ipw,function(X,Y,Z){
    if(X==1){
      # Logistic regression
      sapply(Y,function(x){
        ifelse(
          between(1,round(x$OR_lb[2],4),round(x$OR_ub[2],4)) |
          is.na(x$OR[2])
          ,0,1
        )
      })
    }else{
      # IPW
      sapply(Z,function(x){
        ifelse(
          between(0,round(x$CI95_interval[1],4),round(x$CI95_interval[2],4)) |
          is.na(x$marginal_effect)
          ,0,1
        )
      })
    }
  }) %>%
  do.call(rbind,.) %>%
  `rownames<-`(c('glm','ipw'))

dag$sig2=
  lapply(X=1:2,Y=dag$coef2,Z=dag$ipw2,function(X,Y,Z){
    if(X==1){
      # Logistic regression
      sapply(Y,function(x){
        ifelse(
          between(1,round(x$OR_lb[2],4),round(x$OR_ub[2],4)) |
          is.na(x$OR[2])
          ,0,1
        )
      })
    }else{
      # IPW
      sapply(Z,function(x){
        ifelse(
          between(0,round(x$CI95_interval[1],4),round(x$CI95_interval[2],4)) |
          is.na(x$marginal_effect)
          ,0,1
        )
      })
    }
  }) %>%
  do.call(rbind,.) %>%
  `rownames<-`(c('glm2','ipw2'))
```

```{r Show significant causal covariates, eval=FALSE, include=FALSE}
dag$sig %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column(var='variable') %>%
  mutate_at(2:3,function(x)ifelse(x==1,'yes','no')) %>%
  left_join(rename(dag$baseline_nodes,variable=label),by='variable') %>%
  kable() %>%
  kable_classic()
```

```{r Show significant unadjusted covariates, eval=FALSE, include=FALSE}
dag$sig2 %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column(var='variable') %>%
  mutate_at(2:3,function(x)ifelse(x==1,'yes','no')) %>%
  left_join(rename(dag$baseline_nodes,variable=label),by='variable') %>%
  kable() %>%
  kable_classic()
```

```{r The causes, fig.height=10.5, fig.width=10.5, eval=FALSE, include=FALSE}
dag$baseline_edges[,-3] %>%
  filter(
    from %in% colnames(dag$sig)[dag$sig[2,]==1] &
    to %in% c('Y001',colnames(dag$sig)[dag$sig[2,]==1])
  ) %>%
  plot_dag(0,'Y001 FGR-SGA','all',T)
```

## Quality control of candidate predictors

All candidate predictors, including non-demographical causal factors, have 
non-zero variances (Table 8 in Supplemental Spreadsheet). There were 15 
candidate predictors fulfilling this criterion. We also showed in the same 
table that there are 10 candidate predictors without perfect separation.

```{r Combine selected causal factors and medical histories, include=FALSE}
# Nationwide data for inference by causal factors,
# confirmed by IPW, and by medical histories
inferboth=
  ExpressionSet(
    assayData=
      rbind(
        exprs(infercause) %>%
          .[colnames(dag$sig)[dag$sig['ipw',]==1],,drop=F] %>%
          `rownames<-`(paste0('causal_',rownames(.)))
        ,exprs(inferdata)
      )
    ,phenoData=phenoData(inferdata)
    ,featureData=
      rbind(
        fData(infercause) %>%
          .[colnames(dag$sig)[dag$sig['ipw',]==1],,drop=F] %>%
          `rownames<-`(paste0('causal_',rownames(.)))
        ,fData(inferdata)
      ) %>%
      AnnotatedDataFrame(varMetadata=fvarMetadata(inferdata))
    ,experimentData=
      MIAME(
        name='Herdiantri Sufriyana'
        ,lab='Emily Chia-Yu Su Lab'
        ,contact='herdiantrisufriyana@unusa.ac.id'
        ,title='Medical history dataset for causal inference'
        ,abstract=
          str_replace_all(
            'This dataset is a medical-history table from the BPJS Kesehatan.
            Selected causal factors, that is re-assigned by regex, are added.
            The target population is health insurance holders of 
            12-to-55-years-old females who visit healthcare providers between 
            2015 and 2016. The outcome of interest is fetal growth restriction 
            and small for gestational age (FGR-SGA). The medical history 
            scenario is recorded individually within each healthcare provider 
            nationwide.'
            ,'\n',' '
          ) %>%
          str_replace_all('\\s+',' ')
        ,url='https://github.com/herdiantrisufriyana/fgr_sga'
      )
    ,annotation=annotation(inferdata)
    ,protocolData=protocolData(inferdata)
  )

# Provider-wise data for prediction by causal factors,
# confirmed by IPW, and by medical histories
prediboth=
  ExpressionSet(
    assayData=
      rbind(
        exprs(predicause) %>%
          .[colnames(dag$sig)[dag$sig['ipw',]==1],,drop=F] %>%
          `rownames<-`(paste0('causal_',rownames(.)))
        ,exprs(predidata)
      )
    ,phenoData=phenoData(predidata)
    ,featureData=
      rbind(
        fData(predicause) %>%
          .[colnames(dag$sig)[dag$sig['ipw',]==1],,drop=F] %>%
          `rownames<-`(paste0('causal_',rownames(.)))
        ,fData(predidata)
      ) %>%
      AnnotatedDataFrame(varMetadata=fvarMetadata(predidata))
    ,experimentData=
      MIAME(
        name='Herdiantri Sufriyana'
        ,lab='Emily Chia-Yu Su Lab'
        ,contact='herdiantrisufriyana@unusa.ac.id'
        ,title='Medical history dataset for prediction'
        ,abstract=
          str_replace_all(
            'This dataset is a medical-history table from the BPJS Kesehatan.
            Selected causal factors, that is re-assigned by regex, are added.
            The target population is health insurance holders of 
            12-to-55-years-old females who visit healthcare providers between 
            2015 and 2016. The outcome of interest is fetal growth restriction 
            and small for gestational age (FGR-SGA). The medical history 
            scenario is recorded individually within each healthcare provider 
            nationwide.'
            ,'\n',' '
          ) %>%
          str_replace_all('\\s+',' ')
        ,url='https://github.com/herdiantrisufriyana/fgr_sga'
      )
    ,annotation=annotation(predidata)
    ,protocolData=protocolData(predidata)
  )
```

```{r Candidate predictors with non-zero variances, eval=FALSE, include=FALSE}
var_candidate_predictors=
  
  # Use only training set.
  prediboth %>%
  .[,pData(protocolData(.))$int] %>%
  
  # Get predictors and the outcome.
  lapply(X=1,Y=.,function(X,Y){
    exprs(Y) %>%
      t() %>%
      as.data.frame() %>%
      cbind(select(pData(Y),'outcome'))
  }) %>%
  .[[1]] %>%
  
  # Summarize a standard deviation for each predictor per outcome.
  select(outcome,everything()) %>%
  gather(key,value,-outcome) %>%
  group_by(key,outcome) %>%
  summarize(sd_value=sd(value,na.rm=T),.groups='drop') %>%
  arrange(factor(key,unique(key)),outcome) %>%
  spread(outcome,sd_value) %>%
  setNames(str_remove_all(names(.),'-')) %>% 
  arrange(factor(key,rownames(prediboth)[rownames(prediboth)%in%key]))
```

```{r Train-set-based NPS predictors excluding outcome leaker, include=FALSE}
# Select predictors without perfect separation problem.
if(run_heavy_computation){
  
  int_nps=
    prediboth %>%
    .[,pData(protocolData(.))$int] %>%
    extract_nps_mh() %>%
    arrange(factor(key,rownames(prediboth)[rownames(prediboth)%in%key]))
  
  saveRDS(int_nps,'data/int_nps.rds')
  
}else{
  int_nps=readRDS('data/int_nps.rds')
}

# Identify codes related to the end of pregnancy.
outcome_leaker=
  int_nps %>%
  left_join(rename(annotation,key=code),by='key') %>%
  filter(
    str_detect(
      str_to_lower(paste(key,desc))
      ,paste0(c(
        'abort'
        ,'deliver'
        ,'cesar'
        ,'labou?r\\s+'
        ,'natal'
        ,'postpartum'
        ,'terminat'
        ,'o0[0123]'
        ,'o152'
        ,'o364'
        ,'o63'
        ,'o7[02]'
        ,'o8[579]'
        ,'o90'
        ,'z3[79]'
      ),collapse='|')
    )
  ) %>%
  filter(!(
    str_detect(
      str_to_lower(paste(key,desc))
      ,paste0(c(
        'aborter'
        ,'ante'
        ,'peri'
        ,'delayed'
        ,'false'
        ,'failed'
        ,'prenatal'
        ,'threatened'
        ,'o311'
        ,'z351'
        ,'o600'
        ,'o96'
      ),collapse='|')
    ) &
    !str_detect(
      str_to_lower(key)
      ,paste0(c(
        'o0[34568]'
        ,'o15[12]'
        ,'o7[02]'
        ,'o8[79]'
      ),collapse='|')
    )
  )) %>%
  select(key,desc)

# Exclude the outcome-leaker codes.
int_nps_eol_p0=
  int_nps %>%
  left_join(
    outcome_leaker %>%
      select(key) %>%
      mutate(excluded=1)
    ,by='key'
  ) %>%
  filter(is.na(excluded)) %>%
  select(-excluded)
```

```{r table-C3, eval=FALSE, include=FALSE}
# Non-zero variance and no perfect separation
var_candidate_predictors %>%
  
  # Exclude predictors that do not exist in training set.
  filter(!(nonevent==0 & event==0)) %>%
  
  # Join predictors without perfect separation problem.
  left_join(
    prediboth %>%
      .[,pData(protocolData(.))$int] %>%
      extract_nps_mh() %>%
      arrange(factor(key,rownames(prediboth)[rownames(prediboth)%in%key])) %>%
      mutate(perfect_separation='No')
    ,by=c('key','nonevent','event')
  ) %>%
  mutate(
    perfect_separation=
      ifelse(is.na(perfect_separation),'Yes',perfect_separation)
  ) %>%
  
  # Join combined annotation tables of medical histories and causal factors.
  left_join(
    rename(annotation,key=code) %>%
      rbind(
        dag$baseline_nodes %>%
          mutate(label=paste0('causal_',label)) %>%
          rename(desc=name,key=label) %>%
          select(key,desc)
      )
    ,by='key'
  ) %>%
  rename(candidate_predictor=key,description=desc) %>%
  setNames(str_to_title(colnames(.)) %>% str_replace_all('_',' ')) %>%
  
  # Save for Table C3.
  write_csv('data/table_C3.csv')
```

We excluded the diagnosis/procedure codes that may leak the outcome information 
(Table 9 in Supplemental Spreadsheet). We only used the existing codes in the 
training set to determine outcome-leaker codes based on the previous codes for 
determining delivery or immediately after delivery care (Table 7 in 
Supplemental Spreadsheet). There were 1 code that may leak the outcome. All 
of them were also irredundant (Table 10 in Supplemental Spreadsheet), as 
described in the main text.

```{r table-C4, eval=FALSE, include=FALSE}
# Save outcome leakers
outcome_leaker %>%
  arrange(key) %>%
  rename(code=key,description=desc) %>%
  setNames(str_to_title(colnames(.))) %>%
  
  # Save for Table C4.
  write_csv('data/table_C4.csv')
```

```{r Correlations of candidate predictors, eval=FALSE, include=FALSE}
cor_predictors=
  
  # Use only training set.
  prediboth %>%
  .[,pData(protocolData(.))$int] %>%
  
  # Get predictors and the outcome.
  lapply(X=1,Y=.,function(X,Y){
    exprs(Y) %>%
      t() %>%
      as.data.frame() %>%
      cbind(select(pData(Y),'outcome'))
  }) %>%
  .[[1]] %>%
  
  # Get only predictors without perfect separation problem  
  # and not outcome leakers. 
  select(outcome,everything()) %>%
  mutate_all(function(x)ifelse(is.na(x),0,x)) %>%
  .[,int_nps_eol_p0$key] %>%
  
  # Compute inter-predictor Pearson correlation coefficients.
  cor()
```

```{r table-C5, eval=FALSE, include=FALSE}
# Save the correlation coefficients.
cor_predictors %>%
  as.data.frame() %>%
  rownames_to_column(var=' ') %>%
  
  # Save for Table C5.
  write_csv('data/table_C5.csv')
```


```{r Show the inter-predictor correlations, eval=FALSE, include=FALSE}
# Show the correlation coefficients if Pearson r>0.7.
cor_predictors %>%
  
  # Remove auto-correlations.
  as.data.frame() %>%
  rownames_to_column(var='first') %>%
  gather(second,pearson_correlation_r,-first) %>%
  filter(first!=second) %>%
  
  # Remove redundant correlations.
  mutate(pair=seq(nrow(.))) %>%
  gather(order,predictor,-pair,-pearson_correlation_r) %>%
  group_by(pair) %>%
  arrange(pair,predictor) %>%
  mutate(order=c('first','second')) %>%
  ungroup() %>%
  spread(order,predictor) %>%
  select(-pair) %>%
  filter(!duplicated(.)) %>%
  
  # Filter the high-correlated pair of predictors.
  filter(pearson_correlation_r>0.7) %>%
  
  # Join regular expression of the coding components of causal factors 
  # to check if the high-correlated pairs are due to these components.
  left_join(
    dag$baseline_nodes %>%
      mutate(label=paste0('causal_',label)) %>%
      rename(first=label) %>%
      select(first,name)
    ,by='first'
  ) %>%
  left_join(
    dag$measure_nodes %>%
      mutate(label=paste0('causal_',str_remove_all(label,'\\*'))) %>%
      rename(regular_expression=name,first=label) %>%
      select(first,regular_expression)
    ,by='first'
  )
```

```{r Exclude one code of each pair of collinearited predictors}
int_nps_eol_p=
  int_nps_eol_p0 %>%
  filter(!key%in%c('B019','N390'))
```

By systematic human learning and causal inference using available data, we also 
determined causal factors as the candidate predictors (Table 11 in Supplemental 
Spreadsheet). There were 27 first- and 10 second-level factors of PROM. Only 
data for 12 out of 27 causal factors were available in training set. Either the 
diagnosis/procedure codes, or demographical variables (not included as 
candidate predictors), for causal factors are also described (Table 12 in 
Supplemental Spreadsheet).

```{r table-C6, eval=FALSE, include=FALSE}
# Save results of systematic human learning
dag$baseline_nodes %>%
  
  # Get all the first-level factors.
  filter(name!='FGR-SGA') %>%
  
  # Pair with the effect.
  left_join(
    dag$factor %>%
      select(dependent_factor,independent_factor,citation) %>%
      rename(effect_on=dependent_factor,name=independent_factor)
    ,by='name'
  ) %>%
  rename(factor=name) %>%
  
  # Identify the factor levels.
  mutate(level=ifelse(str_detect(label,'A'),'First','Second')) %>%
  select(level,effect_on,everything()) %>%
  
  # Add information about the data availability.
  left_join(
    data.frame(label=rownames(cf_nw_int_bin),data_availability='Yes')
    ,by='label'
  ) %>%
  mutate(
    data_availability=
      ifelse(
        !is.na(data_availability) & effect_on=='FGR-SGA'
        ,'Yes','No'
      )
  ) %>%
  
  # Add information about the model (formula).
  left_join(
    dag$formula %>%
      lapply(X=names(.),Y=.,function(X,Y){
        Z=as.character(Y[[X]])
        data.frame(label=X,mathematical_model=paste0(Z[2],' ~ ',Z[3]))
      }) %>%
      do.call(rbind,.) %>%
      mutate(effect_on='FGR-SGA')
    ,by=c('label','effect_on')
  ) %>%
  
  # Save for Table C6.
  arrange(
    level
    ,factor(effect_on,dag$baseline_nodes$name)
    ,factor(factor,dag$baseline_nodes$name)
  ) %>%
  setNames(str_to_title(colnames(.)) %>% str_replace_all('_',' ')) %>%
  write_csv('data/table_C6.csv')
```

```{r table-C7, eval=FALSE, include=FALSE}
# Save codes and demographics for causal factors
dag$measure_nodes %>%
  
  # Get the regular expression to define causal factors.
  mutate(label=str_remove_all(label,'\\*')) %>%
  rename(regular_expression=name) %>%
  
  # Add the description.
  left_join(dag$baseline_nodes,by='label') %>%
  filter(label!='Y001') %>%
  mutate(label=paste0('causal_',label)) %>%
  rename(causal_factor=name,variable=label) %>%
  select(causal_factor,variable,regular_expression) %>%
  
  # Based on the regular expression, gather the ICD-10 codes that apply.
  lapply(X=seq(nrow(.)),Y=.,function(X,Y){
    
    Z=Y$regular_expression[X]
    
    if(str_detect(Z,'\\(|\\)')){
      
      K=str_split(Z,'\\(|\\)')[[1]]
      
      L=K[2] %>%
        str_split('\\|') %>%
        .[[1]] %>%
        sapply(X=seq(length(.)),Y=.,Z=K[1],function(X,Y,Z){
          paste0(Z,Y[X])
        })
      
    }else{
      
      K=str_split(Z,'\\|')[[1]]
      
      L=K %>%
        lapply(X=seq(length(.)),Y=.,function(X,Y){
          if(str_detect(Y[X],'\\[|\\]')){
            
            Z=str_split(Y[X],'\\[|\\]')[[1]]
            
            if(str_detect(Z[2],'\\^')){
              
              K=Z[2] %>%
                str_remove_all('\\^')
              
              paste0(0:9,collapse='') %>%
                str_remove_all(K) %>%
                sapply(X=seq(str_count(.)),Y=.,Z=Z[1],function(X,Y,Z){
                  paste0(Z,str_sub(Y,X,X))
                })
              
            }else if(str_detect(Z[2],'\\-')){
              
              K=Z[2] %>%
                str_split_fixed('\\-',2)
              
              paste0(K[1]:K[2],collapse='') %>%
                sapply(X=seq(str_count(.)),Y=.,Z=Z[1],function(X,Y,Z){
                  paste0(Z,str_sub(Y,X,X))
                })
              
            }else{
              
              Z[2] %>%
                sapply(X=seq(str_count(.)),Y=.,Z=Z[1],function(X,Y,Z){
                  paste0(Z,str_sub(Y,X,X))
                })
              
            }
            
          }else{
            
            Y[X]
            
          }
        }) %>%
        unlist()
      
    }
    
    data.frame(
      causal_factor=Y$causal_factor[X]
      ,variable=Y$variable[X]
      ,regular_expression=Y$regular_expression[X]
      ,code=L
    )
    
  }) %>%
  do.call(rbind,.) %>%
  select(-regular_expression) %>%
  
  # Add information related to demographics.
  lapply(
    X=seq(nrow(.))
    ,Y=.
    ,Z=
      annotation %>%
      rbind(
        readRDS('data/cat_identity.rds') %>%
          mutate(
            code=
              desc %>%
              str_to_lower() %>%
              sapply(
                str_remove_all
                ,paste0(
                  c('age'
                    ,'householder'
                    ,str_replace_all(colnames(outcome),'_',' '))
                  ,collapse='|'
                )
              ) %>%
              str_to_upper() %>%
              trimws()
          )
      )
    ,function(X,Y,Z){
    
      Z %>%
        filter(str_detect(code,Y$code[X])) %>%
        mutate(
          causal_factor=Y$causal_factor[X]
          ,variable=Y$variable[X]
        )
  }) %>%
  do.call(rbind,.) %>%
  
  # Save for Table C7.
  select(causal_factor,variable,everything()) %>%
  rename(demographics_or_medical_history=code,description=desc) %>%
  setNames(str_to_title(colnames(.)) %>% str_replace_all('_',' ')) %>%
  write_csv('data/table_C7.csv')
```

## Feature extraction as historical rates

We inferred the nationwide historical rates given the day number from a code 
encounter to current visit for each candidate predictor, as described in the 
main text. This used irredundant candidate predictors with non-zero variances 
and no perfect separation in training set only. The candidate predictors were 
transformed into the historical rates in all data partitions.

```{r Compute historical rate based on nationwide training set, include=FALSE}
if(run_heavy_computation){
  nw_int_hlin=
    inferboth %>%
    .[int_nps_eol_p$key
      ,pData(protocolData(.))$int] %>%
    trans_hist_rate(
      interpolation='linear'
      ,verbose=F
    )
  
  saveRDS(nw_int_hlin,'data/nw_int_hlin.rds')
}else{
  nw_int_hlin=readRDS('data/nw_int_hlin.rds')
}
```

```{r Use the nationwide rate to get it for whole prediction set, include=FALSE}
if(run_heavy_computation){
  pw_hlin=
    prediboth %>%
    .[int_nps_eol_p$key,] %>%
    trans_hist_rate(
      hist_rate=preproc(nw_int_hlin)$hist_rate
      ,interpolation='linear'
      ,verbose=F
    )
  
  saveRDS(pw_hlin,'data/pw_hlin.rds')
}else{
  pw_hlin=readRDS('data/pw_hlin.rds')
}
```

```{r Show the outcome and censoring in training set, eval=FALSE, include=FALSE}
pw_hlin %>%
  .[,pData(protocolData(.))$int] %>%
  pData() %>%
  select(outcome,censoring) %>%
  table()
```

## Feature representation as principal components by 10-fold cross validation

The historical rates of all candidate predictors were fitted to a principal 
component (PC) model. Only training set was used for the model fitting. We 
applied 10-fold cross validation to estimate weights for all candidate 
predictors in each PC.

```{r Fit PC models with resampling based on train set, include=FALSE}
if(run_heavy_computation){
  pw_int_rsdr=
    pw_hlin %>%
    .[,pData(protocolData(.))$int] %>%
    exprs() %>%
    t() %>%
    as.data.frame() %>%
    rsdr(
      rs_method='CV'
      ,rs_number=10
      ,dr_method='PCA'
      ,cl=detectCores()/2
    )
  saveRDS(pw_int_rsdr,'data/pw_int_rsdr.rds')
}else{
  cat(readRDS('data/log.rds')[['pw_int_rsdr']])
  pw_int_rsdr=readRDS('data/pw_int_rsdr.rds')
}
```

## Set up tuning grid and training-calibrating configuration

Previous data partition had not held out instances for calibration yet. This 
took 80% of training set. We also gave different weights for event and nonevent 
by including censored outcome, as described in the main text. For 
hyperparameter tuning, we applied 5-fold cross validation, instead of 10-fold 
as applied for PC modeling. Meanwhile, the final training and calibration for 
each model were conducted by bootstrapping for 30 times. These resampling 
methods were applied for the classification tasks. Parallel computing by 
multiple central processing units (CPUs) were applied for training all models.

```{r Build a function to get set for training or testing, include=FALSE}
source('R/get_set-function.R')
```

```{r Prepare train set and parameters, include=FALSE}
# Create an empty list to save training parameters.
training_parameters=list()

# Hold out 20% of training set for calibration.
suppressWarnings(set.seed(66,sample.kind=sample.kind))
training_parameters$pre_calib_set=
  
  # Training set
  pw_hlin %>%
  .[,pData(protocolData(.))$int] %>%
  pData() %>%
  rownames_to_column(var='id') %>%
  
  # Uncensored outcome
  filter(!censoring) %>%
  
  # Get 80% for pre-calibrated set.
  lapply(X=1,Y=.,function(X,Y){
    Z=createDataPartition(Y$outcome,times=1,p=0.8)
    Y$id[Z$Resample1]
  }) %>%
  .[[1]]

# Compute outcome weights.
training_parameters$outcome_weights=
  
  # Training set
  pw_hlin %>%
  .[,pData(protocolData(.))$int] %>%
  pData() %>%
  select(outcome,censoring) %>%
  
  # Compute the probabilities, taking censoring into account.
  cbind(
    table(.) %>%
      as.numeric() %>%
      setNames(c('nonevent_uncensored','event_uncensored'
                 ,'nonevent_censored','event_censored')) %>%
      t() %>%
      as.data.frame() %>%
      mutate(
        total=
          nonevent_uncensored+
          nonevent_censored+
          event_uncensored+
          event_censored
        ,nonevent_prob=nonevent_uncensored/total
        ,event_prob=event_uncensored/total
      ) %>%
      select(nonevent_prob,event_prob)
  ) %>%
  rownames_to_column(var='id') %>%
  
  # Uncensored outcome
  filter(!censoring) %>%
  select(-censoring) %>%
  
  # Compute the weight from half od the inverse probability.
  mutate(
    weight=
      ifelse(
        outcome=='event'
        ,(1/event_prob)*0.5
        ,(1/nonevent_prob)*0.5
      )
  ) %>%
  column_to_rownames(var='id') %>%
  select(weight)

# Define classification tuning to apply 5-fold cross validation.
training_parameters$tuning_trControl=
  trainControl(
    method='cv'
    ,number=5
    ,summaryFunction=twoClassSummary
    ,classProbs=T
    ,savePredictions=T
    ,allowParallel=T
  )

# Define classification training to apply 100-time bootstrapping.
training_parameters$final_trControl=
  trainControl(
    method='boot'
    ,number=100
    ,summaryFunction=twoClassSummary
    ,classProbs=T
    ,savePredictions=T
    ,allowParallel=T
  )
```

```{r Build a function for caret training and evaluation, include=FALSE}
source('R/caret_trainer_evaluator-function.R')
```

## Hyperparameter tuning, final training, and calibrating

We applied the tuning grids and the training configurations for all models, 
except DI-VNN which required several modifications. This is already described 
clearly in the main text. More details will be described for DI-VNN in the next 
section.

```{r Empty lists to save models and the evaluation results, include=FALSE}
model=list()
calib_model=list()
eval_model=list()
```

```{r Conduct causal ridge regression by parallel computing, include=FALSE}
if(run_heavy_computation){
  c(model$causal_ridge
    ,calib_model$causal_ridge
    ,eval_model$causal_ridge) %<-% caret_trainer_evaluator(
      data=
        pw_hlin %>%
        .[rownames(.) %>% .[str_detect(.,'causal')],]
      ,method='glmnet'
      ,calib_method='glm'
      ,tuning=data.frame(alpha=0,lambda=10^seq(-9,0,len=10))
      ,calib_tuning=expand.grid(parameter=seq(0.005,0.1,0.01))
      ,training=training_parameters
      ,title='Conduct causal ridge regression by parallel computing'
      ,dir='data'
      ,file='causal_ridge'
      ,cl=detectCores()/2
    )
}else{
  cat(readRDS('data/log.rds')[['causal_ridge']])
  c(model$causal_ridge
    ,calib_model$causal_ridge
    ,eval_model$causal_ridge) %<-% list(
      readRDS('data/causal_ridge.rds')
      ,readRDS('data/calib_causal_ridge.rds')
      ,readRDS('data/eval_causal_ridge.rds')
    )
}
```

```{r Compute EPV using pre-calibrating train set and all PCs, eval=FALSE, include=FALSE}
pw_hlin %>%
  
  # Use pre-calibrated, training set.
  .[,pData(protocolData(.))$int] %>%
  .[,colnames(.)%in%training_parameters$pre_calib_set] %>%
  pData() %>%
  
  # Summarize the number of censored and uncensored outcomes.
  select(outcome,censoring) %>%
  table() %>%
  as.numeric() %>%
  
  # Get the minimum uncensored number between event and nonevent.
  .[1:2] %>%
  min() %>%
  
  # Floor the number and divide it with the number of candidate features.
  lapply(X=1,Y=.,function(X,Y){
    floor(Y/nrow(pw_hlin))
  }) %>%
  .[[1]] %>%
  c(nrow(pw_hlin)) %>%
  setNames(c('EPV','Candidate features'))
```

```{r Prepare and combine PCs for all sets, include=FALSE}
if(run_heavy_computation){
  cat('Prepare and combine PCs for all sets\n')
  cat('Started:',as.character(now()),'\n')
  
  # Transform any features into the PCs.
  pw_pc=
    list('int','ran','geo','tem','bgt') %>%
    lapply(function(x){
      cat('For ',x,': ',sep='')
      pw_hlin %>%
        .[,pData(protocolData(.))[[x]]] %>%
        transformation(
          rsdr_object=pw_int_rsdr
          ,verbose=T
        )
    }) %>%
    setNames(c('int','ran','geo','tem','bgt'))
  
  # Provider-wise data for prediction by PCs
  pw_pc=
    ExpressionSet(
      assayData=
        pw_pc %>%
        lapply(exprs) %>%
        do.call(cbind,.) %>%
        .[,colnames(pw_hlin)]
      ,phenoData=
        pw_pc %>%
        lapply(phenoData) %>%
        lapply(pData) %>%
        do.call(rbind,.) %>%
        `rownames<-`(str_split_fixed(rownames(.),'\\.',2)[,2]) %>%
        .[colnames(pw_hlin),] %>%
        AnnotatedDataFrame() %>%
        `varMetadata<-`(varMetadata(phenoData(pw_pc$int)))
      ,featureData=featureData(pw_pc$int)
      ,experimentData=
        MIAME(
          name='Herdiantri Sufriyana'
          ,lab='Emily Chia-Yu Su Lab'
          ,contact='herdiantrisufriyana@unusa.ac.id'
          ,title='Medical history PC dataset for prediction'
          ,abstract=
            str_replace_all(
              'This dataset is a medical-history table from the BPJS Kesehatan.
              Selected causal factors, that is re-assigned by regex, are added.
              All are transformed by resampled dimensional reduction using 
              principal components analysis with 10-fold cross validation (CV).
              The target population is health insurance holders of 
              12-to-55-years-old females who visit healthcare providers between 
              2015 and 2016. The outcome of interest is fetal growth restriction 
              and small for gestational age (FGR-SGA). The medical history 
              scenario is recorded individually within each healthcare provider 
              nationwide.'
              ,'\n',' '
            ) %>%
            str_replace_all('\\s+',' ')
          ,url='https://github.com/herdiantrisufriyana/fgr_sga'
        )
      ,annotation=annotation(pw_pc$int)
      ,protocolData=
        pw_pc %>%
        lapply(protocolData) %>%
        lapply(pData) %>%
        do.call(rbind,.) %>%
        `rownames<-`(str_split_fixed(rownames(.),'\\.',2)[,2]) %>%
        .[colnames(pw_hlin),] %>%
        AnnotatedDataFrame() %>%
        `varMetadata<-`(varMetadata(protocolData(pw_pc$int)))
    ) %>%
    `preproc<-`(preproc(pw_pc$int))

  gc()
  cat('End:',as.character(now()))
}else{
  cat(readRDS('data/log.rds')[['pw_pc']])
}
```

```{r Compute maximum number of PCs to get 20 EPV, eval=FALSE, include=FALSE}
pw_hlin %>%
  
  # Use pre-calibrated, training set.
  .[,pData(protocolData(.))$int] %>%
  .[,colnames(.)%in%training_parameters$pre_calib_set] %>%
  pData() %>%
  
  # Summarize the number of censored and uncensored outcomes.
  select(outcome,censoring) %>%
  table() %>%
  as.numeric() %>%
  
  # Get the minimum uncensored number between event and nonevent.
  .[1:2] %>%
  min() %>%
  
  # Floor the number and divide it with the number of candidate features.
  lapply(X=1,Y=.,function(X,Y){
    floor(Y/20)
  }) %>%
  .[[1]] %>%
  c(20) %>%
  setNames(c('PC','EPV'))
```

```{r Conduct PC elastic net regression by parallel computing, include=FALSE}
if(run_heavy_computation){
  c(model$pc_elnet
    ,calib_model$pc_elnet
    ,eval_model$pc_elnet) %<-% caret_trainer_evaluator(
      data=
        pw_pc %>%
        .[preproc(.) %>%
            .$pve %>%
            sort(decreasing=T) %>%
            names() %>%
            .[1:14]
          ,]
      ,method='glmnet'
      ,calib_method='gamLoess'
      ,tuning=expand.grid(alpha=seq(0,1,len=5),lambda=10^seq(-9,0,len=5))
      ,calib_tuning=expand.grid(span=seq(0.005,0.1,0.01),degree=seq(0,1,len=2))
      ,training=training_parameters
      ,title='Conduct PC elastic net regression by parallel computing'
      ,dir='data'
      ,file='pc_elnet'
      ,cl=detectCores()/2
    )
}else{
  cat(readRDS('data/log.rds')[['pc_elnet']])
  c(model$pc_elnet
    ,calib_model$pc_elnet
    ,eval_model$pc_elnet) %<-% list(
      readRDS('data/pc_elnet.rds')
      ,readRDS('data/calib_pc_elnet.rds')
      ,readRDS('data/eval_pc_elnet.rds')
    )
}
```

```{r Compute maximum number of PCs to get 50 EPV, eval=FALSE, include=FALSE}
pw_hlin %>%
  
  # Use pre-calibrated, training set.
  .[,pData(protocolData(.))$int] %>%
  .[,colnames(.)%in%training_parameters$pre_calib_set] %>%
  pData() %>%
  
  # Summarize the number of censored and uncensored outcomes.
  select(outcome,censoring) %>%
  table() %>%
  as.numeric() %>%
  
  # Get the minimum uncensored number between event and nonevent.
  .[1:2] %>%
  min() %>%
  
  # Floor the number and divide it with the number of candidate features.
  lapply(X=1,Y=.,function(X,Y){
    floor(Y/50)
  }) %>%
  .[[1]] %>%
  c(50) %>%
  setNames(c('PC','EPV'))
```

```{r Select the top-weight PCs for downstream analysis, include=FALSE}
selected_pc=
  
  # Get PC weights from the PC elastic net regression model.
  coef(model$pc_elnet$finalModel,model$pc_elnet$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var='term') %>%
  
  # Clean up.
  mutate(term=str_remove_all(term,'\\`|\\(|\\)')) %>%
  setNames(c('term','estimate')) %>%
  filter(estimate!=0) %>%
  arrange(desc(abs(estimate))) %>%
  filter(!term %in% c('Intercept')) %>%
  
  # Find the top-weight PCs up to the maximum number to get 50 EPV.
  slice(1:5) %>%
  mutate(idx=str_remove_all(term,'PC') %>% as.integer())
```

```{r Conduct PC random forest by parallel computing, include=FALSE}
if(run_heavy_computation){
  c(model$pc_rf
    ,calib_model$pc_rf
    ,eval_model$pc_rf) %<-% caret_trainer_evaluator(
      data=pw_pc[selected_pc$term,]
      ,method='Rborist'
      ,calib_method='glm'
      ,tuning=expand.grid(predFixed=seq(5,45,len=5),minNode=seq(20,100,len=5))
      ,calib_tuning=expand.grid(parameter=seq(0.005,0.1,0.01))
      ,training=training_parameters
      ,title='Conduct PC random forest by parallel computing'
      ,dir='data'
      ,file='pc_rf'
      ,cl=detectCores()/2
    )
}else{
  cat(readRDS('data/log.rds')[['pc_rf']])
  c(model$pc_rf
    ,calib_model$pc_rf
    ,eval_model$pc_rf) %<-% list(
      readRDS('data/pc_rf.rds')
      ,readRDS('data/calib_pc_rf.rds')
      ,readRDS('data/eval_pc_rf.rds')
    )
}
```

```{r Conduct PC gradient boosting machine by parallel computing, include=FALSE}
if(run_heavy_computation){
  c(model$pc_gbm
    ,calib_model$pc_gbm
    ,eval_model$pc_gbm) %<-% caret_trainer_evaluator(
      data=pw_pc[selected_pc$term,]
      ,method='gbm'
      ,calib_method='gamLoess'
      ,tuning=
        expand.grid(
          interaction.depth=1
          ,shrinkage=seq(0.0005,0.05,len=25)
          ,n.minobsinnode=20
        ) %>%
        mutate(n.trees=seq(0,2500,len=26) %>% .[-1] %>% rev()) %>%
        select(n.trees,everything())
      ,calib_tuning=expand.grid(span=seq(0.005,0.1,0.01),degree=seq(0,1,len=2))
      ,training=training_parameters
      ,title='Conduct PC gradient boosting machine by parallel computing'
      ,dir='data'
      ,file='pc_gbm'
      ,cl=detectCores()/2
    )
}else{
  cat(readRDS('data/log.rds')[['pc_gbm']])
  c(model$pc_gbm
    ,calib_model$pc_gbm
    ,eval_model$pc_gbm) %<-% list(
      readRDS('data/pc_gbm.rds')
      ,readRDS('data/calib_pc_gbm.rds')
      ,readRDS('data/eval_pc_gbm.rds')
    )
}
```

## Deep-insight visible neural network (DI-VNN)

We applied different preprocessing pipelines for feature selection and 
representation in DI-VNN. Instead of PCs, we used the historical rates of the 
candidate predictors. A 5-minute video explaining DI-VNN pipeline is available 
(see Supplemental Video). Only pre-calibration training set was used for the 
downstream pipeline.

Different to previous DIVNN pipeline, we did not conduct feature selection 
using differential analysis because there were only 9 the candidate predictors.

For 1-bit stochastic gradient descent transformation, we used the 
post-normalization, feature-wise average based on nationwide training set as 
the target of which quantile-to-quantile normalization of any subsets were 
applied onto. These included subsets for calibration and external validation. 
Instead of nationwide, these subsets were provider-wise, because we used these 
for prediction that likely uses medical history from a healthcare provider 
visited by a subject. Then, the transformation was applied as described in the 
main text, depending on the feature wise averages.

Demanding different statistical assumption, we used unnormalized candidate 
predictors for creating a feature map (i.e. ontology array) and a network 
architecture (i.e. ontology network). Both procedures need a 
distance/similarity matrix. We also used nationwide, pre-calibration training 
set to construct this matrix. Only the candidate features selected by 
differential analysis were used. Standardization was applied by subtracting 
each value with feature-wise average and dividing it with feature-wise standard 
deviation. Then, we computed a feature-to-feature Pearson correlation matrix.

For creating a feature map, we projected the filtered candidate predictors onto 
three dimensions, as described in the main text. The results consisted three 
numbers for each of the candidate predictors. We transformed two of these 
values as ranks. If we have 5 candidate predictors, then we order these for 
axes of *x* and *y*. For example, a candidate predictor is mapped at *x=1* and 
*y=3* in a two-dimensional space. This is because that predictor has values on 
dimensions of *x* and *y*, that rank respectively at 1^st^ and 3^rd^ 
positions among the five candidate predictors. Then, we split axes of *x* and 
*y* into  $7\times7$ grid; thus, there might be more than one candidate 
predictors at the same position. We rotated the map by convex-hull algorithm, 
as applied in the original DeepInsight, to find smallest feature map size then 
re-ranking the dimensions. For any positions, we computed maximum number 
of candidate predictors residing on the same position. That number determined 
the number of the two-dimensional layers, i.e. channels. The overlapped 
candidate predictors were ranked based on the third dimension. The ranks 
determined which channels a candidate predictor residing on for each position 
on the two-dimensional space.

This can be considered as a three-dimensional array. In each position, a  
candidate predictor may have a value of -1, 0, or 1, depending on the 1-bit 
stochastic gradient descent transformation. For any positions in the array, 
that have no candidate predictor residing on, a value of 0 is applied. The 
empty position may be occupied by an unfiltered candidate predictor had it 
surpassed filtering by the differential analysis. Therefore, zero value for the 
empty position has the same notion with either the unfiltered candidate 
predictors or those with normalized values equal to the feature-wise averages, 
i.e. undifferentiated features in relative to the outcome. Ranking the 
dimension is a novel method to reduce array dimensions, different to that 
applied by the previous DeepInsight transformation. Positioning of candidate 
predictors on the feature map was derived from pre-calibration training set. 
This positioning is also used for constructing the three-dimensional array of 
the other subsets in calibration and external validation.

Meanwhile, using the same correlation matrix, we applied CliXO algorithm, as 
described in the main text. We applied $\alpha$*=0.01* and $\beta$*=0.5*, as 
recommended. The resulting ontologies derived from pre-calibration training set 
were used to subset a feature map into different arrays, including in 
calibration and external validation. If we have 5 candidate predictors, feature 
1 and 5 may be clustered into the same ontology while feature 3 and 4 into 
another ontology. To subset the feature map into an array for the first 
ontology, we multiplied all numbers in the array with 0 except the feature 
members of that ontology, which are feature 1 and 5. The same method is applied 
for the ontology including feature 3 and 4. Since CliXO is an agglomerative 
hierarchical clustering algorithm, both ontologies may unite into an ontology. 
In this example, the unified ontology includes all candidate features. But, 
this may not be the case. An additional ontology, called root ontology, is 
added to include all candidate predictors, either from the remaining candidate 
predictors, if any, or ones in the ontology consisting the most candidate 
predictors (i.e. highest ontology in the hierarchy). Eventually, we had an 
array for each ontology derived by CliXO algorithm.

Each ontology array was fed to a block of neural network, i.e. 
Inception v4-Resnet. In this architecture, an array in terminal branch of 
an ontology hierarchy is filtered by feeding it through Inception v4, then 
reconstructing the array into the same dimensions as it entered the 
Inception v4. Element-wise addition is applied between the filtered array and 
the original one. This mathematical operation is the Resnet architecture 
itself. To connect a child ontology array with a sibling ontology, if any, we 
applied depth concatenation, i.e. by the channel. The concatenated array 
(double or more channels) is fed to the Inception v4, then reconstructing the 
array into the same dimensions with the parent ontology array. The same 
mathematical operation is applied for the concatenated, filtered array and the 
parent one. Child-to-parent connection was applied between one or more arrays 
in non-terminal branch of an ontology hierarchy and the parent array. Each of 
either the terminal or non-terminal branch had a transformed array as a 
representation of an input array of each ontology. To get a representation, the 
transformation is achieved by a series of iterations using backpropagation 
algorithm.

Before explaining the backpropagation, we need to know how each ontology array 
was transformed into a single number from 0 to 1 that predicts a probability 
of an event, or an integer for estimation task. After transformation by a block 
of Inception v4-Resnet, the transformed array was fed to a block of layers for 
convolution. This reduced the dimensions from $7\times7$ in each channel into a 
single number by a series of mathematical operation of convolution. Therefore, 
we have multiple numbers showing probabilities of an event for each instance, 
transformed and convoluted from all ontology arrays.

```{r DI-VNN feature selection and representation, include=FALSE}
if(run_heavy_computation){
  input=list()
  
  # Use provider-wise, pre-calibrated, training set for modeling.
  input$pw=
    pw_hlin %>%
    .[,!pData(phenoData(.))$censoring] %>%
    .[,pData(protocolData(.))$int] %>%
    .[,colnames(.)%in%training_parameters$pre_calib_set,drop=F]
  
  # Use nationwide, pre-calibrated, training set for feature selection.
  input$nw=
    nw_int_hlin %>%
    .[,!pData(phenoData(.))$censoring] %>%
    .[,colnames(.)%in%training_parameters$pre_calib_set,drop=F]
  
  output=list()
  
  # Get uncensored outcome.
  output$outcome=
    input$pw %>%
    phenoData() %>%
    pData() %>%
    select(outcome)
  
  # Get features corresponding to uncensored outcome.
  output$raw$pw=
    input$pw %>%
    exprs() %>%
    t() %>%
    .[rownames(output$outcome),]
  
  output$raw$nw=
    input$nw %>%
    exprs() %>%
    t() %>%
    .[rownames(output$outcome),]
  
  # Check if feature selection was conducted utilizing differential analysis
  # by moderated-t stats with Benjamini-Hochberg multiple testing correction.
  output$fit=
    t(output$raw$nw) %>%
    normalize.quantiles() %>%
    `dimnames<-`(dimnames(t(output$raw$nw))) %>%
    lmFit(model.matrix(~outcome,output$outcome)) %>%
    eBayes() %>%
    topTable(coef=2,nrow(.$coefficients),adjust.method='BH',sort.by='none')
  # %>%
  #   filter(adj.P.Val<0.05)
  
  # Get the selected features as unnormalized ones.
  output$unnorm$pw=
    output$raw$pw %>%
    .[,rownames(output$fit)]
  
  output$unnorm$nw=
    output$raw$nw %>%
    .[,rownames(output$fit)]
  
  # Normalize features quantile-to-quantile
  # using differential average of features as target.
  output$norm=
    output$unnorm$pw %>%
    t() %>%
    normalize.quantiles.use.target(output$fit$AveExpr) %>%
    t() %>%
    `dimnames<-`(dimnames(output$unnorm$pw))
  
  # Transform features by 1-bit stochastic gradient descent (SGD)
  # using the differential average.
  cat('Transform features by 1-bit stochastic gradient descent (SGD)\n')
  output$predictor_v=
    output$norm %>%
    sweep(2,output$fit$AveExpr,'-') %>%
    pbsapply(function(x){ifelse(x==0,0,ifelse(x>0,1,-1))}) %>%
    matrix(
      ncol=ncol(output$unnorm$pw)
      ,byrow=F
      ,dimnames=dimnames(output$unnorm$pw)
    ) %>%
    as.data.frame()
  
  # Get feature-wise mean of unnormalized features.
  output$predictor_m=
    output$unnorm$nw %>%
    colMeans2()
  
  # Get feature-wise standard deviation (SD) of unnormalized features.
  output$predictor_s=
    output$unnorm$nw %>%
    colSds()
  
  # Scale unnormalized features by the mean and SD.
  output$scaled=
    output$unnorm$nw %>%
    sweep(2,output$predictor_m,'-') %>%
    sweep(2,output$predictor_s,'/')
  
  # Compute feature-feature Pearson correlation matrix
  # of unnormalized features.
  cat('Compute feature-feature Pearson correlation matrix\n')
  output$predictor_p=
    colnames(output$unnorm$nw) %>%
    lapply(X=seq(length(.)-1),Y=.,function(X,Y){
      data.frame(
        predictor1=Y[X]
        ,predictor2=Y[(X+1):length(.)]
      )
    }) %>%
    do.call(rbind,.) %>%
    mutate(
      pearson=
        pbsapply(X=seq(nrow(.)),Y=.,Z=output$scaled,function(X,Y,Z){
          cor(
            Z[,Y$predictor1[X]]
            ,Z[,Y$predictor2[X]]
          )
        })
    ) %>%
    rbind(
      setNames(select(.,predictor2,predictor1,everything()),colnames(.))
      ,data.frame(
        predictor1=colnames(output$unnorm$nw)
        ,predictor2=colnames(output$unnorm$nw)
        ,pearson=1
      )
    ) %>%
    spread(predictor2,pearson) %>%
    column_to_rownames(var='predictor1') %>%
    as.matrix()
  
  # Conduct Barnes-Hut t-moderated stochastic neighbor embedding (t-SNE).
  cat('Conduct Barnes-Hut t-moderated stochastic neighbor embedding (t-SNE)\n')
  suppressWarnings(set.seed(33,sample.kind=sample.kind))
  output$predictor_tsne=
    output$predictor_p %>%
    Rtsne(dims=3,perplexity=17,verbose=T,is_distance=T)
  
  # Construct clique-extracted ontology (CliXO) (choose your own OS).
  output$predictor_c=
    output$predictor_p %>%
    clixo(os='windows')
  
  # Compile input.
  input=list()
  
  input$value=output$predictor_v
  
  input$outcome=
    output$outcome %>%
    mutate(outcome=as.integer(outcome=='event')) %>%
    pull(outcome) %>%
    setNames(rownames(input$value))
  
  input$similarity=output$predictor_p
  
  input$mapping=
    output$predictor_tsne$Y %>%
    `rownames<-`(colnames(input$value))
  
  input$ontology=
    output$predictor_c %>%
    mutate(seq=seq(nrow(.))) %>%
    gather(key,value,-similarity,-relation,-seq) %>%
    mutate(
      value2=
        ifelse(
          str_detect(value,'CliXO:')
          ,str_remove_all(value,'CliXO:')
          ,NA
        ) %>%
        as.integer()
    ) %>%
    mutate(
      value=
        ifelse(
          str_detect(value,'CliXO:')
          ,paste0(
            'ONT:'
            ,str_pad(value2,str_count(max(value2,na.rm=T)),'left','0')
          )
          ,value
        )
    ) %>%
    select(-value2) %>%
    spread(key,value) %>%
    arrange(seq) %>%
    select(-seq) %>%
    select(source,target,everything())
  
  input$fit=output$fit
  
  # Compile into a TidySet.
  cat('Compile into a TidySet\n')
  output=
    TidySet.compile(
      value=input$value
      ,outcome=input$outcome
      ,similarity=input$similarity
      ,mapping=input$mapping
      ,ontology=input$ontology
      ,ranked=T
      ,dims=7
      ,decreasing=F
      ,seed_num=33
    )
  
  saveRDS(input,'data/input.rds')
  saveRDS(output,'data/output.rds')
}else{
  cat(readRDS('data/log.rds')[['output_predictor_v']],'\n')
  cat(readRDS('data/log.rds')[['output_predictor_p']],'\n')
  cat(readRDS('data/log.rds')[['output_predictor_tsne']],'\n')
  cat(readRDS('data/log.rds')[['output']])
  input=readRDS('data/input.rds')
  output=readRDS('data/output.rds')
}
```

```{r Show ontonet, eval=FALSE, include=FALSE}
output %>%
  viz.ontonet(feature=F) %>%
  plot(
    node.size=5
    ,edge.arrow.size=0.25
    ,main='Untrained Ontonet'
  )
```

For each iteration, we computed differences between the outcome, which is 0 and 
1 respectively for nonevent and event, and each probability convoluted from 
each ontology array. For estimation task, this was the differences between 
the true time and the predicted time of delivery. The computation was applied 
by the loss function, as described in the main text. A batch size of 512 
instances was computed for the loss in each iteration. The loss or error was 
used to update the weights. These were initiated randomly, as described in the 
main text, then the weights were updated via backpropagation from the root 
ontology to the terminal ones. This procedure is iterative using 512 instances 
each time until 80% instances were used in pre-calibration training set. This 
achieved a cycle of iterations, or epoch. At the end of each epoch, we computed 
the loss and AUROC using another 20% instances. Each update was multiplied by a 
number, called learning rate. We applied a learning rate of 2^-6. For the 
iterations covering the first 5% of instances in each epoch, the learning rate 
was initiated at one thirty-second of the learning rate at the first iteration 
for that epoch. This is gradually increased until reaching the learning rate at 
the last iteration covering the first 5% of instances, i.e. warm-up strategy. 
From an epoch to the next one, the learning rate for the next epoch was reduced 
by 4% if the AUROC of the 20%-validation subset was no higher than 0.01 in 
addition to that of the previous epoch. No reduction was applied if reaching 
the minimum, which is 1/512 of the initial learning rate. Maximum epochs of 5 
and 500 was set respectively for the hyperparameter tuning and the final 
training. After 50% of the maximum epochs, the iterations were stopped earlier 
if the AUROC of the 20%-validation subset was no higher than 0.001 in addition 
to that of the previous epoch. Only weights of the best iteration were finally 
used. This was determined based on the validation AUROC. After stopping, we 
computed AUROCs of the 20% validation subsets by bootstrapping for 30 times. 
All of these procedures were applied for each trial in the hyperparameter 
tuning and the final training. The tuning grid was applying different $\lambda$ 
values, as described in the main text. The best tuning parameter was determined 
by the bootstrapped, validation AUROC. Eventually, the same calibration and 
external validation procedures were applied on DI-VNN, as applied on the other 
models.

```{r Create a function to refresh keras backend session, include=FALSE}
source('R/refresh_session-function.R')
refresh_session()
```

```{r Create a function to create training function given lambda, include=FALSE}
source('R/trainer_generator-function.R')
```

```{r Conduct hyperparameter tuning for a DI-VNN, include=FALSE}
lambda=10^seq(-10,-1,len=10)
if(run_heavy_computation){
  cat('Conduct hyperparameter tuning for DI-VNN model\n')
  cat('Started:',as.character(now()),'\n')
    
    surrogate_model=
      trainer_generator(
        output
        ,class_weight=
          pw_hlin %>%
          .[,colnames(.)%in%training_parameters$pre_calib_set,drop=F] %>%
          phenoData() %>%
          pData() %>%
          select(outcome) %>%
          mutate(outcome=as.integer(outcome=='event')) %>%
          cbind(
            training_parameters$outcome_weights %>%
            .[rownames(.)%in%training_parameters$pre_calib_set,,drop=F]
          ) %>%
          filter(!duplicated(.)) %>%
          arrange(outcome) %>%
          lapply(X=1,Y=.,function(X,Y){
            setNames(Y$weight,Y$outcome)
          }) %>%
          .[[1]]
        ,epochs=5
        ,patience=round(5/2)
        ,batch_size=512
        ,warm_up=0.05
        ,lr=2^-6
        ,min_lr=2^-6/512
        ,tuning_mode=T
        ,verbose=1
      )
    
    tuning_divnn=list()
    i=1
    for(j in seq(i,length(lambda))){
      suppressWarnings(set.seed(33,sample.kind=sample.kind))
      tuning_divnn[[j]]=surrogate_model(lambda[j])
    }
  
  rm(i,j)
  cat('End:',as.character(now()))
  saveRDS(tuning_divnn,'data/tuning_divnn.rds')
}else{
  cat(readRDS('data/log.rds')[['tuning_divnn']])
  tuning_divnn=readRDS('data/tuning_divnn.rds')
}
```

```{r Plot DI-VNN tuning results, eval=FALSE, include=FALSE}
tuning_divnn %>%
  sapply(function(x)min(x$Score)) %>%
  data.frame(mean_AUROC=.) %>%
  mutate(which_param=seq(nrow(.))) %>%
  mutate(best=which.max(mean_AUROC)) %>%
  qplot(which_param,mean_AUROC,color=which_param==best,data=.) +
  geom_smooth(method='loess',color='black',formula=y~x) +
  scale_x_continuous(breaks=seq(lambda))
```

```{r Conduct modeling for a DI-VNN, include=FALSE}
if(run_heavy_computation){
  cat('Conduct modeling for DI-VNN\n')
  cat('Started:',as.character(now()),'\n')
    
    surrogate_model=
      trainer_generator(
        output
        ,path='data/ontonet'
        ,class_weight=
          pw_hlin %>%
          .[,colnames(.)%in%training_parameters$pre_calib_set,drop=F] %>%
          phenoData() %>%
          pData() %>%
          select(outcome) %>%
          mutate(outcome=as.integer(outcome=='event')) %>%
          cbind(
            training_parameters$outcome_weights %>%
            .[rownames(.)%in%training_parameters$pre_calib_set,,drop=F]
          ) %>%
          filter(!duplicated(.)) %>%
          arrange(outcome) %>%
          lapply(X=1,Y=.,function(X,Y){
            setNames(Y$weight,Y$outcome)
          }) %>%
          .[[1]]
        ,epochs=500
        ,patience=100
        ,batch_size=512
        ,warm_up=0.05
        ,lr=2^-6
        ,min_lr=2^-6/512
        ,tuning_mode=F
        ,checkpoint=T
        ,verbose=1
      )
    suppressWarnings(set.seed(33,sample.kind=sample.kind))
    modeling_divnn=surrogate_model(lambda[10])
    
  cat('End:',as.character(now()))
  save_model_weights_hdf5(modeling_divnn$ontonet,'data/ontonet.h5')
  saveRDS(modeling_divnn,'data/modeling_divnn.rds')
}else{
  cat(readRDS('data/log.rds')[['modeling_divnn']])
  modeling_divnn=readRDS('data/modeling_divnn.rds')
  refresh_session()
  modeling_divnn$ontonet=
    output %>%
    generator.ontonet(l2_norm=lambda[10]) %>%
    # readLines('data/ontonet.json') %>%
    # model_from_json() %>%
    load_model_weights_hdf5('data/ontonet.h5') %>%
    compile(
      optimizer=optimizer_sgd(
        lr=modeling_divnn$history$metrics$lr %>%
          .[which.max(modeling_divnn$history$metrics$val_root_roc)]
        ,momentum=0.9
      )
      ,loss='mean_squared_error'
      ,loss_weights=c(rep(
          0.3/(0.3*(length(.$outputs)-1)+1),length(.$outputs)-1)
          ,1/(0.3*(length(.$outputs)-1)+1)
        )
      ,metrics=c(
          tf$keras$metrics$AUC(name='roc')
          ,tf$keras$metrics$TruePositives(name='tp')
          ,tf$keras$metrics$FalseNegatives(name='fn')
          ,tf$keras$metrics$FalsePositives(name='fp')
          ,tf$keras$metrics$TrueNegatives(name='tn')
        )
    )
}
```

```{r Iteration plot, fig.height=7, fig.width=7, eval=FALSE, include=FALSE}
modeling_divnn$history$metrics %>%
  .[c('root_loss','val_root_loss','root_roc','val_root_roc','lr')] %>%
  do.call(cbind,.) %>%
  as.data.frame() %>%
  mutate(iteration=seq(nrow(.))) %>%
  gather(metric,value,-iteration) %>%
  mutate(set=str_remove_all(metric,'_loss|_roc')) %>%
  mutate(
    metric=case_when(
      metric=='lr'~'1. LR'
      ,str_detect(metric,'loss')~'2. Loss'
      ,str_detect(metric,'roc')~'3. AUROC'
      ,TRUE~''
    )
  ) %>%
  qplot(iteration,value,color=set,data=.,geom='line') +
  geom_smooth(method='loess',formula=y~x,se=F) +
  facet_wrap(~metric,scales='free_y',ncol=1) +
  theme_minimal()
```

```{r Create a function to transform test data for DI-VNN input, include=FALSE}
source('R/test_transformer-function.R')
```

```{r Transform test data for DI-VNN input, include=FALSE}
if(run_heavy_computation){
  test_data=
    list('calib','ran','geo','tem','bgt') %>%
    lapply(function(x){
      cat('Compile data for set of:',x,'\n')
      
      # Select the subset.
      if(x=='int'){
        data=
          pw_hlin %>%
          .[,!pData(phenoData(.))$censoring] %>%
          .[,pData(protocolData(.))$int]
      }else if(x=='calib'){
        data=
          pw_hlin %>%
          .[,!pData(phenoData(.))$censoring] %>%
          .[,pData(protocolData(.))$int] %>%
          .[,!colnames(.)%in%training_parameters$pre_calib_set,drop=F]
      }else{
        data=
          pw_hlin %>%
          .[,!pData(phenoData(.))$censoring] %>%
          .[,pData(protocolData(.))[[x]]]
      }
      
      # Transform the subset.
      test_transformer(
        test_data=data
        ,SGD1bit_fit=input$fit
        ,similarity=input$similarity
        ,mapping=input$mapping
        ,ontology=input$ontology
        ,ranked=T
        ,dims=7
        ,decreasing=F
        ,seed_num=33
      )
    }) %>%
    setNames(c('calib','ran','geo','tem','bgt'))
  saveRDS(test_data,'data/test_data.rds')
}else{
  cat(readRDS('data/log.rds')[['test_data']])
  test_data=readRDS('data/test_data.rds')
}
```

```{r Build a function for DI-VNN evaluation, include=FALSE}
source('R/eval_divnn-function.R')
```

```{r Build a function for DI-VNN calibration and evaluation, include=FALSE}
source('R/divnn_calibrator_evaluator-function.R')
```

```{r Calibrate and evaluate DI-VNN, include=FALSE}
if(run_heavy_computation){
  c(model$divnn
    ,calib_model$divnn
    ,eval_model$divnn) %<-% divnn_calibrator_evaluator(
      data=test_data
      ,modeling=modeling_divnn
      ,training=training_parameters
      ,calib_tuning=
        expand.grid(span=seq(0.005,0.1,0.01)[-4:-7],degree=seq(0,1,len=2))
      ,batch_size=64
      ,title='Calibrate and evaluate DI-VNN'
      ,dir='data'
      ,file='divnn'
    )
}else{
  cat(readRDS('data/log.rds')[['divnn']])
  c(model$divnn
    ,calib_model$divnn
    ,eval_model$divnn) %<-% list(
      readRDS('data/divnn.rds')
      ,readRDS('data/calib_divnn.rds')
      ,readRDS('data/eval_divnn.rds')
    )
}
```

```{r DI-VNN training evaluation, eval=FALSE, include=FALSE}
modeling_divnn$history$metrics %>%
  sapply(X=seq(length(.))
         ,Y=.
         ,Z=modeling_divnn$history$metrics %>%
            .[str_detect(names(.),'val_root_roc')] %>%
            unlist() %>%
            which.max()
         ,function(X,Y,Z){
    setNames(Y[[X]][[Z]][[1]],names(Y)[X])
  }) %>%
  data.frame(value=.) %>%
  .[str_detect(rownames(.),'root'),,drop=F] %>%
  kable() %>%
  kable_classic()
```

## Evaluating the best model for classification and estimation

Model evaluation is already clearly described in the main text. We started from 
evaluating the calibration measures of all models for classification task. 
Then, we chose the best model for classification by AUROC using only internal 
validation (calibration split) bootstrapped for 30 times.

```{r Show calibration plot before calibration, eval=FALSE, include=FALSE}
model %>%
  # Compute true probability interval.
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$pred
        ,event=round(event*20)/20#round(event,1)
        ,obs=as.integer(obs=='event')
      ) %>%
      group_by(event) %>%
      summarize(
        model=factor(X,names(Y))
        ,obs=mean(obs)
        ,lb=mean(obs)-qnorm(0.975)*sqrt(mean(obs)*(1-mean(obs))/n())
        ,ub=mean(obs)+qnorm(0.975)*sqrt(mean(obs)*(1-mean(obs))/n())
      )
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'1. Causal LR'
    ,model=='pc_elnet'~'2. PC-LR'
    ,model=='pc_rf'~'3. PC-RF'
    ,model=='pc_gbm'~'4. PC-GBM'
    ,model=='divnn'~'5. DI-VNN'
    ,TRUE~''
  )) %>%
  
  # Create calibration plot.
  qplot(event,obs,data=.) +
  geom_linerange(aes(ymin=lb,ymax=ub)) +
  geom_abline(lty=2) +
  facet_wrap(~model) +
  coord_equal() +
  scale_x_continuous('Predicted probability',limits=0:1) +
  scale_y_continuous('True probability',limits=0:1) +
  ggtitle('A. Before calibration') +
  theme(axis.text.x=element_text(angle=90,vjust=0.5,hjust=1))
```

```{r Show probability distribution before calibration, eval=FALSE, include=FALSE}
model %>%
  # Compute number of sample per predicted probability.
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$pred
        ,event=round(event*20)/20#round(event,1)
        ,obs=as.integer(obs=='event')
      ) %>%
      group_by(event) %>%
      summarize(
        model=factor(X,names(Y))
        ,n=n()
      )
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'1. Causal LR'
    ,model=='pc_elnet'~'2. PC-LR'
    ,model=='pc_rf'~'3. PC-RF'
    ,model=='pc_gbm'~'4. PC-GBM'
    ,model=='divnn'~'5. DI-VNN'
    ,TRUE~''
  )) %>%
  
  # Create histogram of the predicted probability.
  qplot(event,n,data=.,geom='col',na.rm=T) +
  facet_wrap(~model,scales='free_y') +
  # scale_x_continuous(limits=0:1) +
  theme(axis.text.x=element_text(angle=90,vjust=0.5,hjust=1))
```

```{r Show calibration measures before calibration, eval=FALSE, include=FALSE}
model %>%
  # Compute true probability.
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$pred
        ,event=round(event*20)/20#round(event,2)
        ,obs=as.integer(obs=='event')
      ) %>%
      group_by(event) %>%
      summarize(
        model=factor(X,names(Y))
        ,obs=mean(obs)
      )
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'1. Causal LR'
    ,model=='pc_elnet'~'2. PC-LR'
    ,model=='pc_rf'~'3. PC-RF'
    ,model=='pc_gbm'~'4. PC-GBM'
    ,model=='divnn'~'5. DI-VNN'
    ,TRUE~''
  )) %>%
  
  # Fitting a line to get the intercept and slope.
  group_by(model) %>%
  do(tidy(lm(obs~event,data=.))) %>%
  
  # Wrap up.
  mutate(term=str_remove_all(term,'\\(|\\)') %>% str_to_lower()) %>%
  pivot_wider(
    model,names_from=c('term','term'),values_from=c('estimate','std.error')
  ) %>%
  select(model,estimate_intercept,std.error_intercept,everything()) %>%
  mutate_at(colnames(.) %>% .[.!='model'],function(x)round(x,2)) %>%
  
  # Show results as a table.
  kable() %>%
  kable_classic()
```

```{r Compare ROC among models before calibration, eval=FALSE, include=FALSE}
model %>%
  # Compute interval estimates.
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$results
        ,ROC_lb=ROC-qnorm(0.975)*ROCSD
        ,ROC_ub=ROC+qnorm(0.975)*ROCSD
      ) %>%
      mutate(model=X) %>%
      select(model,ROC,ROC_lb,ROC_ub)
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'1. Causal LR'
    ,model=='pc_elnet'~'2. PC-LR'
    ,model=='pc_rf'~'3. PC-RF'
    ,model=='pc_gbm'~'4. PC-GBM'
    ,model=='divnn'~'5. DI-VNN'
    ,TRUE~''
  )) %>%
  mutate(model=reorder(model,ROC)) %>%
  
  # Plot the comparison of the AUROCs.
  qplot(model,ROC,data=.) +
  geom_errorbar(aes(ymin=ROC_lb,ymax=ROC_ub),width=0.35) +
  geom_hline(yintercept=0.5,lty=2) +
  coord_flip()
```

```{r Compare AUC of ROC among models before calibration, eval=FALSE, include=FALSE}
model %>%
  # Compute the interval estimates.
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$results
        ,ROC_lb=ROC-qnorm(0.975)*ROCSD
        ,ROC_ub=ROC+qnorm(0.975)*ROCSD
      ) %>%
      mutate(model=X) %>%
      select(model,ROC,ROC_lb,ROC_ub)
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'1. Causal LR'
    ,model=='pc_elnet'~'2. PC-LR'
    ,model=='pc_rf'~'3. PC-RF'
    ,model=='pc_gbm'~'4. PC-GBM'
    ,model=='divnn'~'5. DI-VNN'
    ,TRUE~''
  )) %>%
  
  # Show results as a table.
  kable() %>%
  kable_classic()
```

```{r Show calibration plot after calibration, eval=FALSE, include=FALSE}
calib_model %>%
  # Compute true probability interval.
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$pred
        ,event=round(event*20)/20#round(event,1)
        ,obs=as.integer(obs=='event')
      ) %>%
      group_by(event) %>%
      summarize(
        model=factor(X,names(Y))
        ,obs=mean(obs)
        ,lb=mean(obs)-qnorm(0.975)*sqrt(mean(obs)*(1-mean(obs))/n())
        ,ub=mean(obs)+qnorm(0.975)*sqrt(mean(obs)*(1-mean(obs))/n())
      )
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'1. Causal LR'
    ,model=='pc_elnet'~'2. PC-LR'
    ,model=='pc_rf'~'3. PC-RF'
    ,model=='pc_gbm'~'4. PC-GBM'
    ,model=='divnn'~'5. DI-VNN'
    ,TRUE~''
  )) %>%
  
  # Create calibration plot.
  qplot(event,obs,data=.) +
  geom_linerange(aes(ymin=lb,ymax=ub)) +
  geom_abline(lty=2) +
  facet_wrap(~model) +
  coord_equal() +
  scale_x_continuous('Predicted probability',limits=0:1) +
  scale_y_continuous('True probability',limits=0:1) +
  ggtitle('B. After calibration') +
  theme(axis.text.x=element_text(angle=90,vjust=0.5,hjust=1))
```

```{r Show probability distribution after calibration, eval=FALSE, include=FALSE}
calib_model %>%
  # Compute number of sample per predicted probability.
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$pred
        ,event=round(event*20)/20#round(event,1)
        ,obs=as.integer(obs=='event')
      ) %>%
      group_by(event) %>%
      summarize(
        model=factor(X,names(Y))
        ,n=n()
      )
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'1. Causal LR'
    ,model=='pc_elnet'~'2. PC-LR'
    ,model=='pc_rf'~'3. PC-RF'
    ,model=='pc_gbm'~'4. PC-GBM'
    ,model=='divnn'~'5. DI-VNN'
    ,TRUE~''
  )) %>%
  
  # Create histogram of the predicted probability.
  qplot(event,n,data=.,geom='col',na.rm=T) +
  facet_wrap(~model,scales='free_y') +
  theme(axis.text.x=element_text(angle=90,vjust=0.5,hjust=1))
```

```{r Show calibration measures after calibration, eval=FALSE, include=FALSE}
calib_model %>%
  # Compute true probability.
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$pred
        ,event=round(event*20)/20#round(event,2)
        ,obs=as.integer(obs=='event')
      ) %>%
      group_by(event) %>%
      summarize(
        model=factor(X,names(Y))
        ,obs=mean(obs)
      )
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'1. Causal LR'
    ,model=='pc_elnet'~'2. PC-LR'
    ,model=='pc_rf'~'3. PC-RF'
    ,model=='pc_gbm'~'4. PC-GBM'
    ,model=='divnn'~'5. DI-VNN'
    ,TRUE~''
  )) %>%
  
  # Fitting a line to get the intercept and slope.
  group_by(model) %>%
  do(tidy(lm(obs~event,data=.))) %>%
  
  # Wrap up.
  mutate(term=str_remove_all(term,'\\(|\\)') %>% str_to_lower()) %>%
  pivot_wider(
    model,names_from=c('term','term'),values_from=c('estimate','std.error')
  ) %>%
  select(model,estimate_intercept,std.error_intercept,everything()) %>%
  mutate_at(colnames(.) %>% .[.!='model'],function(x)round(x,2)) %>%
  
  # Show results as a table.
  kable() %>%
  kable_classic()
```

```{r Compare ROC among models after calibration, eval=FALSE, include=FALSE}
calib_model %>%
  # Compute the interval estimates.
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$results
        ,ROC_lb=ROC-qnorm(0.975)*ROCSD
        ,ROC_ub=ROC+qnorm(0.975)*ROCSD
      ) %>%
      mutate(model=X) %>%
      select(model,ROC,ROC_lb,ROC_ub)
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'1. Causal LR'
    ,model=='pc_elnet'~'2. PC-LR'
    ,model=='pc_rf'~'3. PC-RF'
    ,model=='pc_gbm'~'4. PC-GBM'
    ,model=='divnn'~'5. DI-VNN'
    ,TRUE~''
  )) %>%
  mutate(model=reorder(model,ROC)) %>%
  
  # Plot the comparison of the AUROCs.
  qplot(model,ROC,data=.) +
  geom_errorbar(aes(ymin=ROC_lb,ymax=ROC_ub),width=0.35) +
  geom_hline(yintercept=0.5,lty=2) +
  coord_flip()
```

```{r Compare AUC of ROC among models after calibration, eval=FALSE, include=FALSE}
calib_model %>%
  # Compute interval estimates.
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$results
        ,ROC_lb=ROC-qnorm(0.975)*ROCSD
        ,ROC_ub=ROC+qnorm(0.975)*ROCSD
      ) %>%
      mutate(model=X) %>%
      select(model,ROC,ROC_lb,ROC_ub)
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'1. Causal LR'
    ,model=='pc_elnet'~'2. PC-LR'
    ,model=='pc_rf'~'3. PC-RF'
    ,model=='pc_gbm'~'4. PC-GBM'
    ,model=='divnn'~'5. DI-VNN'
    ,TRUE~''
  )) %>%
  
  # Show results as a table.
  kable() %>%
  kable_classic()
```

```{r Compute ROC, include=FALSE}
roc=
  
  # Create ROC table per model.
  calib_model %>%
  lapply(X=names(.),Y=.,function(X,Y){
    Y[[X]]$pred %>%
      
      # Get the prediction table.
      select(Resample,rowIndex,event,obs) %>%
      setNames(c('subset','index','score','outcome')) %>%
      
      # Preprocess the table.
      mutate(outcome=as.double(outcome=='event')) %>%
      left_join(
        select(.,index) %>%
          filter(!duplicated(.)) %>%
          arrange(index) %>%
          cbind(
            data.frame(
                key=paste0('th_',str_pad(0:100,3,'left','0'))
                ,value=seq(0,1,len=101)
              ) %>%
              spread(key,value)
          )
        ,by='index'
      ) %>%
      gather(key,th,-subset,-index,-score,-outcome) %>%
      select(-key) %>%
      
      # Compute confusion matrices.
      mutate(pred=as.integer(score>th)) %>%
      mutate(
        tp=as.integer(outcome==1 & pred==1)
        ,fn=as.integer(outcome==1 & pred==0)
        ,fp=as.integer(outcome==0 & pred==1)
        ,tn=as.integer(outcome==0 & pred==0)
      ) %>%
      select(-index,-score,-outcome,-pred) %>%
      group_by(subset,th) %>%
      summarize_all(sum) %>%
      ungroup() %>%
      
      # Compute evaluation metrics.
      mutate(
        tpr=tp/(tp+fn+1e-17)
        ,tnr=tn/(tn+fp+1e-17)
        ,ppv=tp/(tp+fp+1e-17)
        ,npv=tn/(tn+fn+1e-17)
        ,nb=(tp-fp*th/((1-th)+1e-17))/(tp+fp+fn+tn)
        ,p=(tp+fn)/(tp+fp+fn+tn)
      ) %>%
      select(-subset,-tp,-fn,-fp,-tn) %>%
      group_by(th) %>%
      
      # Compute the interval estimates.
      summarize_all(function(x){
        y=mean(x)+(-1:1)*qnorm(0.975)*sd(x)/sqrt(length(x))
        paste0(y,collapse='|')
      }) %>%
      gather(metric,interval,-th) %>%
      separate(interval,c('lb','avg','ub'),sep='\\|') %>%
      mutate_at(c('lb','avg','ub'),as.numeric) %>%
      mutate_at(c('lb','avg','ub'),function(x){
        round(ifelse(x<0,0,ifelse(x>1,1,x)),4)
      }) %>%
      
      # Wrap up.
      mutate(model=X) %>%
      select(model,everything()) %>%
      gather(bound,value,-th,-metric,-model) %>%
      spread(metric,value)
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'Causal RR'
    ,model=='pc_elnet'~'PC-ENR'
    ,model=='pc_rf'~'PC-RF'
    ,model=='pc_gbm'~'PC-GBM'
    ,model=='divnn'~'DI-VNN'
    ,TRUE~''
  )) %>%
  mutate(
    model=factor(model,c('Causal RR','PC-ENR','PC-RF','PC-GBM','DI-VNN'))
  )

# Get optimum threshold per model.
opt_th=
  roc %>%
  filter(bound=='avg') %>%
  select(model,th,tpr,tnr) %>%
  mutate(avg_acc=(tpr+tnr)/2) %>%
  arrange(model,desc(avg_acc),th,desc(tpr),desc(tnr)) %>%
  group_by(model) %>%
  slice(1) %>%
  ungroup()

# Get sensitive threshold per model.
sens_th=
  roc %>%
  filter(bound=='avg') %>%
  select(model,th,tpr,tnr) %>%
  mutate(tpr=round(tpr,2)) %>%
  right_join(
    expand.grid(model=.$model %>% .[!duplicated(.)],tpr=seq(0,1,len=101))
    ,by=c('model','tpr')
  ) %>%
  arrange(model) %>%
  group_by(model) %>%
  arrange(model,tpr,tnr,th) %>%
  mutate_at(c('tnr','th'),na_interpolation) %>%
  filter(tpr>=0.95) %>%
  slice(1) %>%
  ungroup()

# Get specific threshold per model.
spec_th=
  roc %>%
  filter(bound=='avg') %>%
  select(model,th,tpr,tnr) %>%
  mutate(tnr=round(tnr,2)) %>%
  right_join(
    expand.grid(model=.$model %>% .[!duplicated(.)],tnr=seq(0,1,len=101))
    ,by=c('model','tnr')
  ) %>%
  arrange(model) %>%
  group_by(model) %>%
  arrange(tnr,tpr,th) %>%
  mutate_at(c('tpr','th'),na_interpolation) %>%
  filter(tnr>=0.95) %>%
  slice(1) %>%
  ungroup()
```

```{r Create plot components, include=FALSE}
# Create table for calibration plot of the calibrated models.
calibration_plot_data=
  
  # Compute the interval estimates of true probabilities.
  calib_model %>%
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$pred
        ,event=round(event,2)
        ,obs=as.integer(obs=='event')
      ) %>%
      group_by(event) %>%
      summarize(
        model=factor(X,names(Y))
        ,obs=mean(obs)
        ,lb=mean(obs)-qnorm(0.975)*sqrt(mean(obs)*(1-mean(obs))/n())
        ,ub=mean(obs)+qnorm(0.975)*sqrt(mean(obs)*(1-mean(obs))/n())
        ,n=n()
      )
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'Causal RR'
    ,model=='pc_elnet'~'PC-ENR'
    ,model=='pc_rf'~'PC-RF'
    ,model=='pc_gbm'~'PC-GBM'
    ,model=='divnn'~'DI-VNN'
    ,TRUE~''
  )) %>%
  mutate(
    model=factor(model,c('Causal RR','PC-ENR','PC-RF','PC-GBM','DI-VNN'))
  ) %>%
  
  # Compute the calibration measures.
  left_join(
    group_by(.,model) %>%
      do(tidy(lm(obs~event,data=.))) %>%
      mutate(term=str_remove_all(str_to_lower(term),'[:punct:]')) %>%
      mutate(
        avg=estimate
        ,ci=qnorm(0.975)*std.error
      ) %>%
      select(model,term,avg,ci) %>%
      pivot_wider(names_from='term',values_from=c('avg','ci'))
    ,by='model'
  ) %>%
  group_by(model) %>%
  mutate(brier=sqrt(sum(n*(event-obs)^2)/sum(n))) %>%
  ungroup()

# Plot the calibration table.
calibration_plot=
  
  # Plot the table.
  calibration_plot_data %>%
  filter(!model%in%c('Causal RR','PC-RF')) %>%
  qplot(event,obs,data=.) +
  geom_linerange(aes(ymin=lb,ymax=ub)) +
  geom_abline(lty=2) +
  geom_smooth(method='lm',formula=y~x,color='black') +
  
  # Annotate the calibration measures.
  geom_text(
    aes(
      x=0,y=0.2
      ,label=
        ifelse(
          event==0.0#0.3
          ,paste0(
            'Intercept ',formatC(round(avg_intercept,2),decimal.mark='.')
            ,' ± '
            ,formatC(round(ci_intercept,2),decimal.mark='.')
            ,'\n'
            ,'Slope ',formatC(round(avg_event,2),decimal.mark='.')
            ,' ± '
            ,formatC(round(ci_event,2),decimal.mark='.')
            ,'\n'
            ,'Brier score ',format(brier,decimal.mark='.',scientific=T,digits=2)
          )
          ,NA
        )
    )
    ,family='sans'
    ,size=3
    ,hjust=0
    ,vjust=1
    ,alpha=1
    ,na.rm=T
  ) +
  
  # Customized plot.
  facet_wrap(~model,ncol=5) +
  # coord_equal() +
  scale_x_continuous('Predicted probability',limits=c(0,0.1)) +
  scale_y_continuous(
    'True probability\n(95% CI)',limits=c(0,0.2),breaks=seq(0,1,0.05)
    ,labels=scales::number_format(accuracy=0.05,decimal.mark='.')
  ) +
  theme(
    # axis.text.x=element_text(angle=90,vjust=0.5,hjust=1)
    axis.ticks.x=element_blank()
    ,axis.text.x=element_blank()
    ,axis.text.y=element_text(family='sans')
    ,axis.title.x=element_blank()
    ,axis.title.y=element_text(hjust=0.3,family='sans')
    ,strip.text=element_text(family='sans')
  )

# Create probability distribution table of events for the calibrated models.
event_dist_data=
  
  # Compute the numbers of instances per predicted probability for each model.
  calib_model %>%
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$pred
        ,event=round(event,2)
        ,obs=as.integer(obs=='event')
      ) %>%
      filter(obs==1) %>%
      group_by(event) %>%
      summarize(
        model=factor(X,names(Y))
        ,n=n()/10e+4
      )
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'Causal RR'
    ,model=='pc_elnet'~'PC-ENR'
    ,model=='pc_rf'~'PC-RF'
    ,model=='pc_gbm'~'PC-GBM'
    ,model=='divnn'~'DI-VNN'
    ,TRUE~''
  )) %>%
  mutate(
    model=factor(model,c('Causal RR','PC-ENR','PC-RF','PC-GBM','DI-VNN'))
  )

# Plot the probability distribution of events for each model, as histogram.
event_dist=
  event_dist_data %>%
  filter(!model%in%c('Causal RR','PC-RF')) %>%
  qplot(event,n,data=.,geom='col',na.rm=T) +
  geom_vline(
    data=
      spec_th %>%
      filter(!model%in%c('Causal RR','PC-RF'))
    ,aes(xintercept=th)
    ,lty=2
  ) +
  facet_wrap(~model,ncol=5) +
  scale_x_continuous('Predicted probability',limits=c(0,0.1)) +
  scale_y_continuous(
    'Events per\n10,000 visits',breaks=seq(0,0.8,0.01)
    ,labels=scales::number_format(accuracy=0.01,decimal.mark='.')
  ) +
  theme(
    # axis.text.x=element_text(angle=90,vjust=0.5,hjust=1)
    axis.ticks.x=element_blank()
    ,axis.text.x=element_blank()
    ,axis.text.y=element_text(family='sans')
    ,axis.title.x=element_blank()
    ,axis.title.y=element_text(hjust=0.3,family='sans')
    ,strip.text.x=element_blank()
  )

# Create probability distribution table of nonevents for the calibrated models.
nonevent_dist_data=
  
  # Compute the numbers of instances per predicted probability for each model.
  calib_model %>%
  lapply(X=names(.),Y=.,function(X,Y){
    mutate(
        Y[[X]]$pred
        ,event=round(event,2)
        ,obs=as.integer(obs=='event')
      ) %>%
      filter(obs==0) %>%
      group_by(event) %>%
      summarize(
        model=factor(X,names(Y))
        ,n=n()/10e+5
      )
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'Causal RR'
    ,model=='pc_elnet'~'PC-ENR'
    ,model=='pc_rf'~'PC-RF'
    ,model=='pc_gbm'~'PC-GBM'
    ,model=='divnn'~'DI-VNN'
    ,TRUE~''
  )) %>%
  mutate(
    model=factor(model,c('Causal RR','PC-ENR','PC-RF','PC-GBM','DI-VNN'))
  )

# Plot the probability distribution of nonevents for each model, as histogram.
nonevent_dist=
  nonevent_dist_data %>%
  filter(!model%in%c('Causal RR','PC-RF')) %>%
  qplot(event,n,data=.,geom='col',na.rm=T) +
  geom_vline(
    data=
      spec_th %>%
      filter(!model%in%c('Causal RR','PC-RF'))
    ,aes(xintercept=th)
    ,lty=2
  ) +
  facet_wrap(~model,ncol=5) +
  scale_x_continuous(
    'Predicted probability',limits=c(0,0.1)
    ,labels=scales::number_format(accuracy=0.01,decimal.mark='.')
  ) +
  scale_y_reverse(
    'Nonevents per\n100,000 visits',breaks=seq(0,0.8,0.05),limits=c(0.125,0)
    ,labels=scales::number_format(accuracy=0.01,decimal.mark='.')
  ) +
  theme(
    axis.title=element_text(family='sans')
    ,axis.text.x=element_text(angle=90,vjust=0.5,hjust=1,family='sans')
    ,axis.text.y=element_text(family='sans')
    ,strip.text.x=element_blank()
    ,strip.text.y=element_text(family='sans')
  )

# Decision curve analysis
dca=
  roc %>%
  filter(bound=='avg') %>%
  arrange(model,desc(nb)) %>%
  group_by(model,nb) %>%
  slice(1) %>%
  ungroup() %>%
  filter(!model%in%c('Causal RR','PC-RF')) %>%
  ggplot(aes(th,nb)) +
  geom_line(
    data=
      roc %>%
      filter(bound=='avg') %>%
      select(model,p) %>%
      filter(!duplicated(.)) %>%
      mutate(th=0,nb=p) %>%
      rbind(mutate(.,th=p,nb=0)) %>%
      arrange(model,th,desc(nb)) %>%
      filter(!model%in%c('Causal RR','PC-RF'))
    ,lty=1,size=1
  ) +
  geom_hline(yintercept=0,lty=1,size=1) +
  geom_text(
    data=
      spec_th %>%
      filter(!model%in%c('Causal RR','PC-RF'))
    ,aes(x=th,y=0.005,label=paste0(round(th,3),'\n(95% specificity)'))
    ,size=3,hjust=-0.15,vjust=1,family='sans'
  ) +
  geom_vline(
    data=
      spec_th %>%
      filter(!model%in%c('Causal RR','PC-RF'))
    ,aes(xintercept=th)
    ,lty=2
  ) +
  geom_line() +
  geom_point() +
  facet_wrap(~model,ncol=5) +
  scale_x_continuous(
    'Threshold',limits=c(0,0.1)
    ,labels=scales::number_format(accuracy=0.01,decimal.mark='.')
  ) +
  scale_y_continuous(
    'Net benefit'
    ,labels=scales::number_format(accuracy=0.0001,decimal.mark='.')
  ) +
  theme(
    axis.title=element_text(family='sans')
    ,axis.text.x=element_text(angle=90,vjust=0.5,hjust=1,family='sans')
    ,axis.text.y=element_text(family='sans')
    ,strip.text.x=element_blank()
    ,strip.text.y=element_text(family='sans')
  )
```

```{r Show image of Figure 2 of the main text, echo=FALSE, fig.height=5.85827, fig.width=7.08661}
# fig.height=5.85827, fig.width=7.08661 on top of this chunk if shown here
suppressWarnings(ggarrange(
    ggarrange(
      calibration_plot
      ,event_dist
      ,nonevent_dist
      ,heights=c(1.5,1,1.5)
      ,labels=c('','','')
      ,ncol=1,nrow=3
    )
    ,dca
    ,heights=c(4,1.85827)
    ,labels=c('a','b')
    ,ncol=1,nrow=2
  ))
```

## Model weights

```{r Create empty list for tables of model weight, include=FALSE}
model_weight=list()
```

```{r Prepare weight table of PC model, include=FALSE}
model_weight$pc=
  composition(pw_int_rsdr) %>%
  rownames_to_column(var='Predictor') %>%
  left_join(
    rbind(
      annotation %>%
        rename(Predictor=code,Description=desc)
      ,dag$baseline_nodes %>%
        mutate(label=paste0('causal_',label)) %>%
        rename(Predictor=label,Description=name)
    )
    ,by='Predictor'
  ) %>%
  arrange(factor(Predictor,int_nps_eol_p$key)) %>%
  select(Predictor,Description,everything())
```

```{r Show weights of PC, eval=FALSE, include=FALSE}
model_weight$pc %>%
  kable() %>%
  kable_classic()
```

```{r Prepare weight table of PC-ENR, include=FALSE}
model_weight$pc_elnet=
  coef(model$pc_elnet$finalModel,model$pc_elnet$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var='term') %>%
  mutate(term=str_remove_all(term,'\\`|\\(|\\)')) %>%
  setNames(c('term','estimate')) %>%
  rename(weight=estimate) %>%
  arrange(desc(weight)) %>%
  setNames(str_to_sentence(str_replace_all(colnames(.),'_',' ')))
```

```{r Show weights of PC-ENR, eval=FALSE, include=FALSE}
model_weight$pc_elnet %>%
  kable() %>%
  kable_classic()
```

```{r Prepare weight table of PC-GBM, include=FALSE}
model_weight$pc_gbm=
  varImp(model$pc_gbm)[[1]] %>%
  setNames('variable_importance') %>%
  rownames_to_column(var='term') %>%
  rename(`variable importance`=variable_importance) %>%
  arrange(desc(`variable importance`)) %>%
  setNames(str_to_sentence(str_replace_all(colnames(.),'_',' ')))
```

```{r Show weights of PC-GBM, eval=FALSE, include=FALSE}
model_weight$pc_gbm %>%
  kable() %>%
  kable_classic()
```

```{r Prepare weight table of differential analysis, include=FALSE}
model_weight$fit=
  
  # Get differential analysis results.
  input$fit %>%
  rownames_to_column(var='Predictor') %>%
  arrange(adj.P.Val,P.Value,desc(abs(AveExpr))) %>%
  
  # Clean up data.
  mutate(
    P.Value=
      ifelse(
        P.Value<0.0000001
        ,'p<1e-08'
        ,format(P.Value,scientific=T,digits=1)
      )
    ,adj.P.Val=
      ifelse(
        adj.P.Val<0.0000001
        ,'p<1e-08'
        ,format(adj.P.Val,scientific=T,digits=1)
      )
  ) %>%
  
  # Clean up naming.
  left_join(
    rbind(
      annotation %>%
        rename(Predictor=code,Description=desc)
      ,dag$baseline_nodes %>%
        mutate(label=paste0('causal_',label)) %>%
        rename(Predictor=label,Description=name)
    )
    ,by='Predictor'
  ) %>%
  select(Predictor,Description,everything()) %>%
  setNames(
    ifelse(names(.)=='logFC','log(Fold change)',
    ifelse(names(.)=='AveExpr','Normalized average of global value',
    ifelse(names(.)=='t','t statistic',
    ifelse(names(.)=='P.Value','p-value',
    ifelse(names(.)=='adj.P.Val','FDR or adjusted p-value',
    ifelse(names(.)=='B','B statistic',names(.)))))))
  )
```

```{r Show differential analysis, eval=FALSE, include=FALSE}
model_weight$fit %>%
  kable() %>%
  kable_classic()
```

```{r Visualization tables, include=FALSE}
if(run_heavy_computation){
  visualization=list()
  
  cat('Get ontonet visualisation table.\n')
  visualization$ontonet=
    output %>%
    viz.ontonet(
      feature=F
      ,eval.results=modeling_divnn$evaluation
      ,eval.metric='roc'
      ,eval.pal=c('#E64B35FF','#00A087FF')
    )
  
  cat('Get ontoarray visualisation table.\n')
  visualization$ontoarray=
    output %>%
    viz.ontoarray(modeling_divnn$ontonet,batch_size=512,verbose=T)
  
  saveRDS(visualization,'data/visualization.rds')
}else{
  cat(readRDS('data/log.rds')[['visualization']])
  visualization=readRDS('data/visualization.rds')
}
```

```{r Prepare weight table of DI-VNN, include=FALSE}
model_weight$divnn=
  
  # Get the classification DI-VNN weights of the representation layers.
  visualization$ontoarray %>%
  lapply(function(x){
    x$ontotype %>%
      lapply(X=seq(nrow(.)),Y=.,Z=x$output,function(X,Y,Z){
        K=Z[Y$x[X],Y$y[X],Y$z[X]]
        if(K==0){
          NULL
        }else{
          K
        }
      }) %>%
      setNames(x$ontotype$feature)
  }) %>%
  setNames(names(visualization$ontoarray)) %>%
  unlist() %>%
  data.frame(output=.) %>%
  rownames_to_column(var='ontology') %>%
  
  # Get the predictor annotation.
  separate(ontology,c('ontology','predictor'),sep='\\.') %>%
  left_join(
    rbind(
        annotation %>%
          rename(predictor=code,description=desc)
        ,dag$baseline_nodes %>%
          mutate(label=paste0('causal_',label)) %>%
          rename(predictor=label,description=name)
      )
    ,by='predictor'
  ) %>%
  
  # Get the predictor position.
  left_join(
    output %>%
      fData() %>%
      rownames_to_column(var='xyz') %>%
      rename(predictor=feature) %>%
      select(xyz,predictor) %>%
      filter(!is.na(predictor)) %>%
      mutate(xyz=str_remove_all(xyz,'x')) %>%
      separate(xyz,c('dimension_1','yz'),sep='y') %>%
      separate(yz,c('dimension_2','dimension_3'),sep='z')
    ,by='predictor'
  ) %>%
  
  # Wrap up.
  arrange(ontology,dimension_3,dimension_2,dimension_1,predictor) %>%
  select(
    ontology
    ,dimension_1
    ,dimension_2
    ,dimension_3
    ,predictor
    ,description
    ,everything()
  ) %>%
  setNames(str_to_sentence(str_replace_all(colnames(.),'_',' ')))
```

```{r Show weights of DI-VNN, eval=FALSE, include=FALSE}
model_weight$divnn %>%
  kable() %>%
  kable_classic()
```

## Model explainability

```{r Create an empty list to save counterfactual explaination, include=FALSE}
cx=list()
```

```{r Counterfactual explaination of PC-ENR, include=FALSE}
if(run_heavy_computation){
  cx$pc_elnet=
    pw_pc %>%
    fData() %>%
    colnames() %>%
    pblapply(function(x){
      
      Z=lapply(X=c(0,1,2),Y=x,function(X,Y){
          if(X==2){
            Z=pw_hlin %>%
              `exprs<-`(
                exprs(.) %>%
                  sweep(
                    MARGIN=1
                    ,FUN='*'
                    ,STATS=ifelse(rownames(.)==Y,0,1)
                  )
              ) %>%
              `exprs<-`(
                exprs(.) %>%
                  sweep(
                    MARGIN=1
                    ,FUN='+'
                    ,STATS=ifelse(rownames(.)==Y,1,0)
                  )
              )
          }else{
            Z=pw_hlin %>%
              `exprs<-`(
                exprs(.) %>%
                  sweep(
                    MARGIN=1
                    ,FUN='*'
                    ,STATS=ifelse(rownames(.)==Y,X,1)
                  )
              )
          }
          Z %>%
            .[,pData(protocolData(.))[['int']]] %>%
            transformation(
              rsdr_object=pw_int_rsdr
              ,verbose=F
            ) %>%
            .[preproc(pw_pc) %>%
                .$pve %>%
                sort(decreasing=T) %>%
                names() %>%
                .[1:14]
              ,] %>%
            get_set() %>%
            .[!rownames(.)%in%training_parameters$pre_calib_set,,drop=F] %>%
            cbind(
              suppressWarnings(predict(model$pc_elnet,newdata=.,type='prob'))
            ) %>%
            select(event,outcome) %>%
            cbind(
              suppressWarnings(
                  predict(calib_model$pc_elnet,newdata=.,type='prob')
                ) %>%
                rename_all(function(x)paste0(x,'2'))
            ) %>%
            select(-event) %>%
            rename_all(function(x)str_remove_all(x,'2')) %>%
            mutate(obs=outcome) %>%
            select(-outcome) %>%
            rownames_to_column(var='id') %>%
            left_join(
              pw_hlin %>%
                .[,pData(protocolData(.))[['int']]] %>%
                get_set() %>%
                rownames_to_column(var='id') %>%
                select_at(c('id',Y)) %>%
                setNames(c('id','predictor')) %>%
                mutate(predictor=as.integer(predictor>0))
              ,by='id'
            ) %>%
            mutate(obs=as.integer(obs=='event')) %>%
            column_to_rownames(var='id')
          
        }) %>%
        lapply(X=1,Y=.,function(X,Y){
          Y[[1]] %>%
            rownames_to_column(var='id') %>%
            select(id,event,obs,predictor) %>%
            rename(event0=event) %>%
            mutate(pred0=as.integer(event0>0.027)) %>%
            left_join(
              Y[[2]] %>%
                rownames_to_column(var='id') %>%
                select(id,event) %>%
                rename(event1=event) %>%
                mutate(pred1=as.integer(event1>0.027))
              ,by='id'
            ) %>%
            left_join(
              Y[[3]] %>%
                rownames_to_column(var='id') %>%
                select(id,event) %>%
                rename(event2=event) %>%
                mutate(pred2=as.integer(event2>0.027))
              ,by='id'
            )
        }) %>%
        .[[1]]
      
      Z %>%
        mutate(
          marginal_effect1=event1-event0
          ,marginal_effect2=event2-event0
        ) %>%
        lapply(X=1:30,Y=.,function(X,Y){
          suppressWarnings(set.seed(33+X,sample.kind=sample.kind))
          Z=Y %>%
            .[sample(seq(nrow(.)),nrow(.),T),]
          
          K=Z %>%
            summarize(
              marginal_effect1=mean(marginal_effect1)
              ,marginal_effect2=mean(marginal_effect2)
            ) %>%
            gather(metric,value)
          
          L=Z %>%
            group_by(predictor,pred1) %>%
            summarize(p_x0_y0=1-mean(event0)) %>%
            ungroup() %>%
            mutate(
              pn_obs=ifelse(predictor==1 & pred1==1,p_x0_y0,NA)
            ) %>%
            select(pn_obs) %>%
            gather(metric,value) %>%
            filter(!is.na(value))
          
          M=Z %>%
            group_by(predictor,pred1) %>%
            summarize(
              p_x1_y1=mean(event1)
              ,p_x2_y2=mean(event2)
            ) %>%
            ungroup() %>%
            mutate(
              ps_obs_pred1=ifelse(predictor==0 & pred1==0,p_x1_y1,NA)
              ,ps_obs_pred2=ifelse(predictor==0 & pred1==0,p_x2_y2,NA)
            ) %>%
            select(ps_obs_pred1,ps_obs_pred2) %>%
            gather(metric,value) %>%
            filter(!is.na(value))
          
          rbind(K,L,M)
            
        }) %>%
        do.call(rbind,.) %>%
        group_by(metric) %>%
        summarize(
          avg=mean(value)
          ,lb=mean(value)-qnorm(0.975)*sd(value)/sqrt(n())
          ,ub=mean(value)+qnorm(0.975)*sd(value)/sqrt(n())
        ) %>%
        mutate_at(c('avg','lb','ub'),round,4) %>%
        mutate(predictor=x)
      
    }) %>%
    do.call(rbind,.)
  
  saveRDS(cx$pc_elnet,'data/cx_pc_elnet.rds')
}else{
  cat(readRDS('data/log.rds')[['cx_pc_elnet']])
  cx$pc_elnet=readRDS('data/cx_pc_elnet.rds')
}
```

```{r Show CX of PC-ENR, echo=FALSE}
cx$pc_elnet %>%
  pblapply(X=seq(length(unique(.$predictor))),Y=.,Z=5,function(X,Y,Z){
    
    sufficiency='ps_obs_pred2'
    
    K=Y %>%
      lapply(X=c('pn_obs',sufficiency),Y=.,Z=X,function(X,Y,Z){
        K=Y %>%
          filter(metric==X) %>%
          arrange(desc(avg)) %>%
          slice(seq(Z)) %>%
          mutate(
            min=
              paste0(
                ifelse(X=='pn_obs','PN','PS')
                ,' min. '
                ,round(min(avg)*100,2)
                ,'%'
              )
          ) %>%
          mutate_at(c('avg','lb','ub'),function(x)paste0(x*100,'%')) %>%
          unite(int,lb,ub,sep=' to ') %>%
          mutate(int=paste0('(',int,')')) %>%
          unite(value,avg,int,sep=' ') %>%
          spread(metric,value)
        
        L=Y %>%
          filter(metric==ifelse(X=='pn_obs',sufficiency,'pn_obs')) %>%
          arrange(desc(avg)) %>%
          mutate_at(c('avg','lb','ub'),function(x)paste0(x*100,'%')) %>%
          unite(int,lb,ub,sep=' to ') %>%
          mutate(int=paste0('(',int,')')) %>%
          unite(value,avg,int,sep=' ') %>%
          spread(metric,value)
        
        K %>%
          left_join(L,by='predictor') %>%
          mutate(top=ifelse(X=='pn_obs','necessity','sufficiency')) %>%
          mutate_at(ifelse(X=='pn_obs',sufficiency,'pn_obs'),function(x){
            ifelse(is.na(x),'0% (0% to 0%)',x)
          })
      }) %>%
      do.call(rbind,.) %>%
      mutate(
        min=
          sapply(X=seq(nrow(.)),Y=.,function(X,Y){
            paste0(filter(Y,predictor==Y$predictor[X])$min,collapse=' and ')
          })
        ,top=
          sapply(X=seq(nrow(.)),Y=.,function(X,Y){
            paste0(filter(Y,predictor==Y$predictor[X])$top,collapse=' and ')
          })
      ) %>%
      filter(!duplicated(select(.,-min))) %>%
      filter(top=='necessity and sufficiency')
    
    if(nrow(K)>=Z){
      K
    }else{
      NULL
    }
    
  }) %>%
  .[[which(sapply(.,function(x)!is.null(x)))[1]]] %>%
  left_join(
    readRDS('data/annotation.rds') %>%
      rename(predictor=code) %>%
      rbind(
        dag$baseline_nodes %>%
          mutate(label=paste0('causal_',label)) %>%
          left_join(
            dag$measure_nodes %>%
              mutate(
                label=
                  paste0(
                    'causal_'
                    ,str_remove_all(label,'\\*')
                  )
              ) %>%
              rename(code=name)
            ,by='label'
          ) %>%
          mutate(code=ifelse(is.na(code),'',code)) %>%
          unite(desc,name,code,sep=' ') %>%
          rename(predictor=label) %>%
          select(predictor,desc)
      )
    ,by='predictor'
  ) %>%
  kable() %>%
  kable_classic()
```

```{r Counterfactual explaination of PC-GBM, include=FALSE}
if(run_heavy_computation){
  cx$pc_gbm=
    pw_pc[selected_pc$term,] %>%
    fData() %>%
    colnames() %>%
    pblapply(function(x){
      
      Z=lapply(X=c(0,1,2),Y=x,function(X,Y){
          if(X==2){
            Z=pw_hlin %>%
              `exprs<-`(
                exprs(.) %>%
                  sweep(
                    MARGIN=1
                    ,FUN='*'
                    ,STATS=ifelse(rownames(.)==Y,0,1)
                  )
              ) %>%
              `exprs<-`(
                exprs(.) %>%
                  sweep(
                    MARGIN=1
                    ,FUN='+'
                    ,STATS=ifelse(rownames(.)==Y,1,0)
                  )
              )
          }else{
            Z=pw_hlin %>%
              `exprs<-`(
                exprs(.) %>%
                  sweep(
                    MARGIN=1
                    ,FUN='*'
                    ,STATS=ifelse(rownames(.)==Y,X,1)
                  )
              )
          }
          Z %>%
            .[,pData(protocolData(.))[['int']]] %>%
            transformation(
              rsdr_object=pw_int_rsdr
              ,verbose=F
            ) %>%
            .[selected_pc$term,] %>%
            get_set() %>%
            .[!rownames(.)%in%training_parameters$pre_calib_set,,drop=F] %>%
            cbind(
              suppressWarnings(predict(model$pc_gbm,newdata=.,type='prob'))
            ) %>%
            select(event,outcome) %>%
            cbind(
              suppressWarnings(
                  predict(calib_model$pc_gbm,newdata=.,type='prob')
                ) %>%
                rename_all(function(x)paste0(x,'2'))
            ) %>%
            select(-event) %>%
            rename_all(function(x)str_remove_all(x,'2')) %>%
            mutate(obs=outcome) %>%
            select(-outcome) %>%
            rownames_to_column(var='id') %>%
            left_join(
              pw_hlin %>%
                .[,pData(protocolData(.))[['int']]] %>%
                get_set() %>%
                rownames_to_column(var='id') %>%
                select_at(c('id',Y)) %>%
                setNames(c('id','predictor')) %>%
                mutate(predictor=as.integer(predictor>0))
              ,by='id'
            ) %>%
            mutate(obs=as.integer(obs=='event')) %>%
            column_to_rownames(var='id')
          
        }) %>%
        lapply(X=1,Y=.,function(X,Y){
          Y[[1]] %>%
            rownames_to_column(var='id') %>%
            select(id,event,obs,predictor) %>%
            rename(event0=event) %>%
            mutate(pred0=as.integer(event0>0.025)) %>%
            left_join(
              Y[[2]] %>%
                rownames_to_column(var='id') %>%
                select(id,event) %>%
                rename(event1=event) %>%
                mutate(pred1=as.integer(event1>0.025))
              ,by='id'
            ) %>%
            left_join(
              Y[[3]] %>%
                rownames_to_column(var='id') %>%
                select(id,event) %>%
                rename(event2=event) %>%
                mutate(pred2=as.integer(event2>0.025))
              ,by='id'
            )
        }) %>%
        .[[1]]
      
      Z %>%
        mutate(
          marginal_effect1=event1-event0
          ,marginal_effect2=event2-event0
        ) %>%
        lapply(X=1:30,Y=.,function(X,Y){
          suppressWarnings(set.seed(33+X,sample.kind=sample.kind))
          Z=Y %>%
            .[sample(seq(nrow(.)),nrow(.),T),]
          
          K=Z %>%
            summarize(
              marginal_effect1=mean(marginal_effect1)
              ,marginal_effect2=mean(marginal_effect2)
            ) %>%
            gather(metric,value)
          
          L=Z %>%
            group_by(predictor,pred1) %>%
            summarize(p_x0_y0=1-mean(event0)) %>%
            ungroup() %>%
            mutate(
              pn_obs=ifelse(predictor==1 & pred1==1,p_x0_y0,NA)
            ) %>%
            select(pn_obs) %>%
            gather(metric,value) %>%
            filter(!is.na(value))
          
          M=Z %>%
            group_by(predictor,pred1) %>%
            summarize(
              p_x1_y1=mean(event1)
              ,p_x2_y2=mean(event2)
            ) %>%
            ungroup() %>%
            mutate(
              ps_obs_pred1=ifelse(predictor==0 & pred1==0,p_x1_y1,NA)
              ,ps_obs_pred2=ifelse(predictor==0 & pred1==0,p_x2_y2,NA)
            ) %>%
            select(ps_obs_pred1,ps_obs_pred2) %>%
            gather(metric,value) %>%
            filter(!is.na(value))
          
          rbind(K,L,M)
            
        }) %>%
        do.call(rbind,.) %>%
        group_by(metric) %>%
        summarize(
          avg=mean(value)
          ,lb=mean(value)-qnorm(0.975)*sd(value)/sqrt(n())
          ,ub=mean(value)+qnorm(0.975)*sd(value)/sqrt(n())
        ) %>%
        mutate_at(c('avg','lb','ub'),round,4) %>%
        mutate(predictor=x)
      
    }) %>%
    do.call(rbind,.)
  
  saveRDS(cx$pc_gbm,'data/cx_pc_gbm.rds')
}else{
  cat(readRDS('data/log.rds')[['cx_pc_gbm']])
  cx$pc_gbm=readRDS('data/cx_pc_gbm.rds')
}
```

```{r Show CX of PC-GBM, echo=FALSE}
cx$pc_gbm %>%
  pblapply(X=seq(length(unique(.$predictor))),Y=.,Z=5,function(X,Y,Z){
    
    sufficiency='ps_obs_pred2'
    
    K=Y %>%
      lapply(X=c('pn_obs',sufficiency),Y=.,Z=X,function(X,Y,Z){
        K=Y %>%
          filter(metric==X) %>%
          arrange(desc(avg)) %>%
          slice(seq(Z)) %>%
          mutate(
            min=
              paste0(
                ifelse(X=='pn_obs','PN','PS')
                ,' min. '
                ,round(min(avg)*100,2)
                ,'%'
              )
          ) %>%
          mutate_at(c('avg','lb','ub'),function(x)paste0(x*100,'%')) %>%
          unite(int,lb,ub,sep=' to ') %>%
          mutate(int=paste0('(',int,')')) %>%
          unite(value,avg,int,sep=' ') %>%
          spread(metric,value)
        
        L=Y %>%
          filter(metric==ifelse(X=='pn_obs',sufficiency,'pn_obs')) %>%
          arrange(desc(avg)) %>%
          mutate_at(c('avg','lb','ub'),function(x)paste0(x*100,'%')) %>%
          unite(int,lb,ub,sep=' to ') %>%
          mutate(int=paste0('(',int,')')) %>%
          unite(value,avg,int,sep=' ') %>%
          spread(metric,value)
        
        K %>%
          left_join(L,by='predictor') %>%
          mutate(top=ifelse(X=='pn_obs','necessity','sufficiency')) %>%
          mutate_at(ifelse(X=='pn_obs',sufficiency,'pn_obs'),function(x){
            ifelse(is.na(x),'0% (0% to 0%)',x)
          })
      }) %>%
      do.call(rbind,.) %>%
      mutate(
        min=
          sapply(X=seq(nrow(.)),Y=.,function(X,Y){
            paste0(filter(Y,predictor==Y$predictor[X])$min,collapse=' and ')
          })
        ,top=
          sapply(X=seq(nrow(.)),Y=.,function(X,Y){
            paste0(filter(Y,predictor==Y$predictor[X])$top,collapse=' and ')
          })
      ) %>%
      filter(!duplicated(select(.,-min))) %>%
      filter(top=='necessity and sufficiency')
    
    if(nrow(K)>=Z){
      K
    }else{
      NULL
    }
    
  }) %>%
  .[[which(sapply(.,function(x)!is.null(x)))[1]]] %>%
  left_join(
    readRDS('data/annotation.rds') %>%
      rename(predictor=code) %>%
      rbind(
        dag$baseline_nodes %>%
          mutate(label=paste0('causal_',label)) %>%
          left_join(
            dag$measure_nodes %>%
              mutate(
                label=
                  paste0(
                    'causal_'
                    ,str_remove_all(label,'\\*')
                  )
              ) %>%
              rename(code=name)
            ,by='label'
          ) %>%
          mutate(code=ifelse(is.na(code),'',code)) %>%
          unite(desc,name,code,sep=' ') %>%
          rename(predictor=label) %>%
          select(predictor,desc)
      )
    ,by='predictor'
  ) %>%
  kable() %>%
  kable_classic()
```

```{r Counterfactual explaination of DI-VNN, include=FALSE}
if(run_heavy_computation){
  cx$divnn=
    input$fit %>%
    rownames() %>%
    pblapply(function(x){
      cat('\n',x,'\n')
      Z=lapply(X=c(0,1,2),Y=x,function(X,Y){
          if(X==2){
            Z=pw_hlin %>%
              `exprs<-`(
                exprs(.) %>%
                  sweep(
                    MARGIN=1
                    ,FUN='*'
                    ,STATS=ifelse(rownames(.)==Y,0,1)
                  )
              ) %>%
              `exprs<-`(
                exprs(.) %>%
                  sweep(
                    MARGIN=1
                    ,FUN='+'
                    ,STATS=ifelse(rownames(.)==Y,1,0)
                  )
              )
          }else{
            Z=pw_hlin %>%
              `exprs<-`(
                exprs(.) %>%
                  sweep(
                    MARGIN=1
                    ,FUN='*'
                    ,STATS=ifelse(rownames(.)==Y,X,1)
                  )
              )
          }
          
          Z=Z %>%
            .[,pData(protocolData(.))[['int']]] %>%
            test_transformer(
              SGD1bit_fit=input$fit
              ,similarity=input$similarity
              ,mapping=input$mapping
              ,ontology=input$ontology
              ,ranked=T
              ,dims=7
              ,decreasing=F
              ,seed_num=33
            )
          
          modeling_divnn$ontonet %>%
            
            # Predict the outcome.
            predict_generator(
              generator=
                generator.ontoarray(
                  Z
                  ,seq(ncol(Z))
                  ,batch_size=512
                )
              ,steps=ceiling(ncol(Z)/512)
              ,verbose=1
            ) %>%
            
            # Give back the name of the DI-VNN ontologies.
            setNames(
              modeling_divnn$history$metrics %>%
                names() %>%
                .[str_detect(.,'val_')
                  &str_detect(.,'_loss')
                  &str_detect(.,'ONT|root')] %>%
                str_remove_all('val_|_loss')
            ) %>%
            
            # Set back number of instances, that is changed due to batch sizing.
            lapply(function(y){
              y[seq(ncol(Z)),,drop=F]
            }) %>%
            
            # Combine with the outcome data.
            c(list(outcome=Z$outcome)) %>%
            as.data.frame() %>%
            select(root,outcome) %>%
            mutate(
              outcome=
                factor(
                  ifelse(outcome==1,'event','nonevent')
                  ,c('nonevent','event')
                )
            ) %>%
            
            # Mimic the standard input of evalm.
            rename(event=root) %>%
            mutate(nonevent=event) %>%
            select(nonevent,everything()) %>%
            `rownames<-`(colnames(Z)) %>%
            cbind(
              suppressWarnings(predict(calib_model$divnn,newdata=.,type='prob')) %>%
                rename_all(function(x)paste0(x,'2'))
            ) %>%
            select(-nonevent,-event) %>%
            rename_all(function(x)str_remove_all(x,'2')) %>%
            mutate(obs=outcome) %>%
            select(-outcome) %>%
            rownames_to_column(var='id') %>%
            left_join(
              pw_hlin %>%
                .[,pData(protocolData(.))[['int']]] %>%
                get_set() %>%
                rownames_to_column(var='id') %>%
                select_at(c('id',Y)) %>%
                setNames(c('id','predictor')) %>%
                mutate(predictor=as.integer(predictor>0))
              ,by='id'
            ) %>%
            mutate(obs=as.integer(obs=='event')) %>%
            column_to_rownames(var='id')
        
        }) %>%
        lapply(X=1,Y=.,function(X,Y){
          Y[[1]] %>%
            rownames_to_column(var='id') %>%
            select(id,event,obs,predictor) %>%
            rename(event0=event) %>%
            mutate(pred0=as.integer(event0>0.017)) %>%
            left_join(
              Y[[2]] %>%
                rownames_to_column(var='id') %>%
                select(id,event) %>%
                rename(event1=event) %>%
                mutate(pred1=as.integer(event1>0.017))
              ,by='id'
            ) %>%
            left_join(
              Y[[3]] %>%
                rownames_to_column(var='id') %>%
                select(id,event) %>%
                rename(event2=event) %>%
                mutate(pred2=as.integer(event2>0.017))
              ,by='id'
            )
        }) %>%
        .[[1]]
      
      K=Z %>%
        mutate(
          marginal_effect1=event1-event0
          ,marginal_effect2=event2-event0
        ) %>%
        lapply(X=1:30,Y=.,function(X,Y){
          suppressWarnings(set.seed(33+X,sample.kind=sample.kind))
          Z=Y %>%
            .[sample(seq(nrow(.)),nrow(.),T),]
          
          K=Z %>%
            summarize(
              marginal_effect1=mean(marginal_effect1)
              ,marginal_effect2=mean(marginal_effect2)
            ) %>%
            gather(metric,value)
          
          L=Z %>%
            group_by(predictor,pred1) %>%
            summarize(p_x0_y0=1-mean(event0)) %>%
            ungroup() %>%
            mutate(pn_obs=ifelse(predictor==1 & pred1==1,p_x0_y0,NA)) %>%
            select(pn_obs) %>%
            gather(metric,value) %>%
            filter(!is.na(value))
          
          M=Z %>%
            group_by(predictor,pred1) %>%
            summarize(
              p_x1_y1=mean(event1)
              ,p_x2_y2=mean(event2)
            ) %>%
            ungroup() %>%
            mutate(
              ps_obs_pred1=ifelse(predictor==0 & pred1==0,p_x1_y1,NA)
              ,ps_obs_pred2=ifelse(predictor==0 & pred1==0,p_x2_y2,NA)
            ) %>%
            select(ps_obs_pred1,ps_obs_pred2) %>%
            gather(metric,value) %>%
            filter(!is.na(value))
          
          rbind(K,L,M)
            
        }) %>%
        do.call(rbind,.) %>%
        group_by(metric) %>%
        summarize(
          avg=mean(value)
          ,lb=mean(value)-qnorm(0.975)*sd(value)/sqrt(n())
          ,ub=mean(value)+qnorm(0.975)*sd(value)/sqrt(n())
        ) %>%
        mutate_at(c('avg','lb','ub'),round,4) %>%
        mutate(predictor=x)
      
      saveRDS(K,paste0('data/cx_divnn/',x,'.rds'))
      
      K
      
    }) %>%
    do.call(rbind,.)
  
  saveRDS(cx$divnn,'data/cx_divnn.rds')
}else{
  cat(readRDS('data/log.rds')[['cx_divnn']])
  cx$divnn=readRDS('data/cx_divnn.rds')
}
```

```{r Show CX of DI-VNN, echo=FALSE}
cx$divnn %>%
  pblapply(X=seq(length(unique(.$predictor))),Y=.,Z=5,function(X,Y,Z){
    
    sufficiency='ps_obs_pred2'
    
    K=Y %>%
      lapply(X=c('pn_obs',sufficiency),Y=.,Z=X,function(X,Y,Z){
        K=Y %>%
          filter(metric==X) %>%
          arrange(desc(avg)) %>%
          slice(seq(Z)) %>%
          mutate(
            min=
              paste0(
                ifelse(X=='pn_obs','PN','PS')
                ,' min. '
                ,round(min(avg)*100,2)
                ,'%'
              )
          ) %>%
          mutate_at(c('avg','lb','ub'),function(x)paste0(x*100,'%')) %>%
          unite(int,lb,ub,sep=' to ') %>%
          mutate(int=paste0('(',int,')')) %>%
          unite(value,avg,int,sep=' ') %>%
          spread(metric,value)
        
        L=Y %>%
          filter(metric==ifelse(X=='pn_obs',sufficiency,'pn_obs')) %>%
          arrange(desc(avg)) %>%
          mutate_at(c('avg','lb','ub'),function(x)paste0(x*100,'%')) %>%
          unite(int,lb,ub,sep=' to ') %>%
          mutate(int=paste0('(',int,')')) %>%
          unite(value,avg,int,sep=' ') %>%
          spread(metric,value)
        
        K %>%
          left_join(L,by='predictor') %>%
          mutate(top=ifelse(X=='pn_obs','necessity','sufficiency')) %>%
          mutate_at(ifelse(X=='pn_obs',sufficiency,'pn_obs'),function(x){
            ifelse(is.na(x),'0% (0% to 0%)',x)
          })
      }) %>%
      do.call(rbind,.) %>%
      mutate(
        min=
          sapply(X=seq(nrow(.)),Y=.,function(X,Y){
            paste0(filter(Y,predictor==Y$predictor[X])$min,collapse=' and ')
          })
        ,top=
          sapply(X=seq(nrow(.)),Y=.,function(X,Y){
            paste0(filter(Y,predictor==Y$predictor[X])$top,collapse=' and ')
          })
      ) %>%
      filter(!duplicated(select(.,-min))) %>%
      filter(top=='necessity and sufficiency')
    
    if(nrow(K)>=Z){
      K
    }else{
      NULL
    }
    
  }) %>%
  .[[which(sapply(.,function(x)!is.null(x)))[1]]] %>%
  left_join(
    readRDS('data/annotation.rds') %>%
      rename(predictor=code) %>%
      rbind(
        dag$baseline_nodes %>%
          mutate(label=paste0('causal_',label)) %>%
          left_join(
            dag$measure_nodes %>%
              mutate(
                label=
                  paste0(
                    'causal_'
                    ,str_remove_all(label,'\\*')
                  )
              ) %>%
              rename(code=name)
            ,by='label'
          ) %>%
          mutate(code=ifelse(is.na(code),'',code)) %>%
          unite(desc,name,code,sep=' ') %>%
          rename(predictor=label) %>%
          select(predictor,desc)
      )
    ,by='predictor'
  ) %>%
  kable() %>%
  kable_classic()
```

```{r Clinical perspectives, include=FALSE}
cp=
  read_xlsx('data/model_explainability_dr_aufar.xlsx') %>%
  mutate(clinician='GP') %>%
  rbind(
    read_xlsx('data/model_explainability_dr_fariska.xlsx') %>%
      mutate(
        implausible_because=
          ifelse(
            is.na(implausible_because) & !is.na(note)
            ,note
            ,implausible_because
          )
        ,note=NA
      ) %>%
      .[!sapply(as.data.frame(t(.)),function(x)all(is.na(x))),,drop=F] %>%
      lapply(X=1,Y=.,function(X,Y){
        Z=Y %>%
          .[-nrow(.),,drop=F]
        
        Z$note[1]=
          Y %>%
          .[nrow(.),,drop=T] %>%
          .[!is.na(.)] %>%
          paste0(collapse='|')
        
        Z
      }) %>%
      .[[1]] %>%
      mutate(clinician='Ob/Gyn')
  ) %>%
  rename(chosen=note) %>%
  mutate(chosen=ifelse(chosen=='The best one',model,chosen)) %>%
  mutate(
    chosen=
      ifelse(
        model==pull(filter(.,clinician=='GP'),chosen)[1]
        & clinician=='GP'
        ,'yes'
        ,chosen
      )
  ) %>%
  mutate(chosen=str_replace_all(chosen,'\\s+','-')) %>%
  mutate(
    chosen=
      sapply(X=seq(nrow(.)),Y=unique(model),Z=chosen,function(X,Y,Z){
        K=Y %>%
          sapply(function(x)str_detect(Z[X],x)) %>%
          which()
        
        L=Y[K] %>%
          paste0(collapse='|')
        
        ifelse(L=='',Z[X],L)
      })
  ) %>%
  mutate(
    chosen=
      ifelse(
        str_detect(model,pull(filter(.,clinician=='Ob/Gyn'),chosen)[1])
        & clinician=='Ob/Gyn'
        ,'yes'
        ,chosen
      )
  ) %>%
  mutate(chosen=ifelse(is.na(chosen),'no',chosen)) %>%
  mutate(
    clinician=
      clinician %>%
      str_replace_all('[:punct:]','_') %>%
      str_to_lower()
    ,plausibility=
      sapply(
        X=seq(nrow(.))
        ,Y=chosen
        ,Z=plausible_yes_or_no
        ,K=implausible_because
        ,function(X,Y,Z,K){
          L=ifelse(Y[X]=='yes','Chosen','Not chosen')
          
          M=ifelse(Z[X]=='yes','plausible','implausible') %>%
            c(K[X]) %>%
            .[!is.na(.)] %>%
            paste0(collapse=', ')
          
          L %>%
            c(M) %>%
            paste0(collapse=', ')
        }
      )
  ) %>%
  select(-chosen,-plausible_yes_or_no,-implausible_because) %>%
  spread(clinician,plausibility)
```

```{r Show clinical perspectives, echo=FALSE}
cp %>%
  select(
    model
    ,predictor,desc
    ,pn_obs,ps_obs_pred2
    ,gp,ob_gyn
  ) %>%
  unite(predictor,predictor,desc,sep=', ') %>%
  setNames(
    c('Model'
      ,'Top-five predictor'
      ,'PN (95% CI)','PS (95% CI)'
      ,'Clinician 1','Clinician 2')
  ) %>%
  kable() %>%
  kable_classic()
```

## Comparison to the previous models

Start: July 29th, 2021
End: November 24th, 2021

We applied the preferred reporting items for systematic reviews and 
meta-analyses (PRISMA) 2020 guidelines to find comparable models to evaluate 
success criteria. Since a systematic review and meta-analysis were not the main 
purposes of this study, we only applied all items in section methods of the 
guidelines, except item numbers 11 and 14 regarding the risk of bias assessment 
and item numbers 13 and 15 regarding synthesis method and certainty. This was 
because we applied the guidelines only to facilitate fair comparisons to 
previous studies, and did not consider conclusions as to how valid and accurate 
FGR-SGA could be predicted. To achieve that purpose, following the PICOTS 
framework, eligibility criteria included: (1) population, either pregnant or 
non-pregnant women without specifying their medical conditions; (2) index, the 
best prediction model in this study; (3) comparator, prediction models or 
rules; (4) outcome, either FGR or SGA as a binary outcome (event or 
non-event) with ≥20 EPVs; (5) time, prognostic prediction from days to weeks; 
and (6) setting, either primary care or hospital patients. We excluded any 
article types beyond original articles, including conference abstracts but not 
full papers. The studies were not grouped since no synthesis was conducted.

We searched for studies up to April 3, 2021. Unlike human learning that only 
used PubMed, we also included Scopus and Web of Science as 
literature/bibliographic databases in which we searched for previous models, 
because prediction studies were also extensively reported beyond life-science 
journals (i.e., computer-science journals). The keyword was either “fetal 
growth restriction” or “intrauterine growth retardation” and “small for 
gestational age”, combined with “prognostic prediction”. We limited the records 
to within the last five years. We applied a similar, but not exactly the same, 
search strategy to the three databases considering their different interfaces 
(Table 4 in Additional file 1). One researcher, HS, searched the literature and 
loosely filtered these by title and abstract. Then, HS manually assessed the 
eligibility by examining the full texts and identified ambiguous ones. HS and 
YWW independently assessed ambiguous studies. If no consensus was reached 
between HS and YWW, a final decision was made by ECYS. HS collected data from 
each full text. We only extracted the sensitivity and specificity of the best 
model with the most similar outcome definition from each study to that of our 
study. The AUROCs were also included. If not reported, the AUROC was inferred 
by the trapezoidal rule utilizing the sensitivity (Sn.) and specificity (Sp.) 
(Equation 6). We also extracted the study design, population, setting, outcome 
definition, sample size, details on events and non-events, number of candidate 
predictors, EPV, predictors in the best final model, and the most recommended 
validation techniques (external over internal validation; bootstrapping over 
cross-validation, or cross-validation over test split). Plots of sensitivities 
and specificities were overlaid those of our models for PROM prediction. We 
also plotted a point at a sensitivity and a specificity for each of our models 
at the optimum threshold on each ROC curve. AUROCs were compared with the 
models in this study (with or without the 95% CI).

```{r Compute ROC 2, include=FALSE}
th_util=
  roc  %>%
  filter(bound=='avg') %>%
  select(model,th,nb) %>%
  arrange(model,desc(nb)) %>%
  group_by(model,nb) %>%
  slice(1) %>%
  ungroup() %>%
  group_by(model) %>%
  filter(nb>=0 & nb<=max(nb)) %>%
  filter(nb==min(nb) | nb==max(nb)) %>%
  mutate(nb=ifelse(nb==max(nb),'min','max')) %>%
  spread(nb,th) %>%
  mutate(
    model=
      case_when(
        model=='Causal RR'~'causal_ridge'
        ,model=='PC-ENR'~'pc_elnet'
        ,model=='PC-RF'~'pc_rf'
        ,model=='PC-GBM'~'pc_gbm'
        ,model=='DI-VNN'~'divnn'
        ,TRUE~'NA'
      )
  ) %>%
  mutate(max=1)

roc2=
  
  # Create ROC table per model.
  calib_model %>%
  .[th_util$model] %>%
  lapply(X=names(.),Y=.,Z=th_util,function(X,Y,Z){
    Y[[X]]$pred %>%
      filter(
        round(event,2)>=Z$min[Z$model==X]
        & round(event,2)<=Z$max[Z$model==X]
      ) %>%
      
      # Get the prediction table.
      select(Resample,rowIndex,event,obs) %>%
      setNames(c('subset','index','score','outcome')) %>%
      
      # Preprocess the table.
      mutate(outcome=as.double(outcome=='event')) %>%
      left_join(
        select(.,index) %>%
          filter(!duplicated(.)) %>%
          arrange(index) %>%
          cbind(
            data.frame(
                key=paste0('th_',str_pad(0:100,3,'left','0'))
                ,value=seq(0,1,len=101)
              ) %>%
              spread(key,value)
          )
        ,by='index'
      ) %>%
      gather(key,th,-subset,-index,-score,-outcome) %>%
      select(-key) %>%
      
      # Compute confusion matrices.
      mutate(pred=as.integer(score>th)) %>%
      mutate(
        tp=as.integer(outcome==1 & pred==1)
        ,fn=as.integer(outcome==1 & pred==0)
        ,fp=as.integer(outcome==0 & pred==1)
        ,tn=as.integer(outcome==0 & pred==0)
      ) %>%
      select(-index,-score,-outcome,-pred) %>%
      group_by(subset,th) %>%
      summarize_all(sum) %>%
      ungroup() %>%
      
      # Compute evaluation metrics.
      mutate(
        tpr=tp/(tp+fn+1e-17)
        ,tnr=tn/(tn+fp+1e-17)
        ,ppv=tp/(tp+fp+1e-17)
        ,npv=tn/(tn+fn+1e-17)
      ) %>%
      select(-subset,-tp,-fn,-fp,-tn) %>%
      group_by(th) %>%
      
      # Compute the interval estimates.
      summarize_all(function(x){
        y=mean(x)+(-1:1)*qnorm(0.975)*sd(x)/sqrt(length(x))
        paste0(y,collapse='|')
      }) %>%
      gather(metric,interval,-th) %>%
      separate(interval,c('lb','avg','ub'),sep='\\|') %>%
      mutate_at(c('lb','avg','ub'),as.numeric) %>%
      mutate_at(c('lb','avg','ub'),function(x){
        round(ifelse(x<0,0,ifelse(x>1,1,x)),4)
      }) %>%
      
      # Wrap up.
      mutate(model=X) %>%
      select(model,everything()) %>%
      gather(bound,value,-th,-metric,-model) %>%
      spread(metric,value)
  }) %>%
  do.call(rbind,.) %>%
  
  # Clean up naming.
  mutate(model=case_when(
    model=='causal_ridge'~'Causal RR'
    ,model=='pc_elnet'~'PC-ENR'
    ,model=='pc_rf'~'PC-RF'
    ,model=='pc_gbm'~'PC-GBM'
    ,model=='divnn'~'DI-VNN'
    ,TRUE~''
  )) %>%
  mutate(
    model=factor(model,c('Causal RR','PC-ENR','PC-RF','PC-GBM','DI-VNN'))
  )

# Get optimum threshold per model.
opt_th2=
  roc2 %>%
  filter(bound=='avg') %>%
  select(model,th,tpr,tnr) %>%
  mutate(avg_acc=(tpr+tnr)/2) %>%
  arrange(model,desc(avg_acc),th,desc(tpr),desc(tnr)) %>%
  group_by(model) %>%
  slice(1) %>%
  ungroup()

# Get sensitive threshold per model.
sens_th2=
  roc2 %>%
  filter(bound=='avg') %>%
  select(model,th,tpr,tnr) %>%
  mutate(tpr=round(tpr,2)) %>%
  right_join(
    expand.grid(model=.$model %>% .[!duplicated(.)],tpr=seq(0,1,len=101))
    ,by=c('model','tpr')
  ) %>%
  arrange(model) %>%
  group_by(model) %>%
  arrange(model,tpr,tnr,th) %>%
  mutate_at(c('tnr','th'),na_interpolation) %>%
  filter(tpr>=0.95) %>%
  slice(1) %>%
  ungroup()

# Get specific threshold per model.
spec_th2=
  roc2 %>%
  filter(bound=='avg') %>%
  select(model,th,tpr,tnr) %>%
  mutate(tnr=round(tnr,2)) %>%
  right_join(
    expand.grid(model=.$model %>% .[!duplicated(.)],tnr=seq(0,1,len=101))
    ,by=c('model','tnr')
  ) %>%
  arrange(model) %>%
  group_by(model) %>%
  arrange(tnr,tpr,th) %>%
  mutate_at(c('tpr','th'),na_interpolation) %>%
  filter(tnr>=0.95) %>%
  slice(1) %>%
  ungroup()
```

```{r Compare with the previous models, include=FALSE}
# Create group for the systematic review results
srma_group=
  read_xlsx('data/srma_results.xlsx') %>%
  mutate(
    phys=
      as.integer(
        uta_pi==1
        |crl==1
        |map==1
        |nt==1
        |efw==1
        |ua_pi==1
        |mca_pi==1
        |ica_pi==1
        |ra_pi==1
        |ao_pi==1
        |cu_r==1
        |mca_sd==1
        |ua_sd==1
        |upa_sd==1
        |mca_ri==1
        |ua_ri==1
        |uta_ri==1
        |mco==1
      )
    ,chem=
      as.integer(
        papp_a==1
        |fbhcg==1
        |plgf==1
        |pp13==1
        |adam12==1
        |sflt1==1
      )
    ,mat=
      as.integer(
        age==1
        |weight==1
        |height==1
        |bmi==1
        |cig_smoker==1
        |alc_drinker==1
        |drug_abuse==1
        |parity==1
        |race_ethnicity==1
        |conception==1
        |med_history==1
        |fam_history_pe==1
        |medication_preg==1
      )
  ) %>%
  select(study,phys,chem,mat) %>%
  gather(feature,value,-study) %>%
  filter(value>0) %>%
  group_by(study) %>%
  summarize(features=paste0(feature,collapse=' - ')) %>%
  ungroup()

# Filter only the averages in the ROC table.
roc_curve_data=
  roc %>%
  filter(bound=='avg') %>%
  select(-bound)

# Plot the ROC curve.
roc_curve=
  
  # Plot the curve.
  roc_curve_data %>%
  ggplot(aes(tnr,tpr,color=model,fill=model),data=.) +
  geom_line(size=1) +
  geom_abline(intercept=1,slope=1,lty=2) +
  geom_blank(data=data.frame(tnr=-1,tpr=1,model=NA)) +
  geom_point(data=opt_th,size=3) +
  
  # # Plot references from the systematic review results.
  geom_point(
    data=
      read_xlsx('data/srma_results.xlsx') %>%
      # To modify the citation
      # mutate(
      #   study=str_replace(study,'\\[69\\]','[6]')
      #   ,study=str_replace(study,'\\[23\\]','[7]')
      # ) %>%
      rename(tnr=spec,tpr=sens) %>%
      left_join(srma_group,by='study') %>%
      mutate(study=features)
    ,color='black',fill='black'
  ) +
  geom_label(
    data=
      read_xlsx('data/srma_results.xlsx') %>%
      # To modify the citation
      # mutate(
      #   study=str_replace(study,'\\[69\\]','[6]')
      #   ,study=str_replace(study,'\\[23\\]','[7]')
      # ) %>%
      rename(tnr=spec,tpr=sens) %>%
      left_join(srma_group,by='study') %>%
      mutate(study=features)
    ,aes(label=study)
    ,color='black',fill='white',family='sans'
    ,hjust=0,vjust=1
    ,size=3,alpha=0.75,label.padding=unit(0.15,'lines')
  ) +
  geom_label(
    data=
      opt_th %>%
      mutate(pos=rev(seq(0.1,0.5,len=5)))
    ,aes(x=0.3,y=pos,label=model)
    ,hjust=0,vjust=1,size=3,color='black',alpha=0.75,family='sans'
    ,show.legend=F
  ) +
  
  # Customize plot.
  coord_equal() +
  scale_x_reverse(
    'Specificity',limits=1:0,breaks=rev(seq(0,1,0.1))
    ,labels=scales::number_format(accuracy=0.1,decimal.mark='.')
  ) +
  scale_y_continuous(
    'Sensitivity',limits=0:1,breaks=seq(0,1,0.1)
    ,labels=scales::number_format(accuracy=0.1,decimal.mark='.')
  ) +
  scale_color_npg() +
  scale_fill_npg() +
  guides(color=F,fill=F) +
  theme(
    axis.title=element_text(family='sans')
    ,axis.text.x=element_text(angle=90,hjust=1,vjust=0.5,family='sans')
    ,axis.text.y=element_text(family='sans')
  )

# Create table for AUROC plot of the calibrated models.
## External validation
if(run_heavy_computation){
  auroc_table_ext=
    eval_model %>%
    .[th_util$model] %>%
    lapply(X=names(.),Y=.,function(X,Y){
      Z=c(names(Y[[X]])) %>%
        .[!str_detect(.,'geo|tem|bgt')]
      Y[[X]] %>%
        lapply(X=Z,Y=.,Z=X,function(X,Y,Z){
          cat('Model',Z,'set',X,'\n')
          
          if(str_detect(X,'ran')){
            Y[[X]]$probs$Group1=
              Y[[X]]$probs$Group1 %>%
              rbind(Y[[str_replace_all(X,'ran','geo')]]$probs$Group1) %>%
              rbind(Y[[str_replace_all(X,'ran','tem')]]$probs$Group1) %>%
              rbind(Y[[str_replace_all(X,'ran','bgt')]]$probs$Group1)
          }
          
          K=Y[[X]]$probs$Group1 %>%
            select(event,obs) %>%
            mutate(
              wd=
                round(event,2)>=th_util$min[th_util$model==Z]
                & round(event,2)<=th_util$max[th_util$model==Z]
            )
          
          L=K %>%
            summarize(wd=mean(wd)) %>%
            pull(wd)
          
          M=K %>%
            filter(wd==T)
          
          if(nrow(M)==0){
            N=data.frame(
                wd=L
                ,avg=NA
                ,lb=NA
                ,ub=NA
              )
          }else{
            suppressWarnings(set.seed(33,sample.kind='Rounding'))
            N=M %>%
              select(-wd) %>%
              rownames_to_column(var='id') %>%
              left_join(
                select(.,id) %>%
                  filter(!duplicated(.)) %>%
                  arrange(id) %>%
                  cbind(
                    data.frame(
                        key=paste0('th_',str_pad(0:100,3,'left','0'))
                        ,value=seq(0,1,len=101)
                      ) %>%
                      spread(key,value)
                  )
                ,by='id'
              ) %>%
              gather(key,th,-id,-event,-obs) %>%
              select(-key) %>%
              
              # Compute confusion matrices.
              mutate(
                obs=as.integer(obs=='event')
                ,pred=as.integer(event>th)
              ) %>%
              mutate(
                tp=as.integer(obs==1 & pred==1)
                ,fn=as.integer(obs==1 & pred==0)
                ,fp=as.integer(obs==0 & pred==1)
                ,tn=as.integer(obs==0 & pred==0)
              ) %>%
              pbsapply(X=seq(30),Y=.,function(X,Y){
                Y %>%
                  .[sample(seq(nrow(.)),nrow(.),T),] %>%
                  select(-id,-event,-obs,-pred) %>%
                  group_by(th) %>%
                  summarize_all(sum) %>%
                  ungroup() %>%
                  
                  # Compute evaluation metrics.
                  mutate(
                    tpr=tp/(tp+fn+1e-17)
                    ,tnr=tn/(tn+fp+1e-17)
                  ) %>%
                  select(-th,-tp,-fn,-fp,-tn) %>%
                  filter(!duplicated(.)) %>%
                  arrange(desc(tnr),tpr) %>%
                  mutate(seq=seq(nrow(.))) %>%
                  left_join(
                    filter(.,seq!=1) %>%
                      mutate(seq=seq(nrow(.))) %>%
                      rename(tpr_next=tpr,tnr_next=tnr)
                    ,by='seq'
                  ) %>%
                  filter(seq!=max(seq)) %>%
                  mutate(
                    x=tnr-tnr_next
                    ,y=tpr_next-tpr
                    ,auc=x*tpr+0.5*x*y
                  ) %>%
                  summarize(auc=sum(auc)) %>%
                  pull(auc)
              }) %>%
              data.frame(auc=.) %>%
              summarize(
                wd=L
                ,avg=mean(auc)
                ,lb=mean(auc)-qnorm(0.975)*sd(auc)/sqrt(n())
                ,ub=mean(auc)+qnorm(0.975)*sd(auc)/sqrt(n())
              )
          }
          
          N %>%
            mutate(
              model=Z
              ,set=X
            )
            
        }) %>%
        do.call(rbind,.)
    }) %>%
    do.call(rbind,.)
  
  saveRDS(auroc_table_ext,'data/auroc_table_ext.rds')
}else{
  cat(readRDS('data/log.rds')[['auroc_table_ext']])
  auroc_table_ext=readRDS('data/auroc_table_ext.rds')
}

## Internal validation
if(run_heavy_computation){
  auroc_table_int=
    calib_model %>%
    .[th_util$model] %>%
    lapply(X=names(.),Y=.,Z=th_util,function(X,Y,Z){
      Z=Y[[X]]$pred %>%
        mutate(
          wd=
            round(event,2)>=Z$min[Z$model==X]
            & round(event,2)<=Z$max[Z$model==X]
        )
      
      K=Z %>%
        summarize(wd=mean(wd)) %>%
        pull(wd)
      
      L=Z %>%
        filter(wd==T)
      
      if(nrow(L)==0){
        M=data.frame(
            wd=K
            ,avg=NA
            ,lb=NA
            ,ub=NA
          )
      }else{
        M=L %>%
          
          # Get the prediction table.
          select(Resample,rowIndex,event,obs) %>%
          setNames(c('subset','index','score','outcome')) %>%
          
          # Preprocess the table.
          mutate(outcome=as.double(outcome=='event')) %>%
          left_join(
            select(.,index) %>%
              filter(!duplicated(.)) %>%
              arrange(index) %>%
              cbind(
                data.frame(
                    key=paste0('th_',str_pad(0:100,3,'left','0'))
                    ,value=seq(0,1,len=101)
                  ) %>%
                  spread(key,value)
              )
            ,by='index'
          ) %>%
          gather(key,th,-subset,-index,-score,-outcome) %>%
          select(-key) %>%
          
          # Compute confusion matrices.
          mutate(pred=as.integer(score>th)) %>%
          mutate(
            tp=as.integer(outcome==1 & pred==1)
            ,fn=as.integer(outcome==1 & pred==0)
            ,fp=as.integer(outcome==0 & pred==1)
            ,tn=as.integer(outcome==0 & pred==0)
          ) %>%
          select(-index,-score,-outcome,-pred) %>%
          group_by(subset,th) %>%
          summarize_all(sum) %>%
          ungroup() %>%
          
          # Compute evaluation metrics.
          mutate(
            tpr=tp/(tp+fn+1e-17)
            ,tnr=tn/(tn+fp+1e-17)
            ,ppv=tp/(tp+fp+1e-17)
            ,npv=tn/(tn+fn+1e-17)
          ) %>%
          
          # Wrap up.
          mutate(model=X) %>%
          select(model,everything()) %>%
          
          sapply(X=unique(.$subset),Y=.,function(X,Y){
            Y %>%
              filter(subset==X) %>%
              select(model,subset,tpr,tnr) %>%
              filter(!duplicated(.)) %>%
              arrange(desc(tnr),tpr) %>%
              mutate(seq=seq(nrow(.))) %>%
              left_join(
                filter(.,seq!=1) %>%
                  mutate(seq=seq(nrow(.))) %>%
                  rename(tpr_next=tpr,tnr_next=tnr)
                ,by='seq'
              ) %>%
              filter(seq!=max(seq)) %>%
              mutate(
                x=tnr-tnr_next
                ,y=tpr_next-tpr
                ,auc=x*tpr+0.5*x*y
              ) %>%
              summarize(auc=sum(auc)) %>%
              pull(auc)
          }) %>%
          data.frame(auc=.) %>%
          summarize(
            wd=K
            ,avg=mean(auc)
            ,lb=mean(auc)-qnorm(0.975)*sd(auc)/sqrt(n())
            ,ub=mean(auc)+qnorm(0.975)*sd(auc)/sqrt(n())
          )
      }
      
      M %>%
        mutate(
          model=X
          ,set='int'
        )
    }) %>%
    do.call(rbind,.)
  
  saveRDS(auroc_table_int,'data/auroc_table_int.rds')
}else{
  cat(readRDS('data/log.rds')[['auroc_table_int']])
  auroc_table_int=readRDS('data/auroc_table_int.rds')
}

## New groups of the systematic review results
srma_group2=
  read_xlsx('data/srma_results.xlsx') %>%
  .[,c(1,seq(which(colnames(.)=='year')+1,ncol(.)))] %>%
  gather(feature,value,-study) %>%
  filter(value>0) %>%
  group_by(study) %>%
  summarize(features=paste0(feature,collapse=','))

## Create the table.
auroc_table=
  
  # Get the evaluation results.
  auroc_table_ext %>%
  rbind(auroc_table_int) %>%
  filter(!model%in%c('causal_ridge','pc_rf')) %>%
  rename(Score=avg) %>%
  select(set,Score,lb,ub,model,everything()) %>%
  filter(!str_detect(set,'nocalib')) %>%
  mutate(set=str_remove_all(set,'calib_')) %>%
  
  # Clean up model naming.
  mutate(model=case_when(
    model=='causal_ridge'~'Causal RR'
    ,model=='pc_elnet'~'PC-ENR'
    ,model=='pc_rf'~'PC-RF'
    ,model=='pc_gbm'~'PC-GBM'
    ,model=='divnn'~'DI-VNN'
    ,TRUE~''
  )) %>%
  mutate(
    model=factor(model,c('Causal RR','PC-ENR','PC-RF','PC-GBM','DI-VNN'))
  ) %>%
  
  # Clean up subset naming.
  mutate(set=case_when(
    set=='ran'~'External random &\nnon-random splits'
    ,set=='geo'~'External\ngeographical\nsplit'
    ,set=='tem'~'External\ntemporal\nsplit'
    ,set=='bgt'~'External\ngeotemporal\nsplit'
    ,set=='int'~'Internal calibration\nsplit'
    ,TRUE~''
  )) %>%
  
  # Compute the AUROC average of all the models in each subset.
  group_by(set) %>%
  mutate(set_score=mean(Score)) %>%
  ungroup() %>%
  
  # # Add references from the systematic review results.
  rbind(
    read_xlsx('data/srma_results.xlsx') %>%
      filter(
        study%in%paste0('[',c('11','16','17e','17f'
                              ,'5a','14','17a','17b','18c','21','22a','22c'
                              ,'6a','6b','6c','8c','9b','15c'
                              ,'18b','19b','20a','20b','22b','23','24','25'
                              ),']')
      ) %>%
      mutate(set='Training\nset') %>%
      # To modify the citation
      # mutate(
      #   study=str_replace(study,'\\[37\\]','[6]')
      #   ,study=str_replace(study,'\\[23\\]','[7]')
      # ) %>%
      rename(model=study,Score=auroc,lb=auroc_lb,ub=auroc_ub) %>%
      select(set,Score,lb,ub,model) %>%
      mutate(set_score=mean(Score)) %>%
      left_join(rename(srma_group2,model=study),by='model') %>%
      mutate(wd=NA) %>%
      mutate(
        features=
          paste0(
            str_sub(features,1,20)
            ,ifelse(str_count(features)>20,' ...','')
          )
      ) %>%
      mutate(model=paste0(features,' ',model)) %>%
      select(-features)
  ) %>%
  
  # Clean up subset naming.
  mutate(
    set=
      factor(
        set
        ,c('Internal calibration\nsplit'
           ,'Training\nset'
           ,'External random &\nnon-random splits'
           ,'External\ngeographical\nsplit'
           ,'External\ntemporal\nsplit'
           ,'External\ngeotemporal\nsplit')
      )
  )
```

```{r Identify the previous models in ROC, fig.height=10, fig.width=10}
suppressWarnings(set.seed(33,sample.kind='Rounding'))
read_xlsx('data/srma_results.xlsx') %>%
  left_join(srma_group2,by='study') %>%
  mutate(
    features=
      features %>%
      str_replace_all('papp_a','PAPP-A') %>%
      str_replace_all('uta_pi','UtA-PI') %>%
      str_replace_all('fbhcg','Free b-hCG') %>%
      str_replace_all('crl','CRL') %>%
      str_replace_all('age','Age') %>%
      str_replace_all('weight','Weight') %>%
      str_replace_all('cig_smoker','Cig. smoker') %>%
      str_replace_all('race_ethnicity','Race/ethnicity') %>%
      str_replace_all('map','MAP') %>%
      str_replace_all('nt','NT') %>%
      str_replace_all('plgf','PlGF') %>%
      str_replace_all('pp13','PP13') %>%
      str_replace_all('adam12','ADAM12') %>%
      str_replace_all('parity','Parity') %>%
      str_replace_all('conception','Conception') %>%
      str_replace_all('efw','EFW') %>%
      str_replace_all('sflt1','sFLT-1') %>%
      str_replace_all('ua_pi','UA-PI') %>%
      str_replace_all('mca_pi','MCA-PI') %>%
      str_replace_all('ica_pi','ICA-PI') %>%
      str_replace_all('ra_pi','RA-PI') %>%
      str_replace_all('ao_pi','AO-PI') %>%
      str_replace_all('cu_r','CU-R') %>%
      str_replace_all('mca_sd','MCA-SD') %>%
      str_replace_all('ua_sd','UA-SD') %>%
      str_replace_all('upa_sd','UPA-SD') %>%
      str_replace_all('mca_ri','MCA-RI') %>%
      str_replace_all('ua_ri','UA-RI') %>%
      str_replace_all('uta_ri','UtA-RI') %>%
      str_replace_all('height','Height') %>%
      str_replace_all('med_history','Med. history') %>%
      str_replace_all('bmi','BMI') %>%
      str_replace_all('alc_drinker','Alc. drinker') %>%
      str_replace_all('drug_abuse','Drug abuse') %>%
      str_replace_all('fam_history_pe','Fam. history of PE') %>%
      str_replace_all('medication_preg','Medication in pregnancy') %>%
      str_replace_all('mco','MCO') %>%
      str_replace_all(',',', ')
  ) %>%
  mutate(features=paste0(study,' ',features)) %>%
  mutate(
    study=
      ifelse(
        study%in%paste0('[',c('11','16','17e','17f'
                              ,'5a','14','17a','17b','18c','21','22a','22c'
                              ,'6a','6b','6c','8c','9b','15c'
                              ,'18b','19b','20a','20b','22b','23','24'
                              ),']')
        ,study
        ,NA
      )
  ) %>%
  mutate(study=ifelse(is.na(study),NA,features)) %>%
  ggplot(aes(spec,sens)) +
  geom_abline(intercept=1,slope=1,lty=2) +
  geom_line(
    data=
      roc2 %>%
      filter(bound=='avg') %>%
      rename(study=model,sens=tpr,spec=tnr) %>%
      filter(!study%in%c('Causal RR','PC-RF'))
    ,aes(color=study)
    ,size=1
  ) +
  geom_point(aes(size=total,color=ifelse(!is.na(study),'REV-H','REV-L'))) +
  geom_point(
    data=
      opt_th2 %>%
      rename(study=model,sens=tpr,spec=tnr) %>%
      mutate(total=30529+143) %>%
      filter(!study%in%c('Causal RR','PC-RF'))
    ,aes(color=study,size=total)
  ) +
  ggrepel::geom_label_repel(
    aes(label=study)
    ,na.rm=T
    ,label.padding=unit(0.15,'line')
    ,hjust=0,vjust=1,size=3,alpha=0.8
  ) +
  coord_equal() +
  scale_x_reverse('Specificity',limits=1:0) +
  scale_y_continuous('Sensitivity',limits=0:1) +
  scale_color_npg(name='Model')+
  scale_size_area('Sample size')
```

```{r DI-VNN at 95% specificity, eval=FALSE, include=FALSE}
roc %>%
  filter(
    model=='DI-VNN'
    & between(
      th
      ,floor(spec_th$th[spec_th$model=='DI-VNN']*100)/100
      ,ceiling(spec_th$th[spec_th$model=='DI-VNN']*100)/100
    )
  ) %>%
  group_by(th) %>%
  mutate(dif=abs(0.95-mean(tnr))) %>%
  ungroup() %>%
  filter(dif==min(dif)) %>%
  select(model,th,bound,tpr) %>%
  spread(bound,tpr) %>%
  kable(caption='DI-VNN at 95% specificity') %>%
  kable_classic()
```

```{r PC-GBM at 95% specificity, eval=FALSE, include=FALSE}
roc %>%
  filter(
    model=='PC-GBM'
    & between(
      th
      ,floor(spec_th$th[spec_th$model=='PC-GBM']*100)/100
      ,ceiling(spec_th$th[spec_th$model=='PC-GBM']*100)/100
    )
  ) %>%
  group_by(th) %>%
  mutate(dif=abs(0.95-mean(tnr))) %>%
  ungroup() %>%
  filter(dif==min(dif)) %>%
  select(model,th,bound,tpr) %>%
  spread(bound,tpr) %>%
  kable(caption='PC-GBM at 95% specificity') %>%
  kable_classic()
```

```{r PC-ENR at 95% specificity, eval=FALSE, include=FALSE}
roc %>%
  filter(
    model=='PC-ENR'
    & between(
      th
      ,floor(spec_th$th[spec_th$model=='PC-ENR']*100)/100
      ,ceiling(spec_th$th[spec_th$model=='PC-ENR']*100)/100
    )
  ) %>%
  group_by(th) %>%
  mutate(dif=abs(0.95-mean(tnr))) %>%
  ungroup() %>%
  filter(dif==min(dif)) %>%
  select(model,th,bound,tpr) %>%
  spread(bound,tpr) %>%
  kable(caption='PC-ENR at 95% specificity') %>%
  kable_classic()
```

```{r Optimum DI-VNN performance, eval=FALSE, include=FALSE}
rbind(
    roc %>%
      filter(
        model=='DI-VNN'
        & th==opt_th$th[opt_th$model=='DI-VNN']
      ) %>%
      select(model,th,bound,tpr) %>%
      spread(bound,tpr) %>%
      mutate(metric='Sensitivity')
    ,roc %>%
      filter(
        model=='DI-VNN'
        & th==opt_th$th[opt_th$model=='DI-VNN']
      ) %>%
      select(model,th,bound,tnr) %>%
      spread(bound,tnr) %>%
      mutate(metric='Specificity')
  ) %>%
  kable(caption='Optimum DI-VNN performance') %>%
  kable_classic()
```

```{r Optimum PC-GBM performance, eval=FALSE, include=FALSE}
rbind(
    roc %>%
      filter(
        model=='PC-GBM'
        & th==opt_th$th[opt_th$model=='PC-GBM']
      ) %>%
      select(model,th,bound,tpr) %>%
      spread(bound,tpr) %>%
      mutate(metric='Sensitivity')
    ,roc %>%
      filter(
        model=='PC-GBM'
        & th==opt_th$th[opt_th$model=='PC-GBM']
      ) %>%
      select(model,th,bound,tnr) %>%
      spread(bound,tnr) %>%
      mutate(metric='Specificity')
  ) %>%
  kable(caption='Optimum PC-GBM performance') %>%
  kable_classic()
```

```{r Optimum PC-ENR performance, eval=FALSE, include=FALSE}
rbind(
    roc %>%
      filter(
        model=='PC-ENR'
        & th==opt_th$th[opt_th$model=='PC-ENR']
      ) %>%
      select(model,th,bound,tpr) %>%
      spread(bound,tpr) %>%
      mutate(metric='Sensitivity')
    ,roc %>%
      filter(
        model=='PC-ENR'
        & th==opt_th$th[opt_th$model=='PC-ENR']
      ) %>%
      select(model,th,bound,tnr) %>%
      spread(bound,tnr) %>%
      mutate(metric='Specificity')
  ) %>%
  kable(caption='Optimum PC-ENR performance') %>%
  kable_classic()
```

```{r AUROCs of DI-VNN, eval=FALSE, include=FALSE}
auroc_table %>%
  filter(model=='DI-VNN') %>%
  kable() %>%
  kable_classic()
```

```{r Separate the previous models by year and predictors, include=FALSE}
srma_results=read_xlsx('data/srma_results.xlsx')

srma_rename=
  srma_results %>%
  colnames() %>%
  .[seq(16,length(.))] %>%
  data.frame(
    predictor=.
    ,type=
      c('biomarker'
        ,'ultrasound'
        ,'biomarker'
        ,'ultrasound'
        ,'physical_exam'
        ,'biomarker'
        ,'biomarker'
        ,'biomarker'
        ,'biomarker'
        ,'ultrasound'
        ,'biomarker'
        ,'ultrasound'
        ,'ultrasound'
        ,'ultrasound'
        ,'ultrasound'
        ,'ultrasound'
        ,'ultrasound'
        ,'ultrasound'
        ,'ultrasound'
        ,'ultrasound'
        ,'ultrasound'
        ,'ultrasound'
        ,'ultrasound'
        ,'ultrasound'
        ,'demographic'
        ,'physical_exam'
        ,'physical_exam'
        ,'physical_exam'
        ,'lifestyle'
        ,'lifestyle'
        ,'lifestyle'
        ,'obstetric_exam'
        ,'demographic'
        ,'obstetric_exam'
        ,'medical_history'
        ,'family_history'
        ,'medication')
  ) %>%
  right_join(
    srma_results %>%
      select(
        -event,-nonevent,-total
        ,-sens,-sens_lb,-sens_ub,-spec,-spec_lb,-spec_ub
        ,-auroc,-auroc_lb,-auroc_ub
        ,-inference,-year
      ) %>%
      gather(predictor,value,-study)
    ,by='predictor'
  ) %>%
  group_by(study) %>%
  summarize(
    ultrasound=sum(ifelse(type=='ultrasound',value,NA),na.rm=T)>0
    ,biomarker=sum(ifelse(type=='biomarker',value,NA),na.rm=T)>0
    ,others=sum(ifelse(type%in%c('ultrasound','biomarker'),NA,value),na.rm=T)>0
  ) %>%
  ungroup() %>%
  arrange(factor(study,srma_results$study)) %>%
  mutate(
    inaccessible=ultrasound+biomarker
    ,element=inaccessible+others
    ,type=
      case_when(
        element==1 & ultrasound ~ 'Ultrasound only'
        ,element==1 & biomarker ~ 'Biomarker only'
        ,element==2 & ultrasound & biomarker ~ 'Both without others'
        ,element==3 & ultrasound & biomarker ~ 'Both with others'
        ,element==2 & ultrasound  ~ 'Ultrasound with others'
        ,element==2 & biomarker ~ 'Biomarker with others'
        ,element==1 & others ~ 'Others only'
        ,TRUE ~ ''
      ) %>%
      factor(c(
        'Ultrasound only'
        ,'Biomarker only'
        ,'Both without others'
        ,'Both with others'
        ,'Ultrasound with others'
        ,'Biomarker with others'
        ,'Others only'
        ,''
      ))
  ) %>%
  left_join(srma_results,by='study')
```

```{r Plot ROC and the previous models by year and predictors, echo=FALSE, fig.height=7.08661, fig.width=5.85827}
srma_rename %>%
  mutate(
    year=
      case_when(
        year>=2012 & year <=2016 ~'2012 to 2016'
        ,year>=2002 & year <2012 ~'2002 to <2012'
        ,year>=1992 & year <2002 ~'1992 to <2002'
        ,year>=1989 & year <1992 ~'1989 to <1992'
      )
  ) %>%
  ggplot(aes(spec,sens,color=year)) +
  geom_vline(xintercept=c(0.95),lty=2) +
  geom_abline(slope=1,intercept=1,lty=2) +
  geom_line(
    data=
      roc2 %>%
      filter(bound=='avg') %>%
      rename(study=model,sens=tpr,spec=tnr) %>%
      filter(!study%in%c('Causal RR','PC-RF'))
    ,aes(color=study)
    ,size=1
  ) +
  geom_point(aes(size=total)) +
  geom_point(
    data=
      opt_th2 %>%
      rename(study=model,sens=tpr,spec=tnr) %>%
      mutate(total=30529+143) %>%
      filter(!study%in%c('Causal RR','PC-RF'))
    ,aes(color=study,size=total)
  ) +
  facet_wrap(~type,ncol=2) +
  coord_equal() +
  scale_x_reverse('Specificity',limits=c(1,0)) +
  scale_y_continuous('Sensitivity',limits=c(0,1)) +
  scale_color_npg(name='Model') +
  scale_size_area('Sample size') +
  theme(
    legend.position='right'
  )
```

## External validation

We also confirmed the robustness of the best models using external validation 
sets. Uncertainty intervals were also computed by bootstrapping for 30 times. 
A clear description on model validation is already given in the main text.

```{r Plot the AUROCs, include=FALSE}
auroc=
  auroc_table %>%
  mutate(
    study=
      model %>%
      as.character() %>%
      sapply(function(x){
        if(str_detect(x,'\\[|\\]')){
          str_sub(
            x
            ,str_locate_all(x,'\\[|\\]')[[1]][1,1]
            ,str_locate_all(x,'\\[|\\]')[[1]][2,1]
          )
        }else{
          x
        }
      })
  ) %>%
  left_join(
    srma_rename %>%
      select(study,year,type)
    ,by='study'
  ) %>%
  select(-study) %>%
  mutate(
    year=
      ifelse(
        is.na(year)
        ,2022
        ,year
      )
    ,year=
      case_when(
        year==2022 ~ '2022'
        ,year>=2012 & year <=2016 ~'2012 to 2016'
        ,year>=2002 & year <2012 ~'2002 to <2012'
        ,year>=1992 & year <2002 ~'1992 to <2002'
        ,year>=1989 & year <1992 ~'1989 to <1992'
      )
    ,type=
      ifelse(is.na(type),'This study',as.character(type))
  ) %>%
  mutate(
    model=
      model %>%
      str_replace_all('papp_a','PAPP-A') %>%
      str_replace_all('uta_pi','UtA-PI') %>%
      str_replace_all('fbhcg','Free b-hCG') %>%
      str_replace_all('crl','CRL') %>%
      str_replace_all('age','Age') %>%
      str_replace_all('weight','Weight') %>%
      str_replace_all('cig_smoker|cig','Cig. smoker') %>%
      str_replace_all(',c ',',Cig. smoker ') %>%
      str_replace_all('race_ethnicity','Race/ethnicity') %>%
      str_replace_all('map','MAP') %>%
      str_replace_all('nt','NT') %>%
      str_replace_all('plgf','PlGF') %>%
      str_replace_all('pp13','PP13') %>%
      str_replace_all('adam12','ADAM12') %>%
      str_replace_all('parity','Parity') %>%
      str_replace_all('conception','Conception') %>%
      str_replace_all('efw','EFW') %>%
      str_replace_all('sflt1|sflt','sFLT-1') %>%
      str_replace_all('ua_pi','UA-PI') %>%
      str_replace_all('mca_pi','MCA-PI') %>%
      str_replace_all('ica_pi','ICA-PI') %>%
      str_replace_all('ra_pi','RA-PI') %>%
      str_replace_all('ao_pi','AO-PI') %>%
      str_replace_all('cu_r','CU-R') %>%
      str_replace_all('mca_sd','MCA-SD') %>%
      str_replace_all('ua_sd','UA-SD') %>%
      str_replace_all('upa_sd','UPA-SD') %>%
      str_replace_all('mca_ri','MCA-RI') %>%
      str_replace_all('ua_ri','UA-RI') %>%
      str_replace_all('uta_ri','UtA-RI') %>%
      str_replace_all('height','Height') %>%
      str_replace_all('med_history','Med. history') %>%
      str_replace_all('bmi','BMI') %>%
      str_replace_all('alc_drinker','Alc. drinker') %>%
      str_replace_all('drug_abuse','Drug abuse') %>%
      str_replace_all('fam_history_pe','Fam. history of PE') %>%
      str_replace_all('medication_preg','Medication in pregnancy') %>%
      str_replace_all('mco','MCO') %>%
      str_replace_all(',',', ')
  ) %>%
  mutate(
    model=
      reorder(model,Score)
    ,model_group=
      ifelse(year=='2022',as.character(model),as.character(year))
    ,set=
      ifelse(
        set=='Training\nset'
        ,paste0(as.character(type),'\n(training set)')
        ,as.character(set)
      ) %>%
      factor(
        levels=
          unique(.) %>%
          sort() %>%
          .[c(6,7,1,4,3,8,2,5)]
      )
  ) %>%
  ggplot(aes(model,Score,color=model_group)) +
  geom_point(size=1) +
  geom_errorbar(aes(ymin=lb,ymax=ub),width=0.5,size=1) +
  geom_hline(aes(yintercept=set_score),lty=2) +
  geom_hline(yintercept=0.5,lty=2) +
  facet_grid(
    set~.
    ,scales='free_y'
    ,space='free'
  ) +
  coord_flip() +
  # geom_text(aes(label=round(wd*100,2)),hjust=-0.2,vjust=0.2,size=2.5,na.rm=T) +
  scale_x_discrete('Data Partition') +
  scale_y_continuous(
    'AUROC (95% CI)',breaks=seq(0,1,0.1)
    ,labels=scales::number_format(accuracy=0.1,decimal.mark='.')
  ) +
  scale_color_npg(name='Model') +
  theme(
    axis.title.y=element_blank()
    ,axis.title.x=element_text(family='sans')
    ,axis.text.y=element_text(size=unit(8,'pt'),family='sans')
    ,axis.text.x=element_text(family='sans')
    ,strip.text.y=element_text(angle=0,size=unit(7,'pt'),family='sans')
  )
```

```{r Compare the AUROCs, fig.height=7.08661, fig.width=7.08661}
auroc
```

## Important predictors

```{r Re-create a function to plot RSDR results}
source('R/plot.rsdr-function.R')
```

```{r Plot weights of PC-ENR, fig.height=10, fig.width=7}
# Get PC weights from the PC elastic net regression model.
coef(model$pc_elnet$finalModel,model$pc_elnet$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var='term') %>%
  
  # Clean up.
  mutate(term=str_remove_all(term,'\\`|\\(|\\)')) %>%
  setNames(c('term','estimate')) %>%
  filter(estimate!=0) %>%
  arrange(desc(abs(estimate))) %>%
  filter(term!='Intercept') %>%
  
  left_join(
    composition(pw_int_rsdr) %>%
      t() %>%
      as.data.frame() %>%
      rownames_to_column(var='term')
    ,by='term'
  ) %>%
  # gather(feature,value,-term,-estimate) %>%
  # mutate(corrected_value=estimate*value) %>%
  # select(-estimate,-value) %>%
  # spread(feature,corrected_value) %>%
  select(-estimate) %>%
  column_to_rownames(var='term') %>%
  t() %>%
  as.data.frame() %>%
  
  rownames_to_column(var='label') %>%
  left_join(
    readRDS('data/annotation.rds') %>%
      rename(label=code,name=desc) %>%
      select(label,name) %>%
      rbind(
        dag$baseline_nodes %>%
          mutate(label=paste0('causal_',label))
      )
    ,by='label'
  ) %>%
  mutate(
    label=
      ifelse(
        label=='estimate'|is.na(name)
        ,label
        ,paste0(label,' - ',str_sub(name,1,40))
      )
  ) %>%
  select(-name) %>%
  column_to_rownames(var='label') %>%
  # as.matrix() %>%
  # heatmap()
  plot.rsdr(w_cutoff=0.1)
```

```{r Show weights of PC-ENR}
coef(model$pc_elnet$finalModel,model$pc_elnet$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var='term') %>%
  
  # Clean up.
  mutate(term=str_remove_all(term,'\\`|\\(|\\)')) %>%
  setNames(c('term','estimate')) %>%
  filter(estimate!=0) %>%
  arrange(desc(abs(estimate))) %>%
  filter(term!='Intercept')
```

```{r Build a function to plot ontonet, include=FALSE}
source('R/plot.viz.ontonet-function.R')
```

```{r Ontonet, fig.height=12, fig.width=18, eval=FALSE, include=FALSE}
visualization$ontonet %>%
  plot.viz.ontonet(
    node.size=8
    ,node.shape='square'
    ,label=T
    ,label.family='serif'
    ,label.cex=0.85
    ,label.color='black'
    ,asp=0
    ,ylim=c(-1,1)
    ,xlim=c(-1,1)
  )
```

```{r Build a function to plot ontoarray, include=FALSE}
source('R/plot.viz.ontoarray-function.R')
```

```{r Ontoarray, fig.height=12, fig.width=12, eval=FALSE, include=FALSE}
visualization$ontoarray %>%
  plot.viz.ontoarray(
    pal=c('#E64B35FF','#00A087FF')
    ,label=T
    ,grid_col=6
  )
```

```{r Filter non-zero ontotype, echo=FALSE}
visualized_codes=
  
  # Get feature data from the ontoarray.
  visualization$ontoarray %>%
  lapply(function(x){
    x$ontotype %>%
      lapply(X=seq(nrow(.)),Y=.,Z=x$output,function(X,Y,Z){
        K=Z[Y$x[X],Y$y[X],Y$z[X]]
        if(K==0){
          NULL
        }else{
          K
        }
      }) %>%
      setNames(x$ontotype$feature)
  }) %>%
  setNames(names(visualization$ontoarray)) %>%
  unlist() %>%
  data.frame(output=.) %>%
  rownames_to_column(var='ontotype') %>%
  separate(ontotype,c('ontotype','code'),sep='\\.') %>%
  
  # Add tendency to event or nonevent.
  mutate(outcome=ifelse(output>=0,'event','nonevent')) %>%
  
  # Add the description.
  left_join(
    pw_hlin %>%
      fData() %>%
      rownames_to_column(var='code')
    ,by='code'
  ) %>%
  select(outcome,ontotype,code,desc) %>%
  arrange(ontotype,code,outcome) %>%
  
  # Simplify outcome.
  group_by(code,ontotype,desc) %>%
  summarize(outcome=paste0(outcome,collapse=' & '),.groups='drop') %>%
  mutate(outcome=ifelse(outcome=='event & nonevent','both',outcome)) %>%
  arrange(code,ontotype,factor(outcome,c('event','nonevent','both')))
```

```{r Show non-zero ontotype, eval=FALSE, include=FALSE}
visualized_codes %>%
  left_join(
    dag$baseline_nodes %>%
      rename(code=label) %>%
      mutate(code=paste0('causal_',code))
    ,by='code'
  ) %>%
  mutate(
    desc=
      ifelse(
        is.na(name)
        ,desc
        ,paste0(name,' (',desc,')')
      )
  ) %>%
  select(-name) %>%
  kable() %>%
  kable_classic()
```

# Results

```{r Prepare data for Figure 1 of the main text, include=FALSE}
# Create an empty list to save the results.
ovl=list()

# Instance summary by pregnancy status
ovl$pregnancy=
  readRDS('data/pregnancy_status.rds') %>%
  select(subject_id,gestation) %>%
  filter(!duplicated(.)) %>%
  group_by(gestation) %>%
  summarize(n=n(),.groups='drop') %>%
  mutate(p=n/sum(n)) %>%
  left_join(
    readRDS('data/pregnancy_status.rds') %>%
      separate(subject_id,c('subject_id','gestation_n'),sep='\\.') %>%
      select(subject_id,gestation) %>%
      filter(!duplicated(.)) %>%
      group_by(gestation) %>%
      summarize(n2=n(),.groups='drop') %>%
      mutate(p2=n2/sum(n2))
    ,by='gestation'
  )

# Subjects in re-calibration set
ovl$a=
  pw_hlin %>%
  .[,!pData(phenoData(.))$censoring] %>%
  .[,pData(protocolData(.))$int] %>%
  .[,colnames(.)%in%training_parameters$pre_calib_set] %>%
  protocolData() %>%
  pData() %>%
  pull(subject_id)

# Subjects in calibration set
ovl$b=
  pw_hlin %>%
  .[,!pData(phenoData(.))$censoring] %>%
  .[,pData(protocolData(.))$int] %>%
  .[,!colnames(.)%in%training_parameters$pre_calib_set] %>%
  protocolData() %>%
  pData() %>%
  pull(subject_id)

# Subjects in random set
ovl$c=
  pw_hlin %>%
  .[,!pData(phenoData(.))$censoring] %>%
  .[,pData(protocolData(.))$ran] %>%
  protocolData() %>%
  pData() %>%
  pull(subject_id)

# Create a function to overlap among three groups.
ovl$func=function(a,b,c,na=NULL,nb=NULL,nc=NULL){
  abc=a %>% intersect(b) %>% intersect(c)
  ab=a %>% intersect(b) %>% setdiff(abc)
  bc=b %>% intersect(c) %>% setdiff(abc)
  ac=a %>% intersect(c) %>% setdiff(abc)
  a=a %>% setdiff(c(ab,abc,ac))
  b=b %>% setdiff(c(ab,abc,bc))
  c=c %>% setdiff(c(ac,abc,bc))
  output=
    c(abc=length(abc)
      ,ab=length(ab)
      ,bc=length(bc)
      ,ac=length(ac)
      ,a=length(a)
      ,b=length(b)
      ,c=length(c)) %>%
    setNames(
      c(paste(na,'\u2229',nb,'\u2229',nc)
         ,paste(na,'\u2229',nb,'-',na,'\u2229',nb,'\u2229',nc)
         ,paste(nb,'\u2229',nc,'-',na,'\u2229',nb,'\u2229',nc)
         ,paste(na,'\u2229',nc,'-',na,'\u2229',nb,'\u2229',nc)
         ,paste(na,'-',na,'\u222A',nb,'\u222A',nc)
         ,paste(nb,'-',na,'\u222A',nb,'\u222A',nc)
         ,paste(nc,'-',na,'\u222A',nb,'\u222A',nc)
         )
    )
  paste(names(output),'=',formatC(output,big.mark=','))
}

# Visit table of outcome and censoring summary
ovl$d=
  cf_nw_int_bin %>%
  phenoData() %>%
  pData() %>%
  select(outcome,censoring) %>%
  table(visits=.)

# Subject table of outcome and censoring summary
ovl$e=
  cf_nw_int_bin %>%
  phenoData() %>%
  pData() %>%
  select(outcome,censoring) %>%
  cbind(
    cf_nw_int_bin %>%
    protocolData() %>%
    pData() %>%
    select(subject_id)
  ) %>%
  filter(!duplicated(.)) %>%
  select(outcome,censoring) %>%
  table(subjects=.)

# Compile into one table.
ovl$f=
  
  # Step-by-step summary for visit/subject selection
  readRDS('data/selection.rds') %>%
  setNames(c('set','exc_v_total','v_total','exc_s_total','s_total')) %>%
  mutate(v_nonevent=NA,v_event=NA,s_nonevent=NA,s_event=NA,note=NA,p=NA) %>%
  select(
    set,v_nonevent,v_event,v_total,s_nonevent,s_event,s_total
    ,note,p,everything()
  ) %>%
  mutate(
    note=case_when(
      set=='up to the latest date for uncensored and split if >1 pregnancies'
      ~'a,b,c'
      ,TRUE~'NA'
    )
  ) %>%
  
  # Summary of the visits/subjects by subset
  rbind(
    
    # Visit summary
    pw_hlin %>%
      
      # Summarize censoring.
      .[,pData(phenoData(.))$censoring] %>%
      ncol() %>%
      `names<-`('censoring') %>%
      data.frame(total=.) %>%
      rownames_to_column(var='set') %>%
      mutate(nonevent=NA,event=NA) %>%
      select(set,nonevent,event,everything()) %>%
      
      # Summarize all subsets.
      rbind(
        pw_hlin %>%
          .[,!pData(phenoData(.))$censoring] %>%
          .[,pData(protocolData(.))$int] %>%
          .[,colnames(.)%in%training_parameters$pre_calib_set] %>%
          sapply(X=1,Y=.,function(X,Y)table(Y$outcome)) %>%
          `colnames<-`('precalib') %>%
          cbind(sapply(test_data,function(x)table(x$outcome))) %>%
          t() %>%
          as.data.frame() %>%
          rownames_to_column(var='set') %>%
          mutate(total=nonevent+event)
      ) %>%
      setNames(c('set',paste0('v_',colnames(.)[-1]))) %>%
      
      # Subject summary
      left_join(
        pw_hlin %>%
          
          # Summarize censoring.
          .[,pData(phenoData(.))$censoring] %>%
          protocolData() %>%
          pData() %>%
          select(subject_id) %>%
          filter(!duplicated(.)) %>%
          nrow() %>%
          `names<-`('censoring') %>%
          data.frame(total=.) %>%
          rownames_to_column(var='set') %>%
          mutate(nonevent=NA,event=NA) %>%
          select(set,nonevent,event,everything()) %>%
          
          # Summarize all subsets.
          rbind(
            lapply(X=c('precalib','calib','ran','geo','tem','bgt')
                   ,Y=pw_hlin %>% .[,!pData(phenoData(.))$censoring]
                   ,function(X,Y){
                
                if(X=='precalib'){
                  Z=Y %>%
                    .[,pData(protocolData(.))$int] %>%
                    .[,colnames(.)%in%training_parameters$pre_calib_set]
                }else if(X=='calib'){
                  Z=Y %>%
                    .[,pData(protocolData(.))$int] %>%
                    .[,!colnames(.)%in%training_parameters$pre_calib_set]
                }else{
                  Z=Y %>%
                    .[,pData(protocolData(.))[[X]]]
                }
                Z %>%
                  lapply(X=1,Y=.,function(X,Y){
                    Y %>%
                      phenoData() %>%
                      pData() %>%
                      select(outcome) %>%
                      cbind(
                        Y %>%
                          protocolData() %>%
                          pData() %>%
                          select(subject_id)
                      )
                  }) %>%
                  .[[1]] %>%
                  filter(!duplicated(.)) %>%
                  pull(outcome) %>%
                  table(precalib=.) %>%
                  as.data.frame() %>%
                  spread(precalib,Freq) %>%
                  mutate(set=X) %>%
                  select(set,everything())
                
              }) %>%
              do.call(rbind,.) %>%
              mutate(total=nonevent+event)
          ) %>%
          setNames(c('set',paste0('s_',colnames(.)[-1])))
        ,by='set'
      ) %>%
      
      # Annotate each subset for the footnote.
      mutate(
        note=case_when(
          set=='precalib'~'d,e,h'
          ,set=='calib'~'d,f,i'
          ,set=='ran'~'d,g,j'
          ,TRUE~'NA'
        )
      ) %>%
      mutate(p=s_event/s_total) %>%
      mutate(exc_v_total=NA,exc_s_total=NA)
  )
```

```{r Show data for Figure 1 of the main text, eval=FALSE, include=FALSE}
ovl$f %>%
  
  # Clean up naming.
  mutate(
    set=ifelse(set=='precalib','internal pre-calibration split',set)
    ,set=ifelse(set=='calib','internal calibration split',set)
    ,set=ifelse(set=='ran','external random split',set)
    ,set=ifelse(set=='geo','external geographical split',set)
    ,set=ifelse(set=='tem','external temporal split',set)
    ,set=ifelse(set=='bgt','external geotemporal split',set)
  ) %>%
  mutate(set=str_to_sentence(set)) %>%
  setNames(c('Subset'
             ,'Nonevent visits','Event visits','Total visits'
             ,'Nonevent subjects','Event subjects','Total subjects'
             ,'Note','Prevalence','Excluded visits','Excluded subjects')) %>%
  
  # Show the table.
  kable(format.args=list(big.mark=',')) %>%
  kable_classic() %>%
  
  # Add the footnote.
  add_footnote(
    c(paste('Gestation'
            ,ovl$pregnancy$gestation
            ,'is',formatC(ovl$pregnancy$n,big.mark=','))
      ,ovl$func(ovl$a,ovl$b,ovl$c,'P','C','R')
      ,paste('Censored visits in causal inference are'
             ,formatC(sum(ovl$d[3:4]),big.mark=','))
      ,paste('Censored subjects in causal inference are'
             ,formatC(sum(ovl$e[3:4]),big.mark=',')))
  )
```

```{r The subject characteristics 1, eval=FALSE, include=FALSE}
char_sub1=
  cf_nw_int_bin %>%
  phenoData() %>%
  pData() %>%
  rownames_to_column(var='id') %>%
  left_join(
    infercause %>%
      protocolData() %>%
      pData() %>%
      rownames_to_column(var='id') %>%
      select(id,subject_id)
    ,by='id'
  ) %>%
  mutate(outcome=as.character(outcome)) %>%
  mutate(outcome=ifelse(censoring,'censored',outcome)) %>%
  group_by(subject_id) %>%
  arrange(desc(age)) %>%
  slice(1) %>%
  ungroup() %>%
  select(
    outcome
    ,gestation
    ,subject_id
    ,age
    ,marital_status
    ,insurance_class
    ,occupation_segment
  ) %>%
  mutate(gestation=as.integer(gestation>0)) %>%
  lapply(X=1,Y=.,function(X,Y){
    Z=data.frame(variable='age',term='y') %>%
      cbind(
        Y %>%
          mutate(group=paste0(outcome,gestation)) %>%
          group_by(group) %>%
          summarize(
            n=round(mean(age))
            ,p=round(sd(age))
            ,total=n()
          )
      )
    
    K=Y %>%
      filter(outcome!='censored') %>%
      select(outcome,age) %>%
      mutate(outcome=factor(outcome,c('nonevent','event'))) %>%
      glm(outcome~age,data=.,family=binomial(link='logit')) %>%
      tidy() %>%
      filter(term!='(Intercept)') %>%
      mutate(
        variable=term
        ,term='y'
        ,OR=exp(estimate)
        ,LB=exp(estimate-qnorm(0.975)*std.error)
        ,UB=exp(estimate+qnorm(0.975)*std.error)
      ) %>%
      select(variable,term,OR,LB,UB, p.value)
    
    L=Y  %>%
      mutate(group=paste0(outcome,gestation)) %>%
      select(-subject_id,-age,-gestation)
    L=suppressWarnings(gather(L,variable,term,-group)) %>%
      group_by(group,variable,term) %>%
      summarize(n=n()) %>%
      group_by(group,variable) %>%
      mutate(
        p=round(n/sum(n)*100,2)
        ,total=sum(n)
      ) %>%
      mutate(term=ifelse(is.na(term),'unspecified',term))
    
    M=Y %>%
      filter(outcome!='censored') %>%
      select(-subject_id,-age,-gestation) %>%
      gather(variable,value,-outcome) %>%
      mutate(
        value=
          ifelse(
            value%in%c('first','married','central-government-paid householder')
            ,paste0('0_',value)
            ,ifelse(is.na(value),'unspecified',value)
          )
      ) %>%
      group_by(variable)
    
    M=suppressWarnings(suppressMessages(
        M %>%
          mutate(outcome=factor(outcome,c('nonevent','event'))) %>%
          do(tidy(glm(outcome~value,data=.,family=binomial(link='logit'))))
      )) %>%
      mutate(
        term=
          ifelse(
            term=='(Intercept)'
            ,case_when(
              variable=='insurance_class'
              ~'first'
              ,variable=='marital_status'
               ~'married'
              ,variable=='occupation_segment'
               ~'central-government-paid householder'
              ,TRUE~'(Intercept)'
            )
            ,term
          )
      ) %>%
      mutate(
        term=str_remove_all(term,'value')
        ,OR=exp(estimate)
        ,LB=exp(estimate-qnorm(0.975)*std.error)
        ,UB=exp(estimate+qnorm(0.975)*std.error)
      ) %>%
      select(variable,term,OR,LB,UB, p.value)
    
    Z %>%
      left_join(K,by=c('variable','term')) %>%
      rbind(
        L %>%
        left_join(M,by=c('variable','term'))
      )
  }) %>%
  .[[1]] %>%
  pivot_wider(names_from='group',values_from=c('n','p','total')) %>%
  group_by(variable) %>%
  fill(
    n_censored0,n_censored1,n_nonevent1,n_event1
    ,p_censored0,p_censored1,p_nonevent1,p_event1
    ,total_censored0,total_censored1,total_nonevent1,total_event1
    ,.direction='updown'
  ) %>%
  filter(!(variable=='outcome' & term%in%c('nonevent','event'))) %>%
  mutate(
    term=ifelse(variable=='outcome','',term)
    ,total=total_censored0+total_censored1+total_nonevent1+total_event1
  ) %>%
  arrange(variable,term) %>%
  mutate(
    OR=
      ifelse(
        term%in%c('first','married','central-government-paid householder')
        ,NA
        ,OR
      )
    ,LB=ifelse(is.na(OR),NA,LB)
    ,UB=ifelse(is.na(OR),NA,UB)
  ) %>%
  mutate(
    term=
      ifelse(
        variable%in%c('age','outcome')
        ,ifelse(
          variable=='age'
          ,paste0('mean (SD), ',term)
          ,'no. (%)'
        )
        ,paste0(term,', no. (%)')
      )
    ,censored0=
      ifelse(
        variable=='age'
        ,paste0(
          format(n_censored0,digits=0,scientific=F)
          ,' ('
          ,format(p_censored0,digits=0,scientific=F)
          ,')'
        )
        ,ifelse(
          variable=='outcome'
          ,paste0(
            format(total_censored0,digits=0,big.mark=',',scientific=F)
            ,'/'
            ,format(
              total_censored0+total_censored1+total_nonevent1+total_event1
              ,digits=0
              ,big.mark=','
              ,scientific=F
            )
            ,' ('
            ,round(
              total_censored0
              /(total_censored0+total_censored1+total_nonevent1+total_event1)
              *100
              ,2
            )
            ,')'
          )
          ,paste0(
            format(n_censored0,digits=0,big.mark=',',scientific=F)
            ,' ('
            ,format(p_censored0,digits=2,scientific=F)
            ,')'
          )
        )
      )
    ,censored1=
      ifelse(
        variable=='age'
        ,paste0(
          format(n_censored1,digits=0,scientific=F)
          ,' ('
          ,format(p_censored1,digits=0,scientific=F)
          ,')'
        )
        ,ifelse(
          variable=='outcome'
          ,paste0(
            format(total_censored1,digits=0,big.mark=',',scientific=F)
            ,'/'
            ,format(
              total_censored0+total_censored1+total_nonevent1+total_event1
              ,digits=0
              ,big.mark=','
              ,scientific=F
            )
            ,' ('
            ,round(
              total_censored1
              /(total_censored0+total_censored1+total_nonevent1+total_event1)
              *100
              ,2
            )
            ,')'
          )
          ,paste0(
            format(n_censored1,digits=0,big.mark=',',scientific=F)
            ,' ('
            ,format(p_censored1,digits=2,scientific=F)
            ,')'
          )
        )
      )
    ,nonevent1=
      ifelse(
        variable=='age'
        ,paste0(
          format(n_nonevent1,digits=0,scientific=F)
          ,' ('
          ,format(p_nonevent1,digits=0,scientific=F)
          ,')'
        )
        ,ifelse(
          variable=='outcome'
          ,paste0(
            format(total_nonevent1,digits=0,big.mark=',',scientific=F)
            ,'/'
            ,format(
              total_nonevent1+total_event1
              ,digits=0
              ,big.mark=','
              ,scientific=F
            )
            ,' ('
            ,round(total_nonevent1/(total_nonevent1+total_event1)*100,2)
            ,')'
          )
          ,paste0(
            format(n_nonevent1,digits=0,big.mark=',',scientific=F)
            ,' ('
            ,format(p_nonevent1,digits=2,scientific=F)
            ,')'
          )
        )
      )
    ,event1=
      ifelse(
        variable=='age'
        ,paste0(
          format(n_event1,digits=0,scientific=F)
          ,' ('
          ,format(p_event1,digits=0,scientific=F)
          ,')'
        )
        ,ifelse(
          variable=='outcome'
          ,paste0(
            format(total_event1,digits=0,big.mark=',',scientific=F)
            ,'/'
            ,format(
              total_nonevent1+total_event1
              ,digits=0
              ,big.mark=','
              ,scientific=F
            )
            ,' ('
            ,round(total_event1/(total_nonevent1+total_event1)*100,2)
            ,')'
          )
          ,paste0(
            format(n_event1,digits=0,big.mark=',',scientific=F)
            ,' ('
            ,format(p_event1,digits=2,scientific=F)
            ,')'
          )
        )
      )
    ,unadjusted_OR=
      ifelse(
        is.na(OR)
        ,ifelse(variable=='outcome','','(reference)')
        ,paste0(
          round(OR,3)
          ,' ('
          ,round(LB,3)
          ,' to '
          ,round(UB,3)
          ,'; '
          ,case_when(
            p.value<0.001~'P<.001***'
            ,p.value<0.01
             ~paste0(
               'P='
               ,p.value %>%
                 round(3) %>%
                 as.character() %>%
                 str_replace_all('0\\.','.')
               ,'**'
              )
            ,p.value<0.05
             ~paste0(
               'P='
               ,p.value %>%
                 round(2) %>%
                 as.character() %>%
                 str_replace_all('0\\.','.')
               ,'*'
              )
            ,p.value<=0.99
             ~paste0(
               'P='
               ,p.value %>%
                 round(2) %>%
                 as.character() %>%
                 str_replace_all('0\\.','.')
              )
            ,TRUE~'p>.99'
          )
          ,')'
        )
      )
  ) %>%
  arrange(
    factor(
      variable
      ,c('outcome'
         ,'age'
         ,'insurance_class'
         ,'marital_status'
         ,'occupation_segment')
    )
    ,desc(unadjusted_OR=='(reference)')
    ,desc(OR)
  ) %>%
  group_by(variable) %>%
  mutate(variable=ifelse(seq(n())==1,variable,'')) %>%
  ungroup() %>%
  select(variable,term,censored0,censored1,nonevent1,event1,unadjusted_OR)
```

```{r The subject characteristics 2, eval=FALSE, include=FALSE}
cat('Extract baseline data of medical histories\n')
cat('Started:',as.character(now()),'\n')

nw_bin=
  ExpressionSet(
    assayData=
      rbind(
        exprs(infercause) %>%
          `rownames<-`(paste0('causal_',rownames(.)))
        ,exprs(inferdata)
      )
    ,phenoData=phenoData(inferdata)
    ,featureData=
      rbind(
        fData(infercause) %>%
          `rownames<-`(paste0('causal_',rownames(.)))
        ,fData(inferdata)
      ) %>%
      AnnotatedDataFrame(varMetadata=fvarMetadata(inferdata))
    ,experimentData=
      MIAME(
        name='Herdiantri Sufriyana'
        ,lab='Emily Chia-Yu Su Lab'
        ,contact='herdiantrisufriyana@unusa.ac.id'
        ,title='Medical history dataset for causal inference'
        ,abstract=
          str_replace_all(
            'This dataset is a medical-history table from the BPJS Kesehatan.
            Selected causal factors, that is re-assigned by regex, are added.
            The target population is health insurance holders of 
            12-to-55-years-old females who visit healthcare providers between 
            2015 and 2016. The outcome of interest is prelabor rupture of 
            membrane (PROM). The medical history scenario is recorded
            individually within each healthcare provider nationwide.'
            ,'\n',' '
          ) %>%
          str_replace_all('\\s+',' ')
        ,url='https://github.com/herdiantrisufriyana/prom'
      )
    ,annotation=annotation(inferdata)
    ,protocolData=protocolData(inferdata)
  ) %>%
  trans_binary()

nw_subject_bin=
  cbind(
    nw_bin %>%
      protocolData() %>%
      pData() %>%
      select(subject_id)
    ,nw_bin %>%
      phenoData() %>%
      pData() %>%
      select(outcome)
    ,nw_bin %>%
      exprs() %>%
      t() %>%
      as.data.frame()
  ) %>%
  group_by(subject_id,outcome) %>%
  summarize_all(function(x)as.integer(sum(x)>0)) %>%
  ungroup()

cat('End:',as.character(now()))

# Extract baseline data of medical histories
# Started: 2021-09-24 14:30:50 
# Convert the day intervals into the binarized ones
#   |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=02s  
# End: 2021-09-24 14:32:23

char_sub2=
  cf_nw_int_bin %>%
  phenoData() %>%
  pData() %>%
  rownames_to_column(var='id') %>%
  left_join(
    infercause %>%
      protocolData() %>%
      pData() %>%
      rownames_to_column(var='id') %>%
      select(id,subject_id)
    ,by='id'
  ) %>%
  mutate(outcome=as.character(outcome)) %>%
  mutate(outcome=ifelse(censoring,'censored',outcome)) %>%
  group_by(subject_id) %>%
  arrange(desc(age)) %>%
  slice(1) %>%
  ungroup() %>%
  select(subject_id,outcome) %>%
  left_join(select(nw_subject_bin,-outcome),by='subject_id') %>%
  separate(subject_id,c('subject_id','pregnancy'),sep='\\.') %>%
  mutate(gestation=as.integer(pregnancy>0)) %>%
  .[,c('outcome','gestation',paste0('causal_',colnames(dag$sig2)))] %>%
  lapply(X=1,Y=.,function(X,Y){
    Z=Y %>%
      unite(outcome,outcome,gestation,sep='') %>%
      mutate(
        outcome=factor(outcome,c('censored0','censored1','nonevent1','event1'))
      )
    
    K=dag$ipw2 %>%
      lapply(function(x){
        data.frame(
            OR=exp(x$marginal_effect)
            ,LB=exp(x$CI95_interval[1])
            ,UB=exp(x$CI95_interval[2])
            ,p.value=x$p_value
          ) %>%
          `rownames<-`(NULL)
      }) %>%
      do.call(rbind,.) %>%
      rownames_to_column(var='variable') %>%
      mutate(term='positive') %>%
      select(variable,term,OR,LB,UB, p.value) %>%
      mutate(variable=paste0('causal_',variable))

    Z=Z %>%
      group_by(outcome) %>%
      summarize_all(function(x)sum(x==0)) %>%
      gather(variable,negative,-outcome) %>%
      left_join(
        Z %>%
          group_by(outcome) %>%
          summarize_all(function(x)sum(x==1)) %>%
          gather(variable,positive,-outcome)
        ,by=c('outcome','variable')
      ) %>%
      gather(term,n,-outcome,-variable) %>%
      group_by(outcome,variable) %>%
      mutate(
        p=n/sum(n)
        ,total=sum(n)
      ) %>%
      ungroup() %>%
      pivot_wider(names_from='outcome',values_from=c('n','p','total'))

    Z %>%
      left_join(K,by=c('variable','term')) %>%
      arrange(variable,term)
  }) %>%
  .[[1]] %>%
  mutate(
    term=
      ifelse(
        variable=='causal_A20'
        ,ifelse(
          term=='negative'
          ,'20 to 35 y'
          ,'<20 or >35 y'
        )
        ,term
      )
    ,term=paste0(term,', no. (%)')
    ,censored0=
      paste0(
        format(n_censored0,digits=0,big.mark=',',scientific=F)
        ,' ('
        ,format(p_censored0,digits=2,scientific=T)
        ,')'
      )
    ,censored1=
      paste0(
        format(n_censored1,digits=0,big.mark=',',scientific=F)
        ,' ('
        ,format(p_censored1,digits=2,scientific=T)
        ,')'
      )
    ,nonevent1=
      paste0(
        format(n_nonevent1,digits=0,big.mark=',',scientific=F)
        ,' ('
        ,format(p_nonevent1,digits=2,scientific=T)
        ,')'
      )
    ,event1=
      paste0(
        format(n_event1,digits=0,big.mark=',',scientific=F)
        ,' ('
        ,format(p_event1,digits=2,scientific=T)
        ,')'
      )
    ,unadjusted_OR=
      ifelse(
        is.na(OR)
        ,ifelse(variable=='outcome','','(reference)')
        ,paste0(
          round(OR,3)
          ,' ('
          ,round(LB,3)
          ,' to '
          ,round(UB,3)
          ,'; '
          ,case_when(
            p.value<0.001~'P<.001***'
            ,p.value<0.01
             ~paste0(
               'P='
               ,p.value %>%
                 round(3) %>%
                 as.character() %>%
                 str_replace_all('0\\.','.')
               ,'**'
              )
            ,p.value<0.05
             ~paste0(
               'P='
               ,p.value %>%
                 round(2) %>%
                 as.character() %>%
                 str_replace_all('0\\.','.')
               ,'*'
              )
            ,p.value<=0.99
             ~paste0(
               'P='
               ,p.value %>%
                 round(2) %>%
                 as.character() %>%
                 str_replace_all('0\\.','.')
              )
            ,TRUE~'p>.99'
          )
          ,')'
        )
      )
  ) %>%
  arrange(
    factor(
      variable
      ,c(paste0('causal_',colnames(dag$sig2)))
    )
    ,desc(unadjusted_OR=='(reference)')
    ,desc(OR)
  ) %>%
  left_join(
    dag$baseline_nodes %>%
      rename(variable=label,desc=name) %>%
      mutate(variable=paste0('causal_',variable)) %>%
      select(variable,desc)
    ,by='variable'
  ) %>%
  unite(variable,variable,desc,sep=': ') %>%
  group_by(variable) %>%
  mutate(variable=ifelse(seq(n())==1,variable,'')) %>%
  ungroup() %>%
  select(variable,term,censored0,censored1,nonevent1,event1,unadjusted_OR)
```

```{r The subject characteristics 3, eval=FALSE, include=FALSE}
char_sub3=
  cf_nw_int_bin %>%
  phenoData() %>%
  pData() %>%
  rownames_to_column(var='id') %>%
  left_join(
    infercause %>%
      protocolData() %>%
      pData() %>%
      rownames_to_column(var='id') %>%
      select(id,subject_id)
    ,by='id'
  ) %>%
  mutate(outcome=as.character(outcome)) %>%
  mutate(outcome=ifelse(censoring,'censored',outcome)) %>%
  group_by(subject_id) %>%
  arrange(desc(age)) %>%
  slice(1) %>%
  ungroup() %>%
  lapply(X=1,Y=.,function(X,Y){
    Z=Y %>%
      filter(gestation>=1) %>%
      mutate(gestation=factor(gestation,c(1,2))) %>%
      mutate(outcome=factor(outcome,c('nonevent','event'))) %>%
      glm(outcome~gestation,data=.,family=binomial(link='logit')) %>%
      tidy() %>%
      mutate(
        variable='pregnancy episode within the database period'
        ,estimate=ifelse(term=='(Intercept)',NA,estimate)
        ,term=ifelse(term=='(Intercept)','first pregnancy','second pregnancy')
        ,term=paste0(term,',c no. (%)')
        ,OR=exp(estimate)
        ,LB=exp(estimate-qnorm(0.975)*std.error)
        ,UB=exp(estimate+qnorm(0.975)*std.error)
      ) %>%
      mutate(
        unadjusted_OR=
          ifelse(
            is.na(OR)
            ,ifelse(variable=='outcome','','(reference)')
            ,paste0(
              round(OR,3)
              ,' ('
              ,round(LB,3)
              ,' to '
              ,round(UB,3)
              ,'; '
              ,case_when(
                p.value<0.001~'P<.001***'
                ,p.value<0.01
                 ~paste0(
                   'P='
                   ,p.value %>%
                     round(3) %>%
                     as.character() %>%
                     str_replace_all('0\\.','.')
                   ,'**'
                  )
                ,p.value<0.05
                 ~paste0(
                   'P='
                   ,p.value %>%
                     round(2) %>%
                     as.character() %>%
                     str_replace_all('0\\.','.')
                   ,'*'
                  )
                ,p.value<=0.99
                 ~paste0(
                   'P='
                   ,p.value %>%
                     round(2) %>%
                     as.character() %>%
                     str_replace_all('0\\.','.')
                  )
                ,TRUE~'P>.99'
              )
              ,')'
            )
          )
      ) %>%
      select(variable,term,unadjusted_OR)
    
    K=Y %>%
      mutate(
        gestation2=as.integer(gestation>0)
      ) %>%
      unite(outcome,outcome,gestation2,sep='') %>%
      select(gestation,outcome) %>%
      table() %>%
      as.data.frame() %>%
      group_by(outcome) %>%
      mutate(p=Freq/sum(Freq)) %>%
      mutate(
        Freq=format(Freq,digits=0,big.mark=',')
        ,p=paste0('(',round(p*100,2),')')
      ) %>%
      unite(summary,Freq,p,sep=' ') %>%
      spread(outcome,summary) %>%
      mutate(
        variable='pregnancy episode within the database period'
        ,term=
          case_when(
            gestation==0~'no pregnancy, no. (%)'
            ,gestation==1~'first pregnancy,c no. (%)'
            ,gestation==2~'second pregnancy,c no. (%)'
            ,TRUE~''
          )
      ) %>%
      select(-gestation) %>%
      select(variable,term,censored0,censored1,nonevent1,event1)
    
    K %>%
      left_join(Z,by=c('variable','term')) %>%
      mutate(unadjusted_OR=ifelse(is.na(unadjusted_OR),'N/A',unadjusted_OR))
  }) %>%
  .[[1]] %>%
  group_by(variable) %>%
  mutate(variable=ifelse(seq(n())==1,variable,'')) %>%
  ungroup()
```

```{r table-1, eval=FALSE, include=FALSE}
char_sub3 %>%
  mutate(variable=ifelse(variable=='',NA,variable)) %>%
  fill(variable) %>%
  filter(term!='no pregnancy, no. (%)') %>%
  group_by(variable) %>%
  mutate(variable=ifelse(seq(n())==1,variable,'')) %>%
  ungroup() %>%
  rbind(char_sub1 %>% .[2:nrow(.),]) %>%
  rbind(char_sub2) %>%
  mutate(
    unadjusted_OR=
      ifelse(
        unadjusted_OR%in%c('-','(reference)')
        ,unadjusted_OR
        ,str_split_fixed(unadjusted_OR,'; ',2)[,2] %>%
          str_remove_all('\\)')
      )
  ) %>%
  mutate(
    variable=
      case_when(
        str_detect(variable,'causal_')
         ~str_split_fixed(variable,': ',2)[,2]
        ,str_detect(variable,'_')
         ~str_to_sentence(str_replace_all(variable,'_',' '))
        ,variable==''~''
        ,TRUE~str_to_sentence(variable)
      )
  ) %>%
  select(-censored0,-censored1) %>%
  setNames(
    c('Variable'
      ,''
      ,paste0(
        'Not FGR/SGAa (n='
        ,str_split_fixed(char_sub1$nonevent1,'/',2)[1,1]
        ,')'
      )
      ,paste0(
        'FGR/SGAa (n='
        ,str_split_fixed(char_sub1$event1,'/',2)[1,1]
        ,')'
      )
      ,'P value')
  ) %>%
  kable() %>%
  kable_classic() %>%
  
  # Add the footnote.
  add_footnote(
    c('Subject per pregnancy episode (not including censored delivery)'
      ,'Not FGR/SGA vs. FGR/SGA (not including those who were not pregnant)'
      ,paste0(
        'The first and second pregnancies of '
        ,'a subject within the database period'
      ))
    ,notation='alphabet'
  )
```

```{r Prepare causal inference table, include=FALSE}
cauinf_tab=
  # Get causal inference results.
  rbind(
    
    # Causal inference table by outcome regression
    dag$coef %>%
      lapply(X=seq(length(.)),Y=.,function(X,Y){
        Y[[X]] %>%
          filter(term!='(Intercept)') %>%
          slice(1) %>%
          mutate(
            code=term
            ,marginal_effect=OR
            ,lb=OR_lb
            ,ub=OR_ub
            ,p.value=p.value
          ) %>%
          select(code,marginal_effect,lb,ub,p.value)
      }) %>%
      do.call(rbind,.) %>%
      mutate(method='Outcome regression (95% CI; P value)')
    
    # Causal inference table by IPW
    ,dag$ipw %>%
      lapply(X=seq(length(.)),Y=.,function(X,Y){
        data.frame(
          code=names(Y)[X]
          ,marginal_effect=exp(Y[[X]]$marginal_effect)
          ,lb=exp(Y[[X]]$CI95_interval['LB'])
          ,ub=exp(Y[[X]]$CI95_interval['UB'])
          ,p.value=Y[[X]]$p_value
        ) %>%
          `rownames<-`(NULL)
      }) %>%
      do.call(rbind,.) %>%
      mutate(method='Inverse probability weighting (95% CI; P value)')
    
  ) %>%
  
  # Include the description of the causal factors.
  left_join(
    dag$baseline_nodes %>%
      rename(code=label) %>%
      mutate(factor=paste(code,name)) %>%
      select(factor,code)
    ,by='code'
  ) %>%
  select(-code) %>%
  
  # Wrap up.
  select(method,factor,everything()) %>%
  mutate_at(c('marginal_effect','lb','ub'),round,3) %>%
  mutate(
    effect=
      paste0(
        marginal_effect
        ,' ('
        ,lb
        ,' to '
        ,ub
        ,'; '
        ,case_when(
          p.value<0.001~'P<.001***'
          ,p.value<0.01
           ~paste0(
             'P='
             ,p.value %>%
               round(3) %>%
               as.character() %>%
               str_replace_all('0\\.','.')
             ,'**'
            )
          ,p.value<0.05
           ~paste0(
             'P='
             ,p.value %>%
               round(2) %>%
               as.character() %>%
               str_replace_all('0\\.','.')
             ,'*'
            )
          ,p.value<=0.99
           ~paste0(
             'P='
             ,p.value %>%
               round(2) %>%
               as.character() %>%
               str_replace_all('0\\.','.')
            )
          ,TRUE~'P>.99'
        )
        ,')'
      )
  ) %>%
  select(-marginal_effect,-lb,-ub,-p.value) %>%
  spread(method,effect) %>%
  select(factor,`Outcome regression (95% CI; P value)`,everything()) %>%
  mutate(factor=sapply(X=factor,function(X)str_sub(X,5,str_count(X)))) %>%
  rename(`Latent candidate predictors`=factor)
```

```{r Causal inference, eval=FALSE, include=FALSE}
cauinf_tab %>%
  kable() %>%
  kable_classic() %>%
  add_footnote(
    c('P<.05; ** P<.01; *** P<.001; CI, confidence interval')
    ,'symbol'
  )
```

```{r table-C8, eval=FALSE, include=FALSE}
# Save causal inference table
cauinf_tab %>%
  
  # Save for Table C8.
  write_csv('data/table_C8.csv')
```

```{r table-2, eval=FALSE, include=FALSE}
char_sub2 %>%
  mutate(variable=ifelse(variable=='',NA,variable)) %>%
  fill(variable) %>%
  separate(variable,c('code','variable'),sep=': ') %>%
  filter(unadjusted_OR!='(reference)') %>%
  select(variable,unadjusted_OR) %>%
  left_join(
    cauinf_tab %>%
      select(-`Outcome regression (95% CI; P value)`) %>%
      setNames(c('variable','adjusted_OR')) %>%
      mutate(variable=trimws(variable))
    ,by='variable'
  ) %>%
  mutate(
    adjustment=
      variable %>%
      sapply(function(x){
        y=dag$formula[[
            dag$baseline_nodes$label[dag$baseline_nodes$name==x]
          ]] %>%
          as.character() %>%
          .[3] %>%
          str_split(' \\+ ') %>%
          .[[1]]
        
        if(length(y)>1){
          y %>%
            .[2:length(.)] %>%
            data.frame(label=.) %>%
            left_join(dag$baseline_nodes,by='label') %>%
            pull(name) %>%
            paste0(collapse=' + ')
        }else{
          '(no adjustment)'
        }
      })
  ) %>%
  mutate(adjusted_OR=str_remove_all(adjusted_OR,'95% CI ')) %>%
  setNames(
    c('Variable of interest'
      ,'Unadjusted OR (95% CI; P value)'
      ,'Adjusted OR (95% CI; P value)'
      ,'Adjustment')
  ) %>%
  kable() %>%
  kable_classic() %>%
  
  # Add the footnote.
  add_footnote(
    c('P<.05; ** P<.01; *** P<.001; CI, confidence interval;')
    ,'symbol'
  )
```

```{r Selected DAGs, eval=FALSE, include=FALSE}
figures_b1_to_b9=
  caudag_img %>%
  .[which(
    pull(
        dag$baseline_nodes %>%
          filter(str_sub(label,1,1)=='A')
        ,label
      )%in%colnames(dag$sig)[dag$sig[2,]==1]
  )] %>%
  `names<-`(
    dag$baseline_nodes %>%
      filter(label%in%colnames(dag$sig)[dag$sig[2,]==1]) %>%
      column_to_rownames(var='label') %>%
      .[pull(
            dag$baseline_nodes %>%
              filter(str_sub(label,1,1)=='A')
            ,label
          ) %>%
          .[.%in%colnames(dag$sig)[dag$sig[2,]==1]]
        ,]
  )
```

```{r figure-B1, fig.height=9.5, fig.width=7.08661, eval=FALSE, include=FALSE}
figures_b1_to_b9$PIH
```

```{r figure-B2, fig.height=3.46457, fig.width=3.46457, eval=FALSE, include=FALSE}
figures_b1_to_b9$`Multiple pregnancy`
```

```{r figure-B3, fig.height=3.46457, fig.width=3.46457, eval=FALSE, include=FALSE}
figures_b1_to_b9$Malaria
```

```{r figure-B4, fig.height=3.46457, fig.width=3.46457, eval=FALSE, include=FALSE}
figures_b1_to_b9$Varicella
```

```{r figure-B5, fig.height=3.46457, fig.width=3.46457, eval=FALSE, include=FALSE}
figures_b1_to_b9$`Maternal age`
```

```{r figure-B6, fig.height=3.46457, fig.width=3.46457, eval=FALSE, include=FALSE}
figures_b1_to_b9$UTI
```

```{r figure-B7, fig.height=7.08661, fig.width=7.08661, eval=FALSE, include=FALSE}
figures_b1_to_b9$`Placenta previa`
```

```{r figure-B8, fig.height=3.46457, fig.width=3.46457, eval=FALSE, include=FALSE}
figures_b1_to_b9$`Low SES`
```

```{r Prepare data for Figure B10, include=FALSE}
suppressWarnings(set.seed(66,sample.kind=sample.kind))
figure_b10=
  
  # Filter the edges involving only the causal factors and outcome.
  dag$baseline_edges[,-3] %>%
  filter(
    (from %in% colnames(dag$sig)[dag$sig[2,]==1] &
     to %in% c('Y001',colnames(dag$sig)[dag$sig[2,]==1]))
  ) %>%
  
  # Join with the IPW results.
  left_join(
    dag$ipw %>%
      lapply(X=seq(length(.)),Y=.,function(X,Y){
        data.frame(
            from=names(Y)[X]
            ,to='Y001'
            ,marginal_effect=Y[[X]]$marginal_effect
            ,LB=Y[[X]]$CI95_interval['LB']
            ,UB=Y[[X]]$CI95_interval['UB']
            ,p_value=Y[[X]]$p_value
          ) %>%
          `rownames<-`(NULL)
      }) %>%
      do.call(rbind,.)
    ,by=c('from','to')
  ) %>%
  
  # Assign the labels.
  left_join(
    dag$baseline_nodes %>%
      rename(from=label) %>%
      mutate(label=paste(from,name)) %>%
      select(from,label)
    ,by='from'
  ) %>%
  select(-from) %>%
  rename(from=label) %>%
  left_join(
    dag$baseline_nodes %>%
      rename(to=label) %>%
      mutate(label=paste(to,name)) %>%
      select(to,label)
    ,by='to'
  ) %>%
  select(-to) %>%
  rename(to=label) %>%
  
  # Convert to igraph object then ggnetwork dataframe.
  select(from,to,everything()) %>%
  graph_from_data_frame() %>%
  ggnetwork(
    layout=
      layout_as_tree(
        .
        ,root=c()
        ,mode='in'
        ,circular=T
      )[,2:1]
  ) %>%
  mutate(code=str_sub(name,1,3))  %>%
  mutate(name=sapply(X=name,function(X)str_sub(X,5,str_count(X))))
```

```{r figure-B10, echo=FALSE, fig.cap='Final association diagram', fig.height=3.46457, fig.width=3.46457}
figure_b10 %>%
  ggplot(aes(x=x,y=y,xend=xend,yend=yend)) +
  geom_nodes(
    aes(color=code)
    ,show.legend=F
    ,size=8
  ) +
  geom_edges(
    aes(color=code)
    ,arrow=arrow(length=unit(4,'pt'),type='closed')
    ,curvature=0.15
    ,show.legend=F
  ) +
  geom_nodelabel_repel(
    aes(label=name,color=code)
    ,family='sans'
    ,size=unit(3,'pt')
    ,alpha=0.75
    ,show.legend=F
  ) +
  scale_color_npg() +
  theme_blank()
```

```{r figure-3, echo=FALSE, fig.height=5.85827, fig.width=7.08661}
# fig.height=5.85827, fig.width=7.08661 on top of this chunk if shown here
suppressWarnings(ggarrange(
    ggarrange(
      calibration_plot
      ,event_dist
      ,nonevent_dist
      ,heights=c(1.5,1,1.5)
      ,labels=c('','','')
      ,ncol=1,nrow=3
    )
    ,dca
    ,heights=c(4,1.85827)
    ,labels=c('a','b')
    ,ncol=1,nrow=2
  )) +
  ggsave(
    filename="figure2.eps"
    ,device=cairo_ps
    ,width=170
    ,height=170/7.08661*5.85827
    ,unit='mm'
  )
```

```{r Best calibration, eval=FALSE, include=FALSE}
calibration_plot_data %>%
  right_join(
    data.frame(
      model=c('PC-ENR','PC-GBM','DI-VNN')
      ,event=c(0.03,0.03,0.02)
    )
    ,by=c('model','event')
  )
```

```{r Best clinical utility, eval=FALSE, include=FALSE}
roc %>%
  arrange(model,desc(nb)) %>%
  group_by(model,nb,bound) %>%
  slice(1) %>%
  ungroup() %>%
  right_join(
    data.frame(
      model=c('PC-ENR','PC-GBM','DI-VNN')
      ,th=c(0.03,0.03,0.02)
    )
    ,by=c('model','th')
  )
```

```{r table-C9, eval=FALSE, include=FALSE}
# Save weights of PC
model_weight$pc %>%
  
  # Save for Table C9.
  write_csv('data/table_C9.csv')
```

```{r table-C10, eval=FALSE, include=FALSE}
# Save weights of PC-ENR
model_weight$pc_elnet %>%
  
  # Save for Table C10.
  write_csv('data/table_C10.csv')
```

```{r table-C11, eval=FALSE, include=FALSE}
# Save weights of PC-GBM
model_weight$pc_gbm %>%
  
  # Save for Table C11.
  write_csv('data/table_C11.csv')
```

```{r table-C12, eval=FALSE, include=FALSE}
# Save differential analysis
model_weight$fit %>%
  
  # Save for Table C12.
  write_csv('data/table_C12.csv')
```

```{r table-C13, eval=FALSE, include=FALSE}
# Save weights of DI-VNN
model_weight$divnn %>%
  
  # Save for Table C13.
  write_csv('data/table_C13.csv')
```

```{r table-C14, eval=FALSE, include=FALSE}
# Save ontology table
input$ontology %>%
  filter(relation!='feature') %>%
  select(-relation) %>%
  setNames(str_to_sentence(colnames(.))) %>%
  
  # Save for Table C14.
  write_csv('data/table_C14.csv')
```

```{r table-3, echo=FALSE}
cp %>%
  select(
    model
    ,predictor,desc
    ,pn_obs,ps_obs_pred2
    ,gp,ob_gyn
  ) %>%
  unite(predictor,predictor,desc,sep=', ') %>%
  setNames(
    c('Model'
      ,'Top-five predictor'
      ,'PN (95% CI)','PS (95% CI)'
      ,'Clinician 1','Clinician 2')
  ) %>%
  kable() %>%
  kable_classic()
```

```{r table-C15, eval=FALSE, include=FALSE}
# Save counterfactual probabilities of PC-ENR
cx$pc_elnet %>%
  filter(metric%in%c('pn_obs','ps_obs_pred2')) %>%
  mutate(
    metric=
      case_when(
        metric=='pn_obs'~'PN (95% CI)'
        ,metric=='ps_obs_pred2'~'PS (95% CI)'
      )
  ) %>%
  mutate_at(c('avg','lb','ub'),function(x)paste0(round(x*100,2),'%')) %>%
  unite(ci,lb,ub,sep=' to ') %>%
  mutate(ci=paste0('(',ci,')')) %>%
  unite(estimate,avg,ci,sep=' ') %>%
  spread(metric,estimate,fill='0% (0% to 0%)') %>%
  left_join(
    readRDS('data/annotation.rds') %>%
      rename(label=code,name=desc) %>%
      select(label,name) %>%
      rbind(
        dag$baseline_nodes %>%
          mutate(label=paste0('causal_',label))
      ) %>%
      rename(predictor=label,description=name)
    ,by='predictor'
  ) %>%
  select(predictor,description,everything()) %>%
  rename(Predictor=predictor,Description=description) %>%
  
  # Save for Table C15.
  write_csv('data/table_C15.csv')
```

```{r table-C16, eval=FALSE, include=FALSE}
# Save counterfactual probabilities of PC-GBM
cx$pc_gbm %>%
  filter(metric%in%c('pn_obs','ps_obs_pred2')) %>%
  mutate(
    metric=
      case_when(
        metric=='pn_obs'~'PN (95% CI)'
        ,metric=='ps_obs_pred2'~'PS (95% CI)'
      )
  ) %>%
  mutate_at(c('avg','lb','ub'),function(x)paste0(round(x*100,2),'%')) %>%
  unite(ci,lb,ub,sep=' to ') %>%
  mutate(ci=paste0('(',ci,')')) %>%
  unite(estimate,avg,ci,sep=' ') %>%
  spread(metric,estimate,fill='0% (0% to 0%)') %>%
  left_join(
    readRDS('data/annotation.rds') %>%
      rename(label=code,name=desc) %>%
      select(label,name) %>%
      rbind(
        dag$baseline_nodes %>%
          mutate(label=paste0('causal_',label))
      ) %>%
      rename(predictor=label,description=name)
    ,by='predictor'
  ) %>%
  select(predictor,description,everything()) %>%
  rename(Predictor=predictor,Description=description) %>%
  
  # Save for Table C16.
  write_csv('data/table_C16.csv')
```

```{r table-C17, eval=FALSE, include=FALSE}
# Save counterfactual probabilities of DI-VNN
cx$divnn %>%
  filter(metric%in%c('pn_obs','ps_obs_pred2')) %>%
  mutate(
    metric=
      case_when(
        metric=='pn_obs'~'PN (95% CI)'
        ,metric=='ps_obs_pred2'~'PS (95% CI)'
      )
  ) %>%
  mutate_at(c('avg','lb','ub'),function(x)paste0(round(x*100,2),'%')) %>%
  unite(ci,lb,ub,sep=' to ') %>%
  mutate(ci=paste0('(',ci,')')) %>%
  unite(estimate,avg,ci,sep=' ') %>%
  spread(metric,estimate,fill='0% (0% to 0%)') %>%
  left_join(
    readRDS('data/annotation.rds') %>%
      rename(label=code,name=desc) %>%
      select(label,name) %>%
      rbind(
        dag$baseline_nodes %>%
          mutate(label=paste0('causal_',label))
      ) %>%
      rename(predictor=label,description=name)
    ,by='predictor'
  ) %>%
  select(predictor,description,everything()) %>%
  rename(Predictor=predictor,Description=description) %>%
  
  # Save for Table C17.
  write_csv('data/table_C17.csv')
```

```{r table-C18, eval=FALSE, include=FALSE}
# Save SRMA results
read_xlsx('data/srma_results.xlsx') %>%
  select(-nonevent) %>%
  mutate(p=paste0('(',round(event/total*100,2),'%',')')) %>%
  unite(n_N,event,total,sep='/') %>%
  unite(n_N_p,n_N,p,sep=' ') %>%
  
  mutate_at(
    colnames(.) %>%
      .[str_detect(.,'sens')]
    ,function(x)paste0(round(x*100,2),'%')
  ) %>%
  unite(sens_ci,sens_lb,sens_ub,sep=' to ') %>%
  mutate(
    sens_ci=
      sens_ci %>%
      sapply(function(x)ifelse(x=='NA% to NA%','',paste0('(',x,')')))
  ) %>%
  unite(sens,sens,sens_ci,sep=' ') %>%
  mutate(sens=trimws(sens)) %>%
  
  mutate_at(
    colnames(.) %>%
      .[str_detect(.,'spec')]
    ,function(x)paste0(round(x*100,2),'%')
  ) %>%
  unite(spec_ci,spec_lb,spec_ub,sep=' to ') %>%
  mutate(
    spec_ci=
      spec_ci %>%
      sapply(function(x)ifelse(x=='NA% to NA%','',paste0('(',x,')')))
  ) %>%
  unite(spec,spec,spec_ci,sep=' ') %>%
  mutate(spec=trimws(spec)) %>%
  
  mutate_at(
    colnames(.) %>%
      .[str_detect(.,'auroc')]
    ,function(x)round(x,3)
  ) %>%
  unite(auroc_ci,auroc_lb,auroc_ub,sep=' to ') %>%
  mutate(
    auroc_ci=
      auroc_ci %>%
      sapply(function(x)ifelse(x=='NA to NA','',paste0('(',x,')')))
  ) %>%
  unite(auroc,auroc,auroc_ci,sep=' ') %>%
  mutate(auroc=trimws(auroc)) %>%
  mutate(
    inference=
      inference %>%
      str_replace_all('sens','Sensitivity') %>%
      str_replace_all('spec','Specificity') %>%
      str_replace_all('auroc','AUROC')
  ) %>%
  `colnames<-`(
    colnames(.) %>%
      str_replace_all('study','Study') %>%
      str_replace_all('n_N_p','Sample size') %>%
      str_replace_all('sens','Sensitivity (95% CI)') %>%
      str_replace_all('spec','Specificity (95% CI)') %>%
      str_replace_all('auroc','AUROC (95% CI)') %>%
      str_replace_all('inference','Inference') %>%
      str_replace_all('year','Year') %>%
      str_replace_all('papp_a','PAPP-A') %>%
      str_replace_all('uta_pi','UtA-PI') %>%
      str_replace_all('fbhcg','Free b-hCG') %>%
      str_replace_all('crl','CRL') %>%
      str_replace_all('age','Age') %>%
      str_replace_all('weight','Weight') %>%
      str_replace_all('cig_smoker','Cig. smoker') %>%
      str_replace_all('race_ethnicity','Race/ethnicity') %>%
      str_replace_all('map','MAP') %>%
      str_replace_all('nt','NT') %>%
      str_replace_all('plgf','PlGF') %>%
      str_replace_all('pp13','PP13') %>%
      str_replace_all('adam12','ADAM12') %>%
      str_replace_all('parity','Parity') %>%
      str_replace_all('conception','Conception') %>%
      str_replace_all('efw','EFW') %>%
      str_replace_all('sflt1','sFLT-1') %>%
      str_replace_all('ua_pi','UA-PI') %>%
      str_replace_all('mca_pi','MCA-PI') %>%
      str_replace_all('ica_pi','ICA-PI') %>%
      str_replace_all('ra_pi','RA-PI') %>%
      str_replace_all('ao_pi','AO-PI') %>%
      str_replace_all('cu_r','CU-R') %>%
      str_replace_all('mca_sd','MCA-SD') %>%
      str_replace_all('ua_sd','UA-SD') %>%
      str_replace_all('upa_sd','UPA-SD') %>%
      str_replace_all('mca_ri','MCA-RI') %>%
      str_replace_all('ua_ri','UA-RI') %>%
      str_replace_all('uta_ri','UtA-RI') %>%
      str_replace_all('height','Height') %>%
      str_replace_all('med_history','Med. history') %>%
      str_replace_all('bmi','BMI') %>%
      str_replace_all('alc_drinker','Alc. drinker') %>%
      str_replace_all('drug_abuse','Drug abuse') %>%
      str_replace_all('fam_history_pe','Fam. history of PE') %>%
      str_replace_all('medication_preg','Medication in pregnancy') %>%
      str_replace_all('mco','MCO') %>%
      str_replace_all(',',', ')
  ) %>%
  
  # Save for Table C18.
  write_csv('data/table_C18.csv')
```

```{r figure-3, echo=FALSE, fig.height=7.08661, fig.width=5.85827}
srma_rename %>%
  mutate(
    year=
      case_when(
        year>=2012 & year <=2016 ~'2012 to 2016'
        ,year>=2002 & year <2012 ~'2002 to <2012'
        ,year>=1992 & year <2002 ~'1992 to <2002'
        ,year>=1989 & year <1992 ~'1989 to <1992'
      )
  ) %>%
  ggplot(aes(spec,sens,color=year)) +
  geom_vline(xintercept=c(0.95),lty=2) +
  geom_abline(slope=1,intercept=1,lty=2) +
  geom_line(
    data=
      roc2 %>%
      filter(bound=='avg') %>%
      rename(study=model,sens=tpr,spec=tnr) %>%
      filter(!study%in%c('Causal RR','PC-RF'))
    ,aes(color=study)
    ,size=1
  ) +
  geom_point(aes(size=total)) +
  geom_point(
    data=
      opt_th2 %>%
      rename(study=model,sens=tpr,spec=tnr) %>%
      mutate(total=30529+143) %>%
      filter(!study%in%c('Causal RR','PC-RF'))
    ,aes(color=study,size=total)
  ) +
  facet_wrap(~type,ncol=2) +
  coord_equal() +
  scale_x_reverse('Specificity',limits=c(1,0)) +
  scale_y_continuous('Sensitivity',limits=c(0,1)) +
  scale_color_npg(name='Model') +
  scale_size_area('Sample size') +
  theme(
    legend.position='right'
  ) +
  ggsave(
    filename="figure3.eps"
    ,device=cairo_ps
    ,width=170
    ,height=170/5.85827*7.08661
    ,unit='mm'
  )
```

```{r Best discrimination ability, eval=FALSE, include=FALSE}
roc2 %>%
  rename(study=model,sens=tpr,spec=tnr) %>%
  right_join(
    data.frame(
      study=c('PC-ENR','PC-GBM','DI-VNN')
      ,th=c(0.03,0.03,0.02)
    )
    ,by=c('study','th')
  )

auroc_table %>%
  right_join(
    data.frame(model=c('PC-ENR','PC-GBM','DI-VNN'))
    ,by='model'
  )
```

```{r figure-4, fig.height=7.08661, fig.width=7.08661}
auroc +
  ggsave(
    filename="figure4.eps"
    ,device=cairo_ps
    ,width=170
    ,height=170/7.08661*7.08661
    ,unit='mm'
  )
```




























